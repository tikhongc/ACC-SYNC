# -*- coding: utf-8 -*-
"""
Reviews API ç›¸å…³æ¨¡å—
å¤„ç† ACC Reviews API çš„æ‰€æœ‰åŠŸèƒ½ï¼ŒåŒ…æ‹¬å®¡æ‰¹å·¥ä½œæµå’Œè¯„å®¡æ•°æ®
"""

import requests
import json
from flask import Blueprint, jsonify, request
from datetime import datetime
import config
import utils

reviews_bp = Blueprint('reviews', __name__)


@reviews_bp.route('/api/reviews/<project_id>')
def get_project_reviews(project_id):
    """è·å–æŒ‡å®šé¡¹ç›®çš„è¯„å®¡åˆ—è¡¨"""
    access_token = utils.get_access_token()
    if not access_token:
        return jsonify({
            "error": "æœªæ‰¾åˆ° Access Tokenï¼Œè¯·å…ˆè¿›è¡Œè®¤è¯",
            "status": "unauthorized"
        }), 401
    
    headers = {
        "Authorization": f"Bearer {access_token}",
        "Content-Type": "application/json"
    }
    
    # è·å–æŸ¥è¯¢å‚æ•°
    limit = request.args.get('limit', 50, type=int)
    offset = request.args.get('offset', 0, type=int)
    sort = request.args.get('sort', '')
    
    # è¿‡æ»¤å‚æ•°
    filter_workflow_id = request.args.get('filter[workflowId]', '')
    filter_status = request.args.get('filter[status]', '')
    filter_current_step_due_date = request.args.get('filter[currentStepDueDate]', '')
    filter_created_at = request.args.get('filter[createdAt]', '')
    filter_updated_at = request.args.get('filter[updatedAt]', '')
    filter_finished_at = request.args.get('filter[finishedAt]', '')
    filter_next_action_by_user = request.args.get('filter[nextActionByUser]', '')
    filter_next_action_by_role = request.args.get('filter[nextActionByRole]', '')
    filter_next_action_by_company = request.args.get('filter[nextActionByCompany]', '')
    filter_name = request.args.get('filter[name]', '')
    filter_sequence_id = request.args.get('filter[sequenceId]', '')
    filter_archived = request.args.get('filter[archived]', '')
    filter_archived_by = request.args.get('filter[archivedBy]', '')
    filter_archived_at = request.args.get('filter[archivedAt]', '')
    
    # æ„å»ºæŸ¥è¯¢å‚æ•°
    params = {
        'limit': min(limit, 50),  # æœ€å¤§50
        'offset': offset
    }
    
    if sort:
        params['sort'] = sort
    if filter_workflow_id:
        params['filter[workflowId]'] = filter_workflow_id
    if filter_status:
        params['filter[status]'] = filter_status
    if filter_current_step_due_date:
        params['filter[currentStepDueDate]'] = filter_current_step_due_date
    if filter_created_at:
        params['filter[createdAt]'] = filter_created_at
    if filter_updated_at:
        params['filter[updatedAt]'] = filter_updated_at
    if filter_finished_at:
        params['filter[finishedAt]'] = filter_finished_at
    if filter_next_action_by_user:
        params['filter[nextActionByUser]'] = filter_next_action_by_user
    if filter_next_action_by_role:
        params['filter[nextActionByRole]'] = filter_next_action_by_role
    if filter_next_action_by_company:
        params['filter[nextActionByCompany]'] = filter_next_action_by_company
    if filter_name:
        params['filter[name]'] = filter_name
    if filter_sequence_id:
        params['filter[sequenceId]'] = filter_sequence_id
    if filter_archived:
        params['filter[archived]'] = filter_archived.lower() == 'true'
    if filter_archived_by:
        params['filter[archivedBy]'] = filter_archived_by
    if filter_archived_at:
        params['filter[archivedAt]'] = filter_archived_at
    
    try:
        # è°ƒç”¨ Autodesk Construction Cloud Reviews API
        reviews_url = f"{config.AUTODESK_API_BASE}/construction/reviews/v1/projects/{project_id}/reviews"
        reviews_resp = requests.get(reviews_url, headers=headers, params=params)
        
        print(f"APIè¯·æ±‚URL: {reviews_url}")
        print(f"APIè¯·æ±‚å‚æ•°: {params}")
        print(f"APIå“åº”çŠ¶æ€ç : {reviews_resp.status_code}")
        
        if reviews_resp.status_code != 200:
            error_text = reviews_resp.text
            print(f"APIé”™è¯¯å“åº”: {error_text}")
            raise Exception(f"è·å–è¯„å®¡åˆ—è¡¨å¤±è´¥: {reviews_resp.status_code} - {error_text}")
        
        try:
            reviews_data = reviews_resp.json()
            print(f"APIå“åº”æ•°æ®: {reviews_data}")  # è°ƒè¯•ä¿¡æ¯
            
            # è¯¦ç»†è°ƒè¯•å‰å‡ ä¸ªè¯„å®¡çš„IDä¿¡æ¯
            if reviews_data and reviews_data.get("results"):
                print(f"æ€»å…±è·å–åˆ° {len(reviews_data['results'])} ä¸ªè¯„å®¡")
                for i, review in enumerate(reviews_data["results"][:5]):  # åªæ‰“å°å‰5ä¸ª
                    if review:
                        print(f"è¯„å®¡ {i+1}: ID={review.get('id')}, sequenceId={review.get('sequenceId')}, name={review.get('name', '')[:50]}")
                        
        except json.JSONDecodeError as e:
            print(f"JSONè§£æé”™è¯¯: {e}")
            raise Exception(f"APIå“åº”æ•°æ®æ ¼å¼é”™è¯¯: {str(e)}")
        
        if not reviews_data:
            print("APIè¿”å›ç©ºæ•°æ®")
            reviews_data = {"results": [], "pagination": {}}
            
        reviews_list = reviews_data.get("results", [])
        pagination = reviews_data.get("pagination", {})
        
        # ä½¿ç”¨sequenceIdä½œä¸ºä¸»è¦å»é‡æ ‡è¯†ï¼Œå› ä¸ºidå¯èƒ½ä¸å”¯ä¸€
        seen_ids = set()
        unique_reviews = []
        duplicate_count = 0
        
        for review in reviews_list:
            if not review:
                continue
                
            # ä¼˜å…ˆä½¿ç”¨sequenceIdï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨id
            review_unique_id = review.get("sequenceId") or review.get("id", "")
            if not review_unique_id:
                continue  # è·³è¿‡æ²¡æœ‰å”¯ä¸€æ ‡è¯†çš„è¯„å®¡
                
            if review_unique_id in seen_ids:
                duplicate_count += 1
                print(f"å‘ç°é‡å¤è¯„å®¡: sequenceId={review.get('sequenceId')}, id={review.get('id')}, name={review.get('name', '')[:50]}")
                continue  # è·³è¿‡é‡å¤çš„è¯„å®¡
            
            seen_ids.add(review_unique_id)
            unique_reviews.append(review)
        
        original_count = len(reviews_list)
        reviews_list = unique_reviews
        
        if duplicate_count > 0:
            print(f"å»é‡å®Œæˆ: åŸå§‹ {original_count} -> å»é‡å {len(reviews_list)} (ç§»é™¤ {duplicate_count} ä¸ªé‡å¤)")
            
        # è°ƒè¯•å»é‡åçš„è¯„å®¡ID
        print("å»é‡åçš„è¯„å®¡IDåˆ—è¡¨:")
        for i, review in enumerate(reviews_list[:5]):  # åªæ‰“å°å‰5ä¸ª
            if review:
                print(f"å»é‡åè¯„å®¡ {i+1}: ID={review.get('id')}, sequenceId={review.get('sequenceId')}, name={review.get('name', '')[:50]}")
        
        # ç”Ÿæˆè¯„å®¡åˆ†ææ•°æ®
        reviews_analysis = []
        for review in reviews_list:
            if not review:  # è·³è¿‡ç©ºçš„reviewå¯¹è±¡
                continue
                
            # å®‰å…¨è·å–nextActionByæ•°æ®
            next_action_by = review.get("nextActionBy") or {}
            claimed_by = next_action_by.get("claimedBy") or []
            candidates = next_action_by.get("candidates") or {}
            
            analysis = {
                "id": review.get("id", ""),
                "sequence_id": review.get("sequenceId", 0),
                "name": review.get("name", ""),
                "status": review.get("status", ""),
                "current_step_id": review.get("currentStepId", ""),
                "current_step_due_date": utils.format_timestamp(review.get("currentStepDueDate", "")),
                "created_by": review.get("createdBy") or {},
                "created_at": utils.format_timestamp(review.get("createdAt", "")),
                "updated_at": utils.format_timestamp(review.get("updatedAt", "")),
                "finished_at": utils.format_timestamp(review.get("finishedAt", "")),
                "archived": review.get("archived", False),
                "archived_by": review.get("archivedBy") or {},
                "archived_at": utils.format_timestamp(review.get("archivedAt", "")),
                "workflow_id": review.get("workflowId", ""),
                "next_action_by": next_action_by,
                "has_claimed_users": len(claimed_by) > 0,
                "candidates_count": {
                    "roles": len(candidates.get("roles") or []),
                    "users": len(candidates.get("users") or []),
                    "companies": len(candidates.get("companies") or [])
                }
            }
            reviews_analysis.append(analysis)
        
        # ç”Ÿæˆè¯¦ç»†çš„è¯„å®¡åˆ†æï¼ˆä½¿ç”¨å»é‡åçš„è¯„å®¡åˆ—è¡¨ï¼‰
        detailed_analysis = []
        for i, review in enumerate(reviews_list):
            if not review:  # è·³è¿‡ç©ºçš„reviewå¯¹è±¡
                continue
                
            # å®‰å…¨è·å–nextActionByæ•°æ®
            next_action_by = review.get('nextActionBy') or {}
            claimed_by = next_action_by.get('claimedBy') or []
            candidates = next_action_by.get('candidates') or {}
            
            review_analysis = {
                "review_number": i + 1,
                "basic_info": {
                    "id": review.get('id', 'N/A'),
                    "sequence_id": review.get('sequenceId', 'N/A'),
                    "name": review.get('name', 'N/A'),
                    "status": review.get('status', 'N/A'),
                    "workflow_id": review.get('workflowId', 'N/A'),
                    "created_at": utils.format_timestamp(review.get('createdAt', '')),
                    "updated_at": utils.format_timestamp(review.get('updatedAt', '')),
                    "finished_at": utils.format_timestamp(review.get('finishedAt', ''))
                },
                "review_summary": {
                    "current_step_id": review.get('currentStepId', 'N/A'),
                    "current_step_due_date": utils.format_timestamp(review.get('currentStepDueDate', '')),
                    "archived": review.get('archived', False),
                    "has_claimed_users": len(claimed_by) > 0,
                    "total_candidates": (
                        len(candidates.get('roles') or []) +
                        len(candidates.get('users') or []) +
                        len(candidates.get('companies') or [])
                    )
                },
                "participants": {
                    "created_by": review.get('createdBy') or {},
                    "archived_by": review.get('archivedBy') or {},
                    "claimed_by": claimed_by,
                    "candidates": candidates
                }
            }
            detailed_analysis.append(review_analysis)
        
        # ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
        total_reviews = pagination.get('totalResults', len(reviews_list))
        status_counts = {}
        for review in reviews_list:
            if review:  # ç¡®ä¿reviewä¸ä¸ºç©º
                status = review.get('status', 'UNKNOWN')
                status_counts[status] = status_counts.get(status, 0) + 1
        
        archived_count = len([r for r in reviews_list if r and r.get('archived', False)])
        
        # å®‰å…¨è®¡ç®—æœ‰è®¤é¢†ç”¨æˆ·çš„è¯„å®¡æ•°é‡
        with_claimed_users = 0
        total_candidates = 0
        
        for r in reviews_list:
            if r:  # ç¡®ä¿reviewä¸ä¸ºç©º
                next_action_by = r.get('nextActionBy') or {}
                claimed_by = next_action_by.get('claimedBy') or []
                if len(claimed_by) > 0:
                    with_claimed_users += 1
                
                # è®¡ç®—å€™é€‰è€…æ€»æ•°
                candidates = next_action_by.get('candidates') or {}
                total_candidates += (
                    len(candidates.get('users') or []) + 
                    len(candidates.get('roles') or []) + 
                    len(candidates.get('companies') or [])
                )
        
        stats = {
            "total_reviews": total_reviews,
            "current_page_count": len(reviews_list),
            "original_count": original_count,
            "duplicate_count": duplicate_count,
            "unique_count": len(reviews_list),
            "status_counts": status_counts,
            "archived_count": archived_count,
            "active_count": len(reviews_list) - archived_count,
            "with_claimed_users": with_claimed_users,
            "avg_candidates_per_review": round(total_candidates / len(reviews_list), 1) if reviews_list else 0
        }
        
        return jsonify({
            "success": True,
            "project_id": project_id,
            "query_params": params,
            "stats": stats,
            "reviews": reviews_analysis,
            "detailed_analysis": detailed_analysis,
            "pagination": pagination,
            "raw_data": reviews_list,
            "timestamp": datetime.now().isoformat()
        })
        
    except Exception as e:
        print(f"è·å–è¯„å®¡æ•°æ®æ—¶å‡ºé”™: {str(e)}")
        return jsonify({
            "error": f"è·å–è¯„å®¡æ•°æ®å¤±è´¥: {str(e)}",
            "status": "error"
        }), 500


@reviews_bp.route('/api/reviews/<project_id>/jarvis')
def get_jarvis_reviews(project_id=None):
    """è·å– isBIM JARVIS 2025 Dev é¡¹ç›®çš„è¯„å®¡æ•°æ®"""
    # å¦‚æœæ²¡æœ‰æä¾›project_idï¼Œä½¿ç”¨é»˜è®¤çš„JARVISé¡¹ç›®ID
    if not project_id:
        project_id = config.JARVIS_PROJECT_ID
    
    return get_project_reviews(project_id)


@reviews_bp.route('/api/reviews/jarvis')
def get_jarvis_reviews_simple():
    """è·å–é¡¹ç›®çš„è¯„å®¡æ•°æ® - æ”¯æŒåŠ¨æ€é¡¹ç›®ID"""
    # è·å–é¡¹ç›®ID - ä¼˜å…ˆä½¿ç”¨è¯·æ±‚å‚æ•°ï¼Œå¦åˆ™ä½¿ç”¨é»˜è®¤é¡¹ç›®ID
    project_id = request.args.get('projectId', config.JARVIS_PROJECT_ID)
    print(f"ğŸš€ Reviews API: ä½¿ç”¨é¡¹ç›®ID: {project_id}")
    
    return get_project_reviews(project_id)


# ==================== å·¥ä½œæµç›¸å…³æ¥å£ ====================

@reviews_bp.route('/api/reviews/workflows/<project_id>')
def get_project_workflows(project_id):
    """è·å–æŒ‡å®šé¡¹ç›®çš„å®¡æ‰¹å·¥ä½œæµåˆ—è¡¨"""
    access_token = utils.get_access_token()
    if not access_token:
        return jsonify({
            "error": "æœªæ‰¾åˆ° Access Tokenï¼Œè¯·å…ˆè¿›è¡Œè®¤è¯",
            "status": "unauthorized"
        }), 401
    
    headers = {
        "Authorization": f"Bearer {access_token}",
        "Content-Type": "application/json"
    }
    
    # è·å–æŸ¥è¯¢å‚æ•°
    limit = request.args.get('limit', 50, type=int)
    offset = request.args.get('offset', 0, type=int)
    sort = request.args.get('sort', '')
    filter_initiator = request.args.get('filter[initiator]', '')
    filter_status = request.args.get('filter[status]', 'ACTIVE')
    
    # æ„å»ºæŸ¥è¯¢å‚æ•°
    params = {
        'limit': min(limit, 50),  # æœ€å¤§50
        'offset': offset
    }
    
    if sort:
        params['sort'] = sort
    if filter_initiator:
        params['filter[initiator]'] = filter_initiator.lower() == 'true'
    if filter_status:
        params['filter[status]'] = filter_status
    
    try:
        # è°ƒç”¨ Autodesk Construction Cloud Reviews API
        workflows_url = f"{config.AUTODESK_API_BASE}/construction/reviews/v1/projects/{project_id}/workflows"
        workflows_resp = requests.get(workflows_url, headers=headers, params=params)
        
        if workflows_resp.status_code != 200:
            raise Exception(f"è·å–å·¥ä½œæµåˆ—è¡¨å¤±è´¥: {workflows_resp.status_code} - {workflows_resp.text}")
        
        workflows_data = workflows_resp.json()
        workflows_list = workflows_data.get("results", [])
        pagination = workflows_data.get("pagination", {})
        
        # ç”Ÿæˆå·¥ä½œæµåˆ†ææ•°æ®
        workflows_analysis = []
        for workflow in workflows_list:
            analysis = {
                "id": workflow.get("id"),
                "name": workflow.get("name"),
                "description": workflow.get("description", ""),
                "notes": workflow.get("notes", ""),
                "status": workflow.get("status"),
                "created_at": utils.format_timestamp(workflow.get("createdAt", "")),
                "updated_at": utils.format_timestamp(workflow.get("updatedAt", "")),
                "steps_count": len(workflow.get("steps", [])),
                "approval_options_count": len(workflow.get("approvalStatusOptions", [])),
                "has_copy_files": workflow.get("copyFilesOptions", {}).get("enabled", False),
                "has_attached_attributes": len(workflow.get("attachedAttributes", [])) > 0,
                "additional_options": workflow.get("additionalOptions", {}),
                "steps": workflow.get("steps", []),
                "approval_status_options": workflow.get("approvalStatusOptions", []),
                "copy_files_options": workflow.get("copyFilesOptions", {}),
                "attached_attributes": workflow.get("attachedAttributes", []),
                "update_attributes_options": workflow.get("updateAttributesOptions", {})
            }
            workflows_analysis.append(analysis)
        
        # ç”Ÿæˆè¯¦ç»†çš„å·¥ä½œæµæ­¥éª¤åˆ†æ
        detailed_analysis = []
        for i, workflow in enumerate(workflows_list):
            workflow_analysis = {
                "workflow_number": i + 1,
                "basic_info": {
                    "id": workflow.get('id', 'N/A'),
                    "name": workflow.get('name', 'N/A'),
                    "description": workflow.get('description', 'N/A'),
                    "status": workflow.get('status', 'N/A'),
                    "created_at": utils.format_timestamp(workflow.get('createdAt', '')),
                    "updated_at": utils.format_timestamp(workflow.get('updatedAt', '')),
                    "notes": workflow.get('notes', 'N/A')
                },
                "workflow_summary": {
                    "steps_count": len(workflow.get('steps', [])),
                    "approval_options_count": len(workflow.get('approvalStatusOptions', [])),
                    "has_copy_files": workflow.get('copyFilesOptions', {}).get('enabled', False),
                    "has_attached_attributes": len(workflow.get('attachedAttributes', [])) > 0,
                    "allow_initiator_edit": workflow.get('additionalOptions', {}).get('allowInitiatorToEdit', False)
                },
                "detailed_steps": []
            }
            
            # åˆ†æå·¥ä½œæµæ­¥éª¤
            steps = workflow.get("steps", [])
            if steps:
                for step_idx, step in enumerate(steps):
                    step_detail = {
                        "step_number": step_idx + 1,
                        "name": step.get('name', 'N/A'),
                        "type": step.get('type', 'N/A'),
                        "duration": step.get('duration', 0),
                        "due_date_type": step.get('dueDateType', 'N/A'),
                        "group_review": step.get('groupReview', {}),
                        "candidates": {
                            "roles_count": len(step.get('candidates', {}).get('roles', [])),
                            "users_count": len(step.get('candidates', {}).get('users', [])),
                            "companies_count": len(step.get('candidates', {}).get('companies', [])),
                            "roles": step.get('candidates', {}).get('roles', []),
                            "users": step.get('candidates', {}).get('users', []),
                            "companies": step.get('candidates', {}).get('companies', [])
                        }
                    }
                    workflow_analysis["detailed_steps"].append(step_detail)
            
            detailed_analysis.append(workflow_analysis)
        
        # ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
        total_workflows = pagination.get('totalResults', len(workflows_list))
        active_workflows = len([w for w in workflows_list if w.get('status') == 'ACTIVE'])
        inactive_workflows = len([w for w in workflows_list if w.get('status') == 'INACTIVE'])
        
        stats = {
            "total_workflows": total_workflows,
            "current_page_count": len(workflows_list),
            "active_workflows": active_workflows,
            "inactive_workflows": inactive_workflows,
            "avg_steps_per_workflow": round(sum(len(w.get('steps', [])) for w in workflows_list) / len(workflows_list), 1) if workflows_list else 0,
            "workflows_with_copy_files": len([w for w in workflows_list if w.get('copyFilesOptions', {}).get('enabled', False)]),
            "workflows_with_attributes": len([w for w in workflows_list if w.get('attachedAttributes')])
        }
        
        return jsonify({
            "success": True,
            "project_id": project_id,
            "query_params": params,
            "stats": stats,
            "workflows": workflows_analysis,
            "detailed_analysis": detailed_analysis,
            "pagination": pagination,
            "raw_data": workflows_list,
            "timestamp": datetime.now().isoformat()
        })
        
    except Exception as e:
        print(f"è·å–å·¥ä½œæµæ•°æ®æ—¶å‡ºé”™: {str(e)}")
        return jsonify({
            "error": f"è·å–å·¥ä½œæµæ•°æ®å¤±è´¥: {str(e)}",
            "status": "error"
        }), 500


@reviews_bp.route('/api/reviews/workflows/<project_id>/jarvis')
def get_jarvis_workflows(project_id=None):
    """è·å– isBIM JARVIS 2025 Dev é¡¹ç›®çš„å®¡æ‰¹å·¥ä½œæµæ•°æ®"""
    # å¦‚æœæ²¡æœ‰æä¾›project_idï¼Œä½¿ç”¨é»˜è®¤çš„JARVISé¡¹ç›®ID
    if not project_id:
        project_id = config.JARVIS_PROJECT_ID
    
    return get_project_workflows(project_id)


@reviews_bp.route('/api/reviews/workflows/jarvis')
def get_jarvis_workflows_simple():
    """è·å–é¡¹ç›®çš„å®¡æ‰¹å·¥ä½œæµæ•°æ® - æ”¯æŒåŠ¨æ€é¡¹ç›®ID"""
    # è·å–é¡¹ç›®ID - ä¼˜å…ˆä½¿ç”¨è¯·æ±‚å‚æ•°ï¼Œå¦åˆ™ä½¿ç”¨é»˜è®¤é¡¹ç›®ID
    project_id = request.args.get('projectId', config.JARVIS_PROJECT_ID)
    print(f"ğŸš€ Workflows API: ä½¿ç”¨é¡¹ç›®ID: {project_id}")
    
    return get_project_workflows(project_id)


# ==================== å•ä¸ªè¯„å®¡å·¥ä½œæµæ¥å£ ====================

@reviews_bp.route('/api/reviews/<project_id>/<review_id>/workflow')
def get_review_workflow(project_id, review_id):
    """è·å–æŒ‡å®šè¯„å®¡çš„å…³è”å·¥ä½œæµ"""
    access_token = utils.get_access_token()
    if not access_token:
        return jsonify({
            "error": "æœªæ‰¾åˆ° Access Tokenï¼Œè¯·å…ˆè¿›è¡Œè®¤è¯",
            "status": "unauthorized"
        }), 401
    
    headers = {
        "Authorization": f"Bearer {access_token}",
        "Content-Type": "application/json"
    }
    
    try:
        # è°ƒç”¨ Autodesk Construction Cloud Reviews API
        workflow_url = f"{config.AUTODESK_API_BASE}/construction/reviews/v1/projects/{project_id}/reviews/{review_id}/workflow"
        
        print(f"APIè¯·æ±‚URL: {workflow_url}")
        print(f"APIè¯·æ±‚å¤´: {headers}")
        
        workflow_resp = requests.get(workflow_url, headers=headers)
        
        print(f"APIå“åº”çŠ¶æ€ç : {workflow_resp.status_code}")
        
        if workflow_resp.status_code != 200:
            error_text = workflow_resp.text
            print(f"APIé”™è¯¯å“åº”: {error_text}")
            raise Exception(f"è·å–è¯„å®¡å·¥ä½œæµå¤±è´¥: {workflow_resp.status_code} - {error_text}")
        
        try:
            workflow_data = workflow_resp.json()
            print(f"APIå“åº”æ•°æ®: {workflow_data}")
        except json.JSONDecodeError as e:
            print(f"JSONè§£æé”™è¯¯: {e}")
            raise Exception(f"APIå“åº”æ•°æ®æ ¼å¼é”™è¯¯: {str(e)}")
        
        if not workflow_data:
            print("APIè¿”å›ç©ºå·¥ä½œæµæ•°æ®")
            workflow_data = {}
        
        # ç”Ÿæˆå·¥ä½œæµåˆ†ææ•°æ®
        workflow_analysis = {
            "id": workflow_data.get("id", ""),
            "name": workflow_data.get("name", ""),
            "description": workflow_data.get("description", ""),
            "notes": workflow_data.get("notes", ""),
            "additional_options": workflow_data.get("additionalOptions") or {},
            "steps": workflow_data.get("steps") or [],
            "approval_status_options": workflow_data.get("approvalStatusOptions") or [],
            "copy_files_options": workflow_data.get("copyFilesOptions") or {},
            "attached_attributes": workflow_data.get("attachedAttributes") or [],
            "update_attributes_options": workflow_data.get("updateAttributesOptions") or {},
            # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
            "steps_count": len(workflow_data.get("steps", [])),
            "approval_options_count": len(workflow_data.get("approvalStatusOptions", [])),
            "has_copy_files": workflow_data.get("copyFilesOptions", {}).get("enabled", False),
            "has_attached_attributes": len(workflow_data.get("attachedAttributes", [])) > 0,
            "allow_initiator_edit": workflow_data.get("additionalOptions", {}).get("allowInitiatorToEdit", False)
        }
        
        # ç”Ÿæˆè¯¦ç»†çš„æ­¥éª¤åˆ†æ
        detailed_steps = []
        steps = workflow_data.get("steps", [])
        for step_idx, step in enumerate(steps):
            if not step:
                continue
                
            candidates = step.get("candidates") or {}
            step_detail = {
                "step_number": step_idx + 1,
                "id": step.get("id", ""),
                "name": step.get("name", ""),
                "type": step.get("type", ""),
                "duration": step.get("duration", 0),
                "due_date_type": step.get("dueDateType", ""),
                "group_review": step.get("groupReview") or {},
                "candidates": {
                    "roles": candidates.get("roles") or [],
                    "users": candidates.get("users") or [],
                    "companies": candidates.get("companies") or [],
                    "roles_count": len(candidates.get("roles") or []),
                    "users_count": len(candidates.get("users") or []),
                    "companies_count": len(candidates.get("companies") or [])
                }
            }
            detailed_steps.append(step_detail)
        
        # ç”Ÿæˆå®¡æ‰¹çŠ¶æ€é€‰é¡¹åˆ†æ
        approval_options_analysis = []
        for option in workflow_data.get("approvalStatusOptions", []):
            if not option:
                continue
            option_analysis = {
                "id": option.get("id", ""),
                "label": option.get("label", ""),
                "value": option.get("value", ""),
                "built_in": option.get("builtIn", False)
            }
            approval_options_analysis.append(option_analysis)
        
        return jsonify({
            "success": True,
            "project_id": project_id,
            "review_id": review_id,
            "workflow": workflow_analysis,
            "detailed_steps": detailed_steps,
            "approval_options": approval_options_analysis,
            "raw_data": workflow_data,
            "timestamp": datetime.now().isoformat()
        })
        
    except Exception as e:
        print(f"è·å–è¯„å®¡å·¥ä½œæµæ—¶å‡ºé”™: {str(e)}")
        return jsonify({
            "error": f"è·å–è¯„å®¡å·¥ä½œæµå¤±è´¥: {str(e)}",
            "status": "error"
        }), 500


@reviews_bp.route('/api/reviews/jarvis/<review_id>/workflow')
def get_jarvis_review_workflow(review_id):
    """è·å– JARVIS é¡¹ç›®ä¸­æŒ‡å®šè¯„å®¡çš„å·¥ä½œæµ"""
    return get_review_workflow(config.JARVIS_PROJECT_ID, review_id)


# ==================== è¯„å®¡æ–‡ä»¶ç‰ˆæœ¬æ¥å£ ====================

@reviews_bp.route('/api/reviews/<project_id>/<review_id>/versions')
def get_review_versions(project_id, review_id):
    """è·å–æŒ‡å®šè¯„å®¡çš„æ–‡ä»¶ç‰ˆæœ¬åˆ—è¡¨"""
    access_token = utils.get_access_token()
    if not access_token:
        return jsonify({
            "error": "æœªæ‰¾åˆ° Access Tokenï¼Œè¯·å…ˆè¿›è¡Œè®¤è¯",
            "status": "unauthorized"
        }), 401
    
    headers = {
        "Authorization": f"Bearer {access_token}",
        "Content-Type": "application/json"
    }
    
    # è·å–æŸ¥è¯¢å‚æ•°
    limit = request.args.get('limit', 50, type=int)
    offset = request.args.get('offset', 0, type=int)
    filter_approve_status = request.args.getlist('filter[approveStatus]')
    
    # æ„å»ºæŸ¥è¯¢å‚æ•°
    params = {
        'limit': min(limit, 50),  # æœ€å¤§50
        'offset': offset
    }
    
    # æ·»åŠ å®¡æ‰¹çŠ¶æ€è¿‡æ»¤å™¨
    for status in filter_approve_status:
        if status:
            params.setdefault('filter[approveStatus]', []).append(status)
    
    try:
        # è°ƒç”¨ Autodesk Construction Cloud Reviews API
        versions_url = f"{config.AUTODESK_API_BASE}/construction/reviews/v1/projects/{project_id}/reviews/{review_id}/versions"
        
        print(f"APIè¯·æ±‚URL: {versions_url}")
        print(f"APIè¯·æ±‚å‚æ•°: {params}")
        
        versions_resp = requests.get(versions_url, headers=headers, params=params)
        
        print(f"APIå“åº”çŠ¶æ€ç : {versions_resp.status_code}")
        
        if versions_resp.status_code != 200:
            error_text = versions_resp.text
            print(f"APIé”™è¯¯å“åº”: {error_text}")
            raise Exception(f"è·å–è¯„å®¡æ–‡ä»¶ç‰ˆæœ¬å¤±è´¥: {versions_resp.status_code} - {error_text}")
        
        try:
            versions_data = versions_resp.json()
            print(f"APIå“åº”æ•°æ®: {versions_data}")
            
        except json.JSONDecodeError as e:
            print(f"JSONè§£æé”™è¯¯: {e}")
            raise Exception(f"APIå“åº”æ•°æ®æ ¼å¼é”™è¯¯: {str(e)}")
        
        if not versions_data:
            print("APIè¿”å›ç©ºæ–‡ä»¶ç‰ˆæœ¬æ•°æ®")
            versions_data = {"results": [], "pagination": {}}
        
        versions_list = versions_data.get("results", [])
        pagination = versions_data.get("pagination", {})
        
        # å¯¹æ–‡ä»¶ç‰ˆæœ¬è¿›è¡Œå»é‡å¤„ç†
        seen_urns = set()
        unique_versions = []
        duplicate_versions_count = 0
        
        for version in versions_list:
            if not version:
                continue
                
            version_urn = version.get("urn", "")
            if not version_urn:
                continue  # è·³è¿‡æ²¡æœ‰URNçš„ç‰ˆæœ¬
                
            if version_urn in seen_urns:
                duplicate_versions_count += 1
                continue  # è·³è¿‡é‡å¤çš„æ–‡ä»¶ç‰ˆæœ¬
            
            seen_urns.add(version_urn)
            unique_versions.append(version)
        
        original_versions_count = len(versions_list)
        versions_list = unique_versions
        
        if duplicate_versions_count > 0:
            print(f"æ–‡ä»¶ç‰ˆæœ¬å»é‡: åŸå§‹ {original_versions_count} -> å»é‡å {len(versions_list)} (ç§»é™¤ {duplicate_versions_count} ä¸ªé‡å¤)")
        
        # ç”Ÿæˆæ–‡ä»¶ç‰ˆæœ¬åˆ†ææ•°æ®
        versions_analysis = []
        for version in versions_list:
            if not version:
                continue
            
            approve_status = version.get("approveStatus") or {}
            review_content = version.get("reviewContent") or {}
            custom_attributes = review_content.get("customAttributes") or []
            
            # æå–æ›´å¤šæ ‡è¯†ç¬¦æ¥åŒºåˆ†æ–‡ä»¶
            version_number = extract_version_number(version.get("urn", ""))
            file_size = version.get("size", 0)
            created_date = version.get("createdDate", "")
            modified_date = version.get("modifiedDate", "")
            
            analysis = {
                "urn": version.get("urn", ""),
                "item_urn": version.get("itemUrn", ""),
                "name": version.get("name", ""),
                "version_number": version_number,
                "file_size": file_size,
                "created_date": utils.format_timestamp(created_date) if created_date else "",
                "modified_date": utils.format_timestamp(modified_date) if modified_date else "",
                "approve_status": {
                    "id": approve_status.get("id", ""),
                    "label": approve_status.get("label", ""),
                    "value": approve_status.get("value", ""),
                    "status_type": get_approve_status_type(approve_status.get("value", ""))
                },
                "review_content": {
                    "name": review_content.get("name", ""),
                    "custom_attributes": custom_attributes,
                    "custom_attributes_count": len(custom_attributes)
                },
                "copied_file_version_urn": version.get("copiedFileVersionUrn", ""),
                "has_copied_version": bool(version.get("copiedFileVersionUrn")),
                "file_extension": get_file_extension(version.get("name", "")),
                "is_pdf": version.get("name", "").lower().endswith('.pdf'),
                "unique_identifier": f"{version.get('itemUrn', '')}-{version_number}",
                "display_name": f"{version.get('name', '')} (v{version_number})" if version_number else version.get('name', ''),
                # ä¿ç•™åŸå§‹æ•°æ®ç”¨äºè°ƒè¯•
                "raw_version_data": version
            }
            versions_analysis.append(analysis)
        
        # ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
        total_versions = pagination.get('totalResults', len(versions_list))
        status_counts = {}
        file_type_counts = {}
        
        for version in versions_analysis:
            # ç»Ÿè®¡å®¡æ‰¹çŠ¶æ€
            status_label = version["approve_status"]["label"]
            if status_label:
                status_counts[status_label] = status_counts.get(status_label, 0) + 1
            
            # ç»Ÿè®¡æ–‡ä»¶ç±»å‹
            file_ext = version["file_extension"]
            if file_ext:
                file_type_counts[file_ext] = file_type_counts.get(file_ext, 0) + 1
        
        copied_versions_count = len([v for v in versions_analysis if v["has_copied_version"]])
        with_custom_attributes = len([v for v in versions_analysis if v["review_content"]["custom_attributes_count"] > 0])
        
        stats = {
            "total_versions": total_versions,
            "current_page_count": len(versions_list),
            "original_versions_count": original_versions_count,
            "duplicate_versions_count": duplicate_versions_count,
            "unique_versions_count": len(versions_list),
            "status_counts": status_counts,
            "file_type_counts": file_type_counts,
            "copied_versions_count": copied_versions_count,
            "with_custom_attributes": with_custom_attributes,
            "pdf_files_count": len([v for v in versions_analysis if v["is_pdf"]])
        }
        
        return jsonify({
            "success": True,
            "project_id": project_id,
            "review_id": review_id,
            "query_params": params,
            "stats": stats,
            "versions": versions_analysis,
            "pagination": pagination,
            "raw_data": versions_list,
            "timestamp": datetime.now().isoformat()
        })
        
    except Exception as e:
        print(f"è·å–è¯„å®¡æ–‡ä»¶ç‰ˆæœ¬æ—¶å‡ºé”™: {str(e)}")
        return jsonify({
            "error": f"è·å–è¯„å®¡æ–‡ä»¶ç‰ˆæœ¬å¤±è´¥: {str(e)}",
            "status": "error"
        }), 500


def get_approve_status_type(status_value):
    """è·å–å®¡æ‰¹çŠ¶æ€çš„ç±»å‹ç”¨äºUIæ˜¾ç¤º"""
    status_map = {
        'APPROVED': 'success',
        'REJECTED': 'danger',
        'PENDING': 'warning',
        'VOID': 'info'
    }
    return status_map.get(status_value, 'info')


def get_file_extension(filename):
    """è·å–æ–‡ä»¶æ‰©å±•å"""
    if not filename:
        return ""
    return filename.split('.')[-1].upper() if '.' in filename else ""


def extract_version_number(urn):
    """ä»URNä¸­æå–ç‰ˆæœ¬å·"""
    if not urn:
        return ""
    
    # URNæ ¼å¼é€šå¸¸æ˜¯: urn:adsk.wipprod:fs.file:vf.xxxxx?version=N
    import re
    version_match = re.search(r'version=(\d+)', urn)
    if version_match:
        return version_match.group(1)
    
    # ä¹Ÿå¯èƒ½åœ¨URNçš„å…¶ä»–éƒ¨åˆ†
    version_match = re.search(r'v(\d+)', urn)
    if version_match:
        return version_match.group(1)
    
    return "1"  # é»˜è®¤ç‰ˆæœ¬å·


@reviews_bp.route('/api/reviews/jarvis/<review_id>/versions')
def get_jarvis_review_versions(review_id):
    """è·å– JARVIS é¡¹ç›®ä¸­æŒ‡å®šè¯„å®¡çš„æ–‡ä»¶ç‰ˆæœ¬"""
    return get_review_versions(config.JARVIS_PROJECT_ID, review_id)


# ==================== æ–‡ä»¶ç‰ˆæœ¬å®¡æ‰¹å†å²æ¥å£ ====================

@reviews_bp.route('/api/versions/<project_id>/<path:version_id>/approval-statuses')
def get_version_approval_statuses(project_id, version_id):
    """è·å–æŒ‡å®šæ–‡ä»¶ç‰ˆæœ¬çš„å®¡æ‰¹å†å²å’Œè¯„å®¡è®°å½•"""
    access_token = utils.get_access_token()
    if not access_token:
        return jsonify({
            "error": "æœªæ‰¾åˆ° Access Tokenï¼Œè¯·å…ˆè¿›è¡Œè®¤è¯",
            "status": "unauthorized"
        }), 401
    
    headers = {
        "Authorization": f"Bearer {access_token}",
        "Content-Type": "application/json"
    }
    
    # è·å–æŸ¥è¯¢å‚æ•°
    limit = request.args.get('limit', 50, type=int)
    offset = request.args.get('offset', 0, type=int)
    
    # æ„å»ºæŸ¥è¯¢å‚æ•°
    params = {
        'limit': min(limit, 50),  # æœ€å¤§50
        'offset': offset
    }
    
    try:
        # URLç¼–ç ç‰ˆæœ¬IDï¼ˆé€šå¸¸æ˜¯URNï¼‰
        from urllib.parse import quote
        encoded_version_id = quote(version_id, safe='')
        
        # è°ƒç”¨ Autodesk Construction Cloud Reviews API
        approval_url = f"{config.AUTODESK_API_BASE}/construction/reviews/v1/projects/{project_id}/versions/{encoded_version_id}/approval-statuses"
        
        print(f"APIè¯·æ±‚URL: {approval_url}")
        print(f"APIè¯·æ±‚å‚æ•°: {params}")
        print(f"åŸå§‹ç‰ˆæœ¬ID: {version_id}")
        print(f"ç¼–ç ç‰ˆæœ¬ID: {encoded_version_id}")
        
        approval_resp = requests.get(approval_url, headers=headers, params=params)
        
        print(f"APIå“åº”çŠ¶æ€ç : {approval_resp.status_code}")
        
        if approval_resp.status_code != 200:
            error_text = approval_resp.text
            print(f"APIé”™è¯¯å“åº”: {error_text}")
            raise Exception(f"è·å–æ–‡ä»¶å®¡æ‰¹å†å²å¤±è´¥: {approval_resp.status_code} - {error_text}")
        
        try:
            approval_data = approval_resp.json()
            print(f"APIå“åº”æ•°æ®: {approval_data}")
            
            # è¯¦ç»†è®°å½•ç¬¬ä¸€ä¸ªå®¡æ‰¹è®°å½•çš„ç»“æ„ï¼Œä»¥ä¾¿äº†è§£å¯ç”¨å­—æ®µ
            if approval_data and approval_data.get("results") and len(approval_data["results"]) > 0:
                first_approval = approval_data["results"][0]
                print(f"ç¬¬ä¸€ä¸ªå®¡æ‰¹è®°å½•çš„å®Œæ•´ç»“æ„: {json.dumps(first_approval, indent=2, ensure_ascii=False)}")
                print(f"ç¬¬ä¸€ä¸ªå®¡æ‰¹è®°å½•çš„æ‰€æœ‰å­—æ®µ: {list(first_approval.keys())}")
                
                # æ£€æŸ¥åµŒå¥—ç»“æ„
                if "approvalStatus" in first_approval:
                    print(f"approvalStatuså­—æ®µ: {list(first_approval['approvalStatus'].keys())}")
                if "review" in first_approval:
                    print(f"reviewå­—æ®µ: {list(first_approval['review'].keys())}")
        except json.JSONDecodeError as e:
            print(f"JSONè§£æé”™è¯¯: {e}")
            raise Exception(f"APIå“åº”æ•°æ®æ ¼å¼é”™è¯¯: {str(e)}")
        
        if not approval_data:
            print("APIè¿”å›ç©ºå®¡æ‰¹å†å²æ•°æ®")
            approval_data = {"results": [], "pagination": {}}
        
        approval_list = approval_data.get("results", [])
        pagination = approval_data.get("pagination", {})
        
        # ç”Ÿæˆå®¡æ‰¹å†å²åˆ†ææ•°æ®
        approval_analysis = []
        for approval in approval_list:
            if not approval:
                continue
            
            approval_status = approval.get("approvalStatus") or {}
            review_info = approval.get("review") or {}
            
            # æå–ç”¨æˆ·ä¿¡æ¯ - æ£€æŸ¥æ‰€æœ‰å¯èƒ½çš„ç”¨æˆ·å­—æ®µ
            user_info = {}
            
            # æ£€æŸ¥å®¡æ‰¹çŠ¶æ€ä¸­çš„ç”¨æˆ·ä¿¡æ¯
            if "approvedBy" in approval:
                user_info["approved_by"] = approval.get("approvedBy") or {}
            if "reviewedBy" in approval:
                user_info["reviewed_by"] = approval.get("reviewedBy") or {}
            if "createdBy" in approval:
                user_info["created_by"] = approval.get("createdBy") or {}
            if "updatedBy" in approval:
                user_info["updated_by"] = approval.get("updatedBy") or {}
            if "assignedTo" in approval:
                user_info["assigned_to"] = approval.get("assignedTo") or {}
            
            # æ£€æŸ¥æ—¶é—´æˆ³ä¿¡æ¯
            timestamps = {}
            if "approvedAt" in approval:
                timestamps["approved_at"] = utils.format_timestamp(approval.get("approvedAt", ""))
            if "reviewedAt" in approval:
                timestamps["reviewed_at"] = utils.format_timestamp(approval.get("reviewedAt", ""))
            if "createdAt" in approval:
                timestamps["created_at"] = utils.format_timestamp(approval.get("createdAt", ""))
            if "updatedAt" in approval:
                timestamps["updated_at"] = utils.format_timestamp(approval.get("updatedAt", ""))
            
            # æ£€æŸ¥å®¡æ‰¹çŠ¶æ€ä¸­çš„ç”¨æˆ·ä¿¡æ¯
            if isinstance(approval_status, dict):
                if "approvedBy" in approval_status:
                    user_info["status_approved_by"] = approval_status.get("approvedBy") or {}
                if "assignedTo" in approval_status:
                    user_info["status_assigned_to"] = approval_status.get("assignedTo") or {}
            
            # æ£€æŸ¥è¯„å®¡ä¿¡æ¯ä¸­çš„ç”¨æˆ·ä¿¡æ¯
            if isinstance(review_info, dict):
                if "createdBy" in review_info:
                    user_info["review_created_by"] = review_info.get("createdBy") or {}
                if "assignedTo" in review_info:
                    user_info["review_assigned_to"] = review_info.get("assignedTo") or {}
                if "currentAssignee" in review_info:
                    user_info["current_assignee"] = review_info.get("currentAssignee") or {}
            
            analysis = {
                "approval_status": {
                    "id": approval_status.get("id", ""),
                    "label": approval_status.get("label", ""),
                    "value": approval_status.get("value", ""),
                    "status_type": get_approve_status_type(approval_status.get("value", ""))
                },
                "review": {
                    "id": review_info.get("id", ""),
                    "sequence_id": review_info.get("sequenceId", 0),
                    "status": review_info.get("status", ""),
                    "status_type": get_review_status_type(review_info.get("status", ""))
                },
                "user_info": user_info,
                "timestamps": timestamps,
                "has_user_info": len(user_info) > 0,
                "has_timestamps": len(timestamps) > 0,
                "is_in_review": review_info.get("status") == "OPEN",
                "is_finished": review_info.get("status") in ["CLOSED", "VOID"],
                "sequence_display": f"#{review_info.get('sequenceId', 0)}"
            }
            approval_analysis.append(analysis)
        
        # ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
        total_approvals = pagination.get('totalResults', len(approval_list))
        
        # æŒ‰çŠ¶æ€åˆ†ç»„ç»Ÿè®¡
        approval_status_counts = {}
        review_status_counts = {}
        in_review_count = 0
        finished_count = 0
        
        for approval in approval_analysis:
            # ç»Ÿè®¡å®¡æ‰¹çŠ¶æ€
            approval_label = approval["approval_status"]["label"]
            if approval_label:
                approval_status_counts[approval_label] = approval_status_counts.get(approval_label, 0) + 1
            
            # ç»Ÿè®¡è¯„å®¡çŠ¶æ€
            review_status = approval["review"]["status"]
            if review_status:
                review_status_counts[review_status] = review_status_counts.get(review_status, 0) + 1
            
            # ç»Ÿè®¡è¿›è¡Œä¸­å’Œå·²å®Œæˆ
            if approval["is_in_review"]:
                in_review_count += 1
            elif approval["is_finished"]:
                finished_count += 1
        
        # æŒ‰åºåˆ—IDæ’åºï¼ˆå€’åºï¼‰
        approval_analysis.sort(key=lambda x: x["review"]["sequence_id"], reverse=True)
        
        # åˆ†ç»„æ•°æ®
        in_review_approvals = [a for a in approval_analysis if a["is_in_review"]]
        finished_approvals = [a for a in approval_analysis if a["is_finished"]]
        
        stats = {
            "total_approvals": total_approvals,
            "current_page_count": len(approval_list),
            "approval_status_counts": approval_status_counts,
            "review_status_counts": review_status_counts,
            "in_review_count": in_review_count,
            "finished_count": finished_count,
            "latest_sequence_id": max([a["review"]["sequence_id"] for a in approval_analysis], default=0)
        }
        
        return jsonify({
            "success": True,
            "project_id": project_id,
            "version_id": version_id,
            "encoded_version_id": encoded_version_id,
            "query_params": params,
            "stats": stats,
            "approval_history": approval_analysis,
            "in_review_approvals": in_review_approvals,
            "finished_approvals": finished_approvals,
            "pagination": pagination,
            "raw_data": approval_list,
            "timestamp": datetime.now().isoformat()
        })
        
    except Exception as e:
        print(f"è·å–æ–‡ä»¶å®¡æ‰¹å†å²æ—¶å‡ºé”™: {str(e)}")
        return jsonify({
            "error": f"è·å–æ–‡ä»¶å®¡æ‰¹å†å²å¤±è´¥: {str(e)}",
            "status": "error"
        }), 500


def get_review_status_type(status_value):
    """è·å–è¯„å®¡çŠ¶æ€çš„ç±»å‹ç”¨äºUIæ˜¾ç¤º"""
    status_map = {
        'OPEN': 'success',
        'CLOSED': 'info',
        'VOID': 'warning'
    }
    return status_map.get(status_value, 'info')


@reviews_bp.route('/api/versions/jarvis/<path:version_id>/approval-statuses')
def get_jarvis_version_approval_statuses(version_id):
    """è·å– JARVIS é¡¹ç›®ä¸­æŒ‡å®šæ–‡ä»¶ç‰ˆæœ¬çš„å®¡æ‰¹å†å²"""
    return get_version_approval_statuses(config.JARVIS_PROJECT_ID, version_id)


