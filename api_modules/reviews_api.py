# -*- coding: utf-8 -*-
"""
Reviews API ç›¸å…³æ¨¡å—
å¤„ç† ACC Reviews API çš„æ‰€æœ‰åŠŸèƒ½ï¼ŒåŒ…æ‹¬å®¡æ‰¹å·¥ä½œæµå’Œè¯„å®¡æ•°æ®
"""

import requests
import json
from flask import Blueprint, jsonify, request
from datetime import datetime
import config
import utils
import threading
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from urllib.parse import unquote

reviews_bp = Blueprint('reviews', __name__)

# Reviews API ç›¸å…³åŠŸèƒ½å®ç°


def _normalize_file_identifier(file_id):
    """æ ‡å‡†åŒ–æ–‡ä»¶æ ‡è¯†ç¬¦ï¼Œå¤„ç†URLç¼–ç ç­‰"""
    if not file_id:
        return ""
    
    # URLè§£ç 
    decoded_id = unquote(file_id)
    
    # ç§»é™¤å¯èƒ½çš„å‰ç¼€
    if decoded_id.startswith('urn:'):
        return decoded_id
    
    return decoded_id


def _analyze_reviewer_types(claimed_by, candidates):
    """
    åˆ†æå®¡é˜…è€…ç±»å‹ï¼ŒåŒºåˆ†ä¸»è¦å®¡é˜…è€…å’Œå¯é€‰å®¡é˜…è€…
    
    Args:
        claimed_by: å·²è®¤é¢†çš„ç”¨æˆ·åˆ—è¡¨
        candidates: å€™é€‰è€…å­—å…¸ï¼ŒåŒ…å« users, roles, companies
    
    Returns:
        dict: åŒ…å«ä¸»è¦å®¡é˜…è€…å’Œå¯é€‰å®¡é˜…è€…ä¿¡æ¯çš„å­—å…¸
    """
    # æå–å€™é€‰ç”¨æˆ·ã€è§’è‰²å’Œå…¬å¸
    candidate_users = candidates.get("users", []) if candidates else []
    candidate_roles = candidates.get("roles", []) if candidates else []
    candidate_companies = candidates.get("companies", []) if candidates else []
    
    # ä¸»è¦å®¡é˜…è€… = å·²è®¤é¢†çš„ç”¨æˆ·
    primary_reviewers = claimed_by or []
    
    # å¯é€‰å®¡é˜…è€… = å°šæœªè®¤é¢†çš„å€™é€‰è€…
    optional_reviewers = {
        "users": candidate_users,
        "roles": candidate_roles, 
        "companies": candidate_companies
    }
    
    # è®¡ç®—æ€»æ•°
    total_primary = len(primary_reviewers)
    total_optional = len(candidate_users) + len(candidate_roles) + len(candidate_companies)
    
    # åˆ¤æ–­å®¡é˜…æ¨¡å¼
    if total_primary > 0 and total_optional > 0:
        review_mode = "mixed"  # æ··åˆæ¨¡å¼ï¼šæ—¢æœ‰ä¸»è¦å®¡é˜…è€…ï¼Œä¹Ÿæœ‰å¯é€‰å®¡é˜…è€…
    elif total_primary > 0:
        review_mode = "primary_only"  # ä»…ä¸»è¦å®¡é˜…è€…
    elif total_optional > 0:
        review_mode = "optional_only"  # ä»…å¯é€‰å®¡é˜…è€…
    else:
        review_mode = "none"  # æ— å®¡é˜…è€…
    
    return {
        "primary_reviewers": primary_reviewers,
        "optional_reviewers": optional_reviewers,
        "counts": {
            "primary_total": total_primary,
            "optional_users": len(candidate_users),
            "optional_roles": len(candidate_roles),
            "optional_companies": len(candidate_companies),
            "optional_total": total_optional,
            "total_reviewers": total_primary + total_optional
        },
        "review_mode": review_mode,
        "has_primary_reviewers": total_primary > 0,
        "has_optional_reviewers": total_optional > 0,
        "is_multi_reviewer": (total_primary + total_optional) > 1,
        "assignment_details": {
            "has_direct_users": len(candidate_users) > 0,
            "has_roles": len(candidate_roles) > 0,
            "has_companies": len(candidate_companies) > 0,
            "role_names": [r.get("name", "Unknown Role") for r in candidate_roles],
            "company_names": [c.get("name", "Unknown Company") for c in candidate_companies]
        }
    }


def _analyze_group_review_config(group_review_config):
    """
    åˆ†æå·¥ä½œæµæ­¥éª¤çš„ç»„å®¡é˜…é…ç½®
    
    Args:
        group_review_config: ç»„å®¡é˜…é…ç½®å­—å…¸
    
    Returns:
        dict: åŒ…å«ç»„å®¡é˜…é…ç½®åˆ†æçš„å­—å…¸
    """
    if not group_review_config:
        return {
            "enabled": False,
            "type": "single",
            "description": "Single reviewer mode",
            "min_reviewers": 1,
            "is_multi_reviewer_step": False
        }
    
    enabled = group_review_config.get("enabled", False)
    review_type = group_review_config.get("type", "ALL")
    min_reviewers = group_review_config.get("min", 1)
    
    # æ ¹æ®ç±»å‹ç”Ÿæˆæè¿°
    type_descriptions = {
        "ALL": "All reviewers must review",
        "ANY": "Any reviewer can approve",
        "MAJORITY": "Majority of reviewers must approve"
    }
    
    description = type_descriptions.get(review_type, f"Unknown review type: {review_type}")
    
    # å¦‚æœå¯ç”¨äº†ç»„å®¡é˜…ä½†ç±»å‹æ˜¯ALLï¼Œä¸”æœ€å°æ•°é‡å¤§äº1ï¼Œåˆ™æ˜¯å¤šå®¡é˜…è€…å¿…é¡»æ¨¡å¼
    if enabled and review_type == "ALL" and min_reviewers > 1:
        description = f"At least {min_reviewers} reviewers must all agree"
    elif enabled and review_type == "ANY":
        description = f"At least any one of {min_reviewers} reviewers must agree"
    elif enabled and review_type == "MAJORITY":
        description = f"Majority of reviewers must agree (minimum {min_reviewers})"
    
    return {
        "enabled": enabled,
        "type": review_type,
        "description": description,
        "min_reviewers": min_reviewers,
        "is_multi_reviewer_step": enabled and min_reviewers > 1,
        "review_strategy": {
            "requires_all": review_type == "ALL",
            "requires_any": review_type == "ANY", 
            "requires_majority": review_type == "MAJORITY"
        }
    }


def _analyze_workflow_step_reviewer_types(step):
    """
    åˆ†æå·¥ä½œæµæ­¥éª¤çš„å®¡é˜…è€…ç±»å‹ï¼ˆåŸºäºå·¥ä½œæµå®šä¹‰ï¼Œä¸å±•å¼€å…·ä½“ç”¨æˆ·ï¼‰
    
    Args:
        step: å·¥ä½œæµæ­¥éª¤æ•°æ®
    
    Returns:
        dict: åŒ…å«å®¡é˜…è€…ç±»å‹åˆ†æçš„å­—å…¸
    """
    if not step:
        return {
            "has_reviewers": False,
            "reviewer_types": [],
            "total_potential_reviewers": 0,
            "is_multi_reviewer": False,
            "assignment_mode": "none"
        }
    
    candidates = step.get("candidates", {})
    users = candidates.get("users", [])
    roles = candidates.get("roles", [])
    companies = candidates.get("companies", [])
    
    # åˆ†æå®¡é˜…è€…ç±»å‹
    reviewer_types = []
    if users:
        reviewer_types.append({
            "type": "direct_users",
            "count": len(users),
            "items": [{"id": u.get("id"), "name": u.get("name", "Unknown User")} for u in users]
        })
    
    if roles:
        reviewer_types.append({
            "type": "roles",
            "count": len(roles),
            "items": [{"id": r.get("id"), "name": r.get("name", "Unknown Role")} for r in roles]
        })
    
    if companies:
        reviewer_types.append({
            "type": "companies", 
            "count": len(companies),
            "items": [{"id": c.get("id"), "name": c.get("name", "Unknown Company")} for c in companies]
        })
    
    # è®¡ç®—æ½œåœ¨å®¡é˜…è€…æ€»æ•°ï¼ˆæ³¨æ„ï¼šè§’è‰²å’Œå…¬å¸å¯èƒ½åŒ…å«å¤šä¸ªç”¨æˆ·ï¼‰
    total_potential = len(users)  # ç›´æ¥ç”¨æˆ·æ•°é‡ç¡®å®š
    if roles:
        total_potential += len(roles)  # è§’è‰²æ•°é‡ï¼ˆæ¯ä¸ªè§’è‰²å¯èƒ½æœ‰å¤šä¸ªç”¨æˆ·ï¼‰
    if companies:
        total_potential += len(companies)  # å…¬å¸æ•°é‡ï¼ˆæ¯ä¸ªå…¬å¸å¯èƒ½æœ‰å¤šä¸ªç”¨æˆ·ï¼‰
    
    # åˆ¤æ–­åˆ†é…æ¨¡å¼
    if len(reviewer_types) == 0:
        assignment_mode = "none"
    elif len(reviewer_types) == 1 and reviewer_types[0]["type"] == "direct_users" and reviewer_types[0]["count"] == 1:
        assignment_mode = "single_user"
    elif len(reviewer_types) == 1 and reviewer_types[0]["type"] == "direct_users":
        assignment_mode = "multiple_users"
    elif any(rt["type"] in ["roles", "companies"] for rt in reviewer_types):
        assignment_mode = "role_or_company_based"
    else:
        assignment_mode = "mixed"
    
    # æ£€æŸ¥ç»„å®¡é˜…é…ç½®
    group_review = step.get("groupReview", {})
    is_group_review = group_review.get("enabled", False)
    
    return {
        "has_reviewers": total_potential > 0,
        "reviewer_types": reviewer_types,
        "total_potential_reviewers": total_potential,
        "is_multi_reviewer": total_potential > 1 or is_group_review,
        "assignment_mode": assignment_mode,
        "group_review_enabled": is_group_review,
        "step_type": step.get("type", "UNKNOWN"),
        "summary": {
            "direct_users": len(users),
            "roles": len(roles),
            "companies": len(companies),
            "needs_role_expansion": len(roles) > 0,
            "needs_company_expansion": len(companies) > 0
        }
    }




def _is_file_match(version, file_id):
    """æ”¹è¿›çš„æ–‡ä»¶åŒ¹é…é€»è¾‘ï¼Œä½¿ç”¨ç²¾ç¡®åŒ¹é…"""
    if not version or not file_id:
        return False
    
    # æ ‡å‡†åŒ–æ–‡ä»¶ID
    normalized_file_id = _normalize_file_identifier(file_id)
    
    # è·å–ç‰ˆæœ¬ä¿¡æ¯
    version_urn = version.get("urn", "")
    version_item_urn = version.get("itemUrn", "")
    version_name = version.get("name", "")
    
    # ç²¾ç¡®åŒ¹é…ç­–ç•¥
    matches = [
        # 1. ç²¾ç¡®URNåŒ¹é…
        version_urn == normalized_file_id,
        version_urn == file_id,
        
        # 2. ItemURNåŒ¹é…
        version_item_urn == normalized_file_id,
        version_item_urn == file_id,
        
        # 3. æ–‡ä»¶åç²¾ç¡®åŒ¹é…
        version_name == normalized_file_id,
        version_name == file_id,
        
        # 4. å¦‚æœæ–‡ä»¶IDçœ‹èµ·æ¥åƒæ–‡ä»¶åï¼Œè¿›è¡Œæ–‡ä»¶ååŒ¹é…
        version_name and not file_id.startswith('urn:') and version_name.lower() == file_id.lower()
    ]
    
    return any(matches)


def _check_review_for_file(review, file_id, project_id, headers):
    """æ£€æŸ¥å•ä¸ªè¯„å®¡æ˜¯å¦åŒ…å«æŒ‡å®šæ–‡ä»¶ï¼Œå¹¶è¿”å›åŒ¹é…çš„æ–‡ä»¶ç‰ˆæœ¬ä¿¡æ¯"""
    try:
        review_id = review.get('id')
        if not review_id:
            return None
        
        # è·å–è¯„å®¡çš„æ–‡ä»¶ç‰ˆæœ¬
        versions_url = f"{config.AUTODESK_API_BASE}/construction/reviews/v1/projects/{project_id}/reviews/{review_id}/versions"
        versions_response = requests.get(versions_url, headers=headers, timeout=10)
        
        if versions_response.status_code != 200:
            print(f"âš ï¸ æ— æ³•è·å–è¯„å®¡ {review_id} çš„æ–‡ä»¶ç‰ˆæœ¬: {versions_response.status_code}")
            return None
        
        versions_data = versions_response.json()
        versions = versions_data.get("results", [])
        
        # ä½¿ç”¨æ”¹è¿›çš„åŒ¹é…é€»è¾‘ï¼ŒåŒæ—¶è¿”å›åŒ¹é…çš„æ–‡ä»¶ç‰ˆæœ¬ä¿¡æ¯
        for version in versions:
            if _is_file_match(version, file_id):
                print(f"âœ… åœ¨è¯„å®¡ {review_id} ä¸­æ‰¾åˆ°åŒ¹é…æ–‡ä»¶: {version.get('name', 'Unknown')}")
                # è¿”å›reviewå’ŒåŒ¹é…çš„ç‰ˆæœ¬ä¿¡æ¯ï¼Œé¿å…é‡å¤APIè°ƒç”¨
                return {
                    'review': review,
                    'matched_version': version,
                    'all_versions': versions
                }
        
        return None
        
    except Exception as e:
        print(f"âŒ æ£€æŸ¥è¯„å®¡ {review.get('id', 'unknown')} æ—¶å‡ºé”™: {str(e)}")
        return None


def _check_review_contains_file(review, filter_file_urn, filter_file_name, project_id, headers):
    """æ£€æŸ¥è¯„å®¡æ˜¯å¦åŒ…å«æŒ‡å®šçš„æ–‡ä»¶ï¼ˆç”¨äºè¿‡æ»¤ï¼‰"""
    try:
        review_id = review.get('id')
        if not review_id:
            return False
        
        # è·å–è¯„å®¡çš„æ–‡ä»¶ç‰ˆæœ¬
        versions_url = f"{config.AUTODESK_API_BASE}/construction/reviews/v1/projects/{project_id}/reviews/{review_id}/versions"
        versions_response = requests.get(versions_url, headers=headers, timeout=10)
        
        if versions_response.status_code != 200:
            return False
        
        versions_data = versions_response.json()
        versions = versions_data.get("results", [])
        
        # æ£€æŸ¥æ˜¯å¦æœ‰åŒ¹é…çš„æ–‡ä»¶
        for version in versions:
            if not version:
                continue
            
            # æ–‡ä»¶URNåŒ¹é…
            if filter_file_urn and _is_file_match(version, filter_file_urn):
                return True
            
            # æ–‡ä»¶ååŒ¹é…
            if filter_file_name:
                version_name = version.get("name", "")
                if version_name and filter_file_name.lower() in version_name.lower():
                    return True
        
        return False
        
    except Exception as e:
        print(f"âŒ æ£€æŸ¥è¯„å®¡ {review.get('id', 'unknown')} æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
        return False


def get_workflow_step_info(project_id, workflow_id, current_step_id, access_token, review_status=None):
    """è·å–å·¥ä½œæµæ­¥éª¤ä¿¡æ¯ï¼Œè®¡ç®—å½“å‰æ­¥éª¤è¿›åº¦"""
    if not workflow_id:
        return {
            "current_step_number": 0,
            "total_steps": 0,
            "current_step_name": "",
            "progress_percentage": 0,
            "step_progress_text": "No workflow",
            "final_status": "unknown",
            "is_completed": False,
            "is_rejected": False
        }
    
    try:
        headers = {
            "Authorization": f"Bearer {access_token}",
            "Content-Type": "application/json"
        }
        
        # è½¬æ¢é¡¹ç›®IDæ ¼å¼ï¼ˆç§»é™¤ 'b.' å‰ç¼€ï¼‰
        from api_modules.submittal_api import convert_project_id
        clean_project_id = convert_project_id(project_id)
        
        # è·å–å·¥ä½œæµè¯¦ç»†ä¿¡æ¯
        workflow_url = f"{config.AUTODESK_API_BASE}/construction/reviews/v1/projects/{clean_project_id}/workflows/{workflow_id}"
        workflow_resp = requests.get(workflow_url, headers=headers)
        
        if workflow_resp.status_code != 200:
            print(f"Failed to get workflow details: {workflow_resp.status_code}")
            return {
                "current_step_number": 0,
                "total_steps": 0,
                "current_step_name": "",
                "progress_percentage": 0,
                "step_progress_text": "Cannot get workflow info",
                "final_status": "error",
                "is_completed": False,
                "is_rejected": False
            }
        
        workflow_data = workflow_resp.json()
        
        # å¤„ç†å·¥ä½œæµæ•°æ®
        steps = workflow_data.get("steps", [])
        total_steps = len(steps)
        
        if total_steps == 0:
            return {
                "current_step_number": 0,
                "total_steps": 0,
                "current_step_name": "",
                "progress_percentage": 0,
                "step_progress_text": "Workflow has no steps",
                "final_status": "empty",
                "is_completed": False,
                "is_rejected": False
            }
        
        # åˆ†æè¯„å®¡çŠ¶æ€å’Œæœ€ç»ˆçŠ¶æ€
        is_completed = review_status in ['CLOSED', 'VOID']
        is_rejected = review_status == 'VOID'
        is_approved = review_status == 'CLOSED'
        
        # æŸ¥æ‰¾å½“å‰æ­¥éª¤
        current_step_number = 0
        current_step_name = ""
        
        for i, step in enumerate(steps):
            if step and step.get("id") == current_step_id:
                current_step_number = i + 1
                current_step_name = step.get("name", f"Step {i + 1}")
                break
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„æ­¥éª¤IDï¼Œå¯èƒ½æ˜¯å·²å®Œæˆæˆ–å…¶ä»–çŠ¶æ€
        if current_step_number == 0:
            if is_completed:
                # æ ¹æ®è¯„å®¡çŠ¶æ€ç¡®å®šæœ€ç»ˆçŠ¶æ€
                if is_rejected:
                    final_status = "rejected"
                    progress_text = f"Rejected ({total_steps}/{total_steps})"
                    current_step_name = "Rejected"
                elif is_approved:
                    final_status = "approved"
                    progress_text = f"Approved ({total_steps}/{total_steps})"
                    current_step_name = "Approved"
                else:
                    final_status = "completed"
                    progress_text = f"Completed ({total_steps}/{total_steps})"
                    current_step_name = "Completed"
                
                return {
                    "current_step_number": total_steps,
                    "total_steps": total_steps,
                    "current_step_name": current_step_name,
                    "progress_percentage": 100,
                    "step_progress_text": progress_text,
                    "final_status": final_status,
                    "is_completed": True,
                    "is_rejected": is_rejected
                }
            else:
                # æœªæ‰¾åˆ°å½“å‰æ­¥éª¤ï¼Œå¯èƒ½æ˜¯æ•°æ®é—®é¢˜
                return {
                    "current_step_number": 0,
                    "total_steps": total_steps,
                    "current_step_name": "Unknown",
                    "progress_percentage": 0,
                    "step_progress_text": "Unknown progress",
                    "final_status": "unknown",
                    "is_completed": False,
                    "is_rejected": False
                }
        
        # è®¡ç®—è¿›åº¦ç™¾åˆ†æ¯”
        if is_completed:
            progress_percentage = 100
            if is_rejected:
                final_status = "rejected"
                progress_text = f"Rejected ({total_steps}/{total_steps})"
            elif is_approved:
                final_status = "approved"
                progress_text = f"Approved ({total_steps}/{total_steps})"
            else:
                final_status = "completed"
                progress_text = f"Completed ({total_steps}/{total_steps})"
        else:
            progress_percentage = round((current_step_number / total_steps) * 100, 1)
            final_status = "in_progress"
            progress_text = f"Step {current_step_number} / {total_steps} ({progress_percentage}%)"
        
        return {
            "current_step_number": current_step_number,
            "total_steps": total_steps,
            "current_step_name": current_step_name,
            "progress_percentage": progress_percentage,
            "step_progress_text": progress_text,
            "workflow_name": workflow_data.get("name", ""),
            "workflow_description": workflow_data.get("description", ""),
            "final_status": final_status,
            "is_completed": is_completed,
            "is_rejected": is_rejected
        }
        
    except Exception as e:
        print(f"Error getting workflow step info: {str(e)}")
        return {
            "current_step_number": 0,
            "total_steps": 0,
            "current_step_name": "",
            "progress_percentage": 0,
            "step_progress_text": f"Failed to get progress: {str(e)}",
            "final_status": "error",
            "is_completed": False,
            "is_rejected": False
        }




@reviews_bp.route('/api/reviews/<project_id>')
def get_project_reviews(project_id):
    """è·å–æŒ‡å®šé¡¹ç›®çš„è¯„å®¡åˆ—è¡¨"""
    access_token = utils.get_access_token()
    if not access_token:
        return jsonify({
            "error": "æœªæ‰¾åˆ° Access Tokenï¼Œè¯·å…ˆè¿›è¡Œè®¤è¯",
            "status": "unauthorized"
        }), 401
    
    headers = {
        "Authorization": f"Bearer {access_token}",
        "Content-Type": "application/json"
    }
    
    # è½¬æ¢é¡¹ç›®IDæ ¼å¼ï¼ˆç§»é™¤ 'b.' å‰ç¼€ï¼‰
    from api_modules.submittal_api import convert_project_id
    clean_project_id = convert_project_id(project_id)
    print(f"ğŸ”§ Reviews API: åŸå§‹é¡¹ç›®ID: {project_id}, è½¬æ¢å: {clean_project_id}")
    
    # è·å–æŸ¥è¯¢å‚æ•°
    limit = request.args.get('limit', 50, type=int)
    offset = request.args.get('offset', 0, type=int)
    sort = request.args.get('sort', '')
    
    # è¿‡æ»¤å‚æ•°
    filter_workflow_id = request.args.get('filter[workflowId]', '')
    filter_status = request.args.get('filter[status]', '')
    filter_current_step_due_date = request.args.get('filter[currentStepDueDate]', '')
    filter_created_at = request.args.get('filter[createdAt]', '')
    filter_updated_at = request.args.get('filter[updatedAt]', '')
    filter_finished_at = request.args.get('filter[finishedAt]', '')
    filter_next_action_by_user = request.args.get('filter[nextActionByUser]', '')
    filter_next_action_by_role = request.args.get('filter[nextActionByRole]', '')
    filter_next_action_by_company = request.args.get('filter[nextActionByCompany]', '')
    filter_name = request.args.get('filter[name]', '')
    filter_sequence_id = request.args.get('filter[sequenceId]', '')
    filter_archived = request.args.get('filter[archived]', '')
    filter_archived_by = request.args.get('filter[archivedBy]', '')
    filter_archived_at = request.args.get('filter[archivedAt]', '')
    
    # æ–°å¢ï¼šæ–‡ä»¶URNè¿‡æ»¤å‚æ•°ï¼ˆè‡ªå®šä¹‰å®ç°ï¼‰
    filter_file_urn = request.args.get('filter[fileUrn]', '')
    filter_file_name = request.args.get('filter[fileName]', '')
    
    # æ„å»ºæŸ¥è¯¢å‚æ•°
    params = {
        'limit': min(limit, 50),  # æœ€å¤§50
        'offset': offset
    }
    
    if sort:
        params['sort'] = sort
    if filter_workflow_id:
        params['filter[workflowId]'] = filter_workflow_id
    if filter_status:
        params['filter[status]'] = filter_status
    if filter_current_step_due_date:
        params['filter[currentStepDueDate]'] = filter_current_step_due_date
    if filter_created_at:
        params['filter[createdAt]'] = filter_created_at
    if filter_updated_at:
        params['filter[updatedAt]'] = filter_updated_at
    if filter_finished_at:
        params['filter[finishedAt]'] = filter_finished_at
    if filter_next_action_by_user:
        params['filter[nextActionByUser]'] = filter_next_action_by_user
    if filter_next_action_by_role:
        params['filter[nextActionByRole]'] = filter_next_action_by_role
    if filter_next_action_by_company:
        params['filter[nextActionByCompany]'] = filter_next_action_by_company
    if filter_name:
        params['filter[name]'] = filter_name
    if filter_sequence_id:
        params['filter[sequenceId]'] = filter_sequence_id
    if filter_archived:
        params['filter[archived]'] = filter_archived.lower() == 'true'
    if filter_archived_by:
        params['filter[archivedBy]'] = filter_archived_by
    if filter_archived_at:
        params['filter[archivedAt]'] = filter_archived_at
    
    try:
        # è°ƒç”¨ Autodesk Construction Cloud Reviews API
        reviews_url = f"{config.AUTODESK_API_BASE}/construction/reviews/v1/projects/{clean_project_id}/reviews"
        reviews_resp = requests.get(reviews_url, headers=headers, params=params)
        
        print(f"APIè¯·æ±‚URL: {reviews_url}")
        print(f"APIè¯·æ±‚å‚æ•°: {params}")
        print(f"APIå“åº”çŠ¶æ€ç : {reviews_resp.status_code}")
        
        if reviews_resp.status_code != 200:
            error_text = reviews_resp.text
            print(f"APIé”™è¯¯å“åº”: {error_text}")
            raise Exception(f"Failed to get review list: {reviews_resp.status_code} - {error_text}")
        
        try:
            reviews_data = reviews_resp.json()
            print(f"APIå“åº”æ•°æ®: {reviews_data}")  # è°ƒè¯•ä¿¡æ¯
            
            # è¯¦ç»†è°ƒè¯•å‰å‡ ä¸ªè¯„å®¡çš„IDä¿¡æ¯
            if reviews_data and reviews_data.get("results"):
                print(f"æ€»å…±è·å–åˆ° {len(reviews_data['results'])} ä¸ªè¯„å®¡")
                for i, review in enumerate(reviews_data["results"][:5]):  # åªæ‰“å°å‰5ä¸ª
                    if review:
                        print(f"è¯„å®¡ {i+1}: ID={review.get('id')}, sequenceId={review.get('sequenceId')}, name={review.get('name', '')[:50]}")
                        
        except json.JSONDecodeError as e:
            print(f"JSONè§£æé”™è¯¯: {e}")
            raise Exception(f"API response data format error: {str(e)}")
        
        if not reviews_data:
            print("APIè¿”å›ç©ºæ•°æ®")
            reviews_data = {"results": [], "pagination": {}}
            
        reviews_list = reviews_data.get("results", [])
        pagination = reviews_data.get("pagination", {})
        
        # ä½¿ç”¨sequenceIdä½œä¸ºä¸»è¦å»é‡æ ‡è¯†ï¼Œå› ä¸ºidå¯èƒ½ä¸å”¯ä¸€
        seen_ids = set()
        unique_reviews = []
        duplicate_count = 0
        
        for review in reviews_list:
            if not review:
                continue
                
            # ä¼˜å…ˆä½¿ç”¨sequenceIdï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨id
            review_unique_id = review.get("sequenceId") or review.get("id", "")
            if not review_unique_id:
                continue  # è·³è¿‡æ²¡æœ‰å”¯ä¸€æ ‡è¯†çš„è¯„å®¡
                
            if review_unique_id in seen_ids:
                duplicate_count += 1
                print(f"å‘ç°é‡å¤è¯„å®¡: sequenceId={review.get('sequenceId')}, id={review.get('id')}, name={review.get('name', '')[:50]}")
                continue  # è·³è¿‡é‡å¤çš„è¯„å®¡
            
            seen_ids.add(review_unique_id)
            unique_reviews.append(review)
        
        original_count = len(reviews_list)
        reviews_list = unique_reviews
        
        if duplicate_count > 0:
            print(f"å»é‡å®Œæˆ: åŸå§‹ {original_count} -> å»é‡å {len(reviews_list)} (ç§»é™¤ {duplicate_count} ä¸ªé‡å¤)")
            
        # è°ƒè¯•å»é‡åçš„è¯„å®¡ID
        print("å»é‡åçš„è¯„å®¡IDåˆ—è¡¨:")
        for i, review in enumerate(reviews_list[:5]):  # åªæ‰“å°å‰5ä¸ª
            if review:
                print(f"å»é‡åè¯„å®¡ {i+1}: ID={review.get('id')}, sequenceId={review.get('sequenceId')}, name={review.get('name', '')[:50]}")
        
        # æ–°å¢ï¼šæ–‡ä»¶è¿‡æ»¤é€»è¾‘
        if filter_file_urn or filter_file_name:
            print(f"ğŸ” åº”ç”¨æ–‡ä»¶è¿‡æ»¤: URN={filter_file_urn}, Name={filter_file_name}")
            filtered_reviews = []
            file_filter_start_time = time.time()
            
            # ä½¿ç”¨å¹¶è¡Œå¤„ç†æ¥åŠ é€Ÿæ–‡ä»¶è¿‡æ»¤
            max_workers = min(8, len(reviews_list))
            
            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                # ä¸ºæ¯ä¸ªè¯„å®¡æäº¤æ–‡ä»¶æ£€æŸ¥ä»»åŠ¡
                future_to_review = {}
                for review in reviews_list:
                    if review and review.get('id'):
                        future = executor.submit(_check_review_contains_file, 
                                               review, filter_file_urn, filter_file_name, 
                                               project_id, headers)
                        future_to_review[future] = review
                
                # æ”¶é›†è¿‡æ»¤ç»“æœ
                for future in as_completed(future_to_review):
                    try:
                        contains_file = future.result(timeout=10)
                        if contains_file:
                            review = future_to_review[future]
                            filtered_reviews.append(review)
                            print(f"âœ… è¯„å®¡ {review.get('id')} åŒ…å«ç›®æ ‡æ–‡ä»¶")
                    except Exception as e:
                        print(f"âŒ æ–‡ä»¶è¿‡æ»¤æ£€æŸ¥å‡ºé”™: {str(e)}")
                        continue
            
            file_filter_time = round(time.time() - file_filter_start_time, 2)
            print(f"ğŸ¯ æ–‡ä»¶è¿‡æ»¤å®Œæˆ: {len(reviews_list)} -> {len(filtered_reviews)} ä¸ªè¯„å®¡ï¼Œè€—æ—¶ {file_filter_time} ç§’")
            
            reviews_list = filtered_reviews
        
        # ç”Ÿæˆè¯„å®¡åˆ†ææ•°æ®
        reviews_analysis = []
        
        for review in reviews_list:
            if not review:  # è·³è¿‡ç©ºçš„reviewå¯¹è±¡
                continue
                
            # å®‰å…¨è·å–nextActionByæ•°æ®
            next_action_by = review.get("nextActionBy") or {}
            claimed_by = next_action_by.get("claimedBy") or []
            candidates = next_action_by.get("candidates") or {}
            
            # è·å–å·¥ä½œæµæ­¥éª¤è¿›åº¦ä¿¡æ¯
            workflow_id = review.get("workflowId", "")
            current_step_id = review.get("currentStepId", "")
            review_status = review.get("status", "")
            step_progress = get_workflow_step_info(project_id, workflow_id, current_step_id, access_token, review_status)
            
            # åˆ†æå®¡é˜…è€…ç±»å‹ï¼ˆä¸»è¦ vs å¯é€‰ï¼‰
            reviewer_analysis = _analyze_reviewer_types(claimed_by, candidates)
            
            # æå–è¯¦ç»†çš„å€™é€‰äººä¿¡æ¯
            candidate_details = {
                "users": [],
                "roles": [],
                "companies": [],
                "claimed_users": []
            }
            
            # å¤„ç†å·²è®¤é¢†ç”¨æˆ·
            for user in claimed_by:
                if user:
                    candidate_details["claimed_users"].append({
                        "id": user.get("id", ""),
                        "name": user.get("name", ""),
                        "email": user.get("email", ""),
                        "autodeskId": user.get("autodeskId", "")
                    })
            
            # å¤„ç†å€™é€‰ç”¨æˆ·
            for user in candidates.get("users", []):
                if user:
                    candidate_details["users"].append({
                        "id": user.get("id", ""),
                        "name": user.get("name", ""),
                        "email": user.get("email", ""),
                        "autodeskId": user.get("autodeskId", "")
                    })
            
            # å¤„ç†å€™é€‰è§’è‰²
            for role in candidates.get("roles", []):
                if role:
                    candidate_details["roles"].append({
                        "id": role.get("id", ""),
                        "name": role.get("name", ""),
                        "description": role.get("description", "")
                    })
            
            # å¤„ç†å€™é€‰å…¬å¸
            for company in candidates.get("companies", []):
                if company:
                    candidate_details["companies"].append({
                        "id": company.get("id", ""),
                        "name": company.get("name", ""),
                        "trade": company.get("trade", "")
                    })

            analysis = {
                "id": review.get("id", ""),
                "sequence_id": review.get("sequenceId", 0),
                "name": review.get("name", ""),
                "status": review.get("status", ""),
                "current_step_id": current_step_id,
                "current_step_due_date": utils.format_timestamp(review.get("currentStepDueDate", "")),
                "created_by": review.get("createdBy") or {},
                "created_at": utils.format_timestamp(review.get("createdAt", "")),
                "updated_at": utils.format_timestamp(review.get("updatedAt", "")),
                "finished_at": utils.format_timestamp(review.get("finishedAt", "")),
                "archived": review.get("archived", False),
                "archived_by": review.get("archivedBy") or {},
                "archived_at": utils.format_timestamp(review.get("archivedAt", "")),
                "workflow_id": workflow_id,
                "next_action_by": next_action_by,
                "has_claimed_users": len(claimed_by) > 0,
                "candidates_count": {
                    "roles": len(candidates.get("roles") or []),
                    "users": len(candidates.get("users") or []),
                    "companies": len(candidates.get("companies") or [])
                },
                # æ–°å¢ï¼šè¯¦ç»†çš„å€™é€‰äººä¿¡æ¯
                "candidate_details": candidate_details,
                # æ–°å¢ï¼šå®¡é˜…è€…ç±»å‹åˆ†æ
                "reviewer_analysis": reviewer_analysis,
                # æ–°å¢ï¼šå·¥ä½œæµæ­¥éª¤è¿›åº¦ä¿¡æ¯
                "workflow_progress": step_progress
            }
            reviews_analysis.append(analysis)
        
        # ç”Ÿæˆè¯¦ç»†çš„è¯„å®¡åˆ†æï¼ˆä½¿ç”¨å»é‡åçš„è¯„å®¡åˆ—è¡¨ï¼‰
        detailed_analysis = []
        for i, review in enumerate(reviews_list):
            if not review:  # è·³è¿‡ç©ºçš„reviewå¯¹è±¡
                continue
                
            # å®‰å…¨è·å–nextActionByæ•°æ®
            next_action_by = review.get('nextActionBy') or {}
            claimed_by = next_action_by.get('claimedBy') or []
            candidates = next_action_by.get('candidates') or {}
            
            # è·å–å·¥ä½œæµæ­¥éª¤è¿›åº¦ä¿¡æ¯
            workflow_id = review.get('workflowId', '')
            current_step_id = review.get('currentStepId', '')
            review_status = review.get('status', '')
            step_progress = get_workflow_step_info(project_id, workflow_id, current_step_id, access_token, review_status)
            
            # åˆ†æå®¡é˜…è€…ç±»å‹ï¼ˆä¸»è¦ vs å¯é€‰ï¼‰
            reviewer_analysis = _analyze_reviewer_types(claimed_by, candidates)
            
            review_analysis = {
                "review_number": i + 1,
                "basic_info": {
                    "id": review.get('id', 'N/A'),
                    "sequence_id": review.get('sequenceId', 'N/A'),
                    "name": review.get('name', 'N/A'),
                    "status": review.get('status', 'N/A'),
                    "workflow_id": workflow_id,
                    "created_at": utils.format_timestamp(review.get('createdAt', '')),
                    "updated_at": utils.format_timestamp(review.get('updatedAt', '')),
                    "finished_at": utils.format_timestamp(review.get('finishedAt', ''))
                },
                "review_summary": {
                    "current_step_id": current_step_id,
                    "current_step_due_date": utils.format_timestamp(review.get('currentStepDueDate', '')),
                    "archived": review.get('archived', False),
                    "has_claimed_users": len(claimed_by) > 0,
                    "total_candidates": (
                        len(candidates.get('roles') or []) +
                        len(candidates.get('users') or []) +
                        len(candidates.get('companies') or [])
                    )
                },
                "participants": {
                    "created_by": review.get('createdBy') or {},
                    "archived_by": review.get('archivedBy') or {},
                    "claimed_by": claimed_by,
                    "candidates": candidates
                },
                # æ–°å¢ï¼šå®¡é˜…è€…ç±»å‹åˆ†æ
                "reviewer_analysis": reviewer_analysis,
                # æ–°å¢ï¼šå·¥ä½œæµæ­¥éª¤è¿›åº¦ä¿¡æ¯
                "workflow_progress": step_progress
            }
            detailed_analysis.append(review_analysis)
        
        # ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
        total_reviews = pagination.get('totalResults', len(reviews_list))
        status_counts = {}
        for review in reviews_list:
            if review:  # ç¡®ä¿reviewä¸ä¸ºç©º
                status = review.get('status', 'UNKNOWN')
                status_counts[status] = status_counts.get(status, 0) + 1
        
        archived_count = len([r for r in reviews_list if r and r.get('archived', False)])
        
        # å®‰å…¨è®¡ç®—æœ‰è®¤é¢†ç”¨æˆ·çš„è¯„å®¡æ•°é‡
        with_claimed_users = 0
        total_candidates = 0
        
        for r in reviews_list:
            if r:  # ç¡®ä¿reviewä¸ä¸ºç©º
                next_action_by = r.get('nextActionBy') or {}
                claimed_by = next_action_by.get('claimedBy') or []
                if len(claimed_by) > 0:
                    with_claimed_users += 1
                
                # è®¡ç®—å€™é€‰è€…æ€»æ•°
                candidates = next_action_by.get('candidates') or {}
                total_candidates += (
                    len(candidates.get('users') or []) + 
                    len(candidates.get('roles') or []) + 
                    len(candidates.get('companies') or [])
                )
        
        stats = {
            "total_reviews": total_reviews,
            "current_page_count": len(reviews_list),
            "original_count": original_count,
            "duplicate_count": duplicate_count,
            "unique_count": len(reviews_list),
            "status_counts": status_counts,
            "archived_count": archived_count,
            "active_count": len(reviews_list) - archived_count,
            "with_claimed_users": with_claimed_users,
            "avg_candidates_per_review": round(total_candidates / len(reviews_list), 1) if reviews_list else 0
        }
        
        return jsonify({
            "success": True,
            "project_id": project_id,
            "query_params": params,
            "stats": stats,
            "reviews": reviews_analysis,
            "detailed_analysis": detailed_analysis,
            "pagination": pagination,
            "raw_data": reviews_list,
            "timestamp": datetime.now().isoformat()
        })
        
    except Exception as e:
        print(f"è·å–è¯„å®¡æ•°æ®æ—¶å‡ºé”™: {str(e)}")
        return jsonify({
            "error": f"è·å–è¯„å®¡æ•°æ®å¤±è´¥: {str(e)}",
            "status": "error"
        }), 500


@reviews_bp.route('/api/reviews/<project_id>/jarvis')
def get_jarvis_reviews(project_id=None):
    """è·å– isBIM JARVIS 2025 Dev é¡¹ç›®çš„è¯„å®¡æ•°æ®"""
    # å¦‚æœæ²¡æœ‰æä¾›project_idï¼Œä½¿ç”¨é»˜è®¤çš„JARVISé¡¹ç›®ID
    if not project_id:
        project_id = config.DEFAULT_PROJECT_ID
    
    return get_project_reviews(project_id)


@reviews_bp.route('/api/reviews/jarvis')
def get_jarvis_reviews_simple():
    """
    è·å–é¡¹ç›®çš„è¯„å®¡æ•°æ® - æ”¯æŒåŠ¨æ€é¡¹ç›®IDå’Œæ–‡ä»¶è¿‡æ»¤
    
    æ”¯æŒçš„æŸ¥è¯¢å‚æ•°ï¼š
    - projectId: é¡¹ç›®IDï¼ˆå¿…éœ€ï¼‰
    - filter[fileUrn]: æŒ‰æ–‡ä»¶URNè¿‡æ»¤è¯„å®¡
    - filter[fileName]: æŒ‰æ–‡ä»¶åè¿‡æ»¤è¯„å®¡
    - å…¶ä»–æ ‡å‡†è¿‡æ»¤å‚æ•°...
    
    ç¤ºä¾‹ï¼š
    - è·å–æ‰€æœ‰è¯„å®¡: /api/reviews/jarvis?projectId=xxx
    - æŒ‰æ–‡ä»¶URNè¿‡æ»¤: /api/reviews/jarvis?projectId=xxx&filter[fileUrn]=urn:adsk.wipprod:fs.file:vf.xxx
    - æŒ‰æ–‡ä»¶åè¿‡æ»¤: /api/reviews/jarvis?projectId=xxx&filter[fileName]=UserGuide.pdf
    """
    # è·å–é¡¹ç›®ID - å¿…é¡»é€šè¿‡å‚æ•°æä¾›
    project_id = request.args.get('projectId')
    
    if not project_id:
        return jsonify({
            "error": "ç¼ºå°‘å¿…éœ€çš„ projectId å‚æ•°",
            "message": "è¯·åœ¨è¯·æ±‚ä¸­æä¾› projectId å‚æ•°ï¼Œä¾‹å¦‚: ?projectId=your-project-id",
            "status": "error",
            "suggestion": "è¯·å…ˆé€‰æ‹©ä¸€ä¸ªé¡¹ç›®ï¼Œç„¶åé‡è¯•"
        }), 400
    
    print(f"ğŸš€ Reviews API: ä½¿ç”¨é¡¹ç›®ID: {project_id}")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰æ–‡ä»¶è¿‡æ»¤å‚æ•°
    filter_file_urn = request.args.get('filter[fileUrn]', '')
    filter_file_name = request.args.get('filter[fileName]', '')
    
    if filter_file_urn or filter_file_name:
        print(f"ğŸ” åº”ç”¨æ–‡ä»¶è¿‡æ»¤: URN={filter_file_urn}, Name={filter_file_name}")
    
    return get_project_reviews(project_id)


# ==================== å·¥ä½œæµç›¸å…³æ¥å£ ====================

@reviews_bp.route('/api/reviews/workflows/<project_id>')
def get_project_workflows(project_id):
    """è·å–æŒ‡å®šé¡¹ç›®çš„å®¡æ‰¹å·¥ä½œæµåˆ—è¡¨"""
    access_token = utils.get_access_token()
    if not access_token:
        return jsonify({
            "error": "æœªæ‰¾åˆ° Access Tokenï¼Œè¯·å…ˆè¿›è¡Œè®¤è¯",
            "status": "unauthorized"
        }), 401
    
    headers = {
        "Authorization": f"Bearer {access_token}",
        "Content-Type": "application/json"
    }
    
    # è½¬æ¢é¡¹ç›®IDæ ¼å¼ï¼ˆç§»é™¤ 'b.' å‰ç¼€ï¼‰
    from api_modules.submittal_api import convert_project_id
    clean_project_id = convert_project_id(project_id)
    print(f"ğŸ”§ Reviews API: åŸå§‹é¡¹ç›®ID: {project_id}, è½¬æ¢å: {clean_project_id}")
    
    # è·å–æŸ¥è¯¢å‚æ•°
    limit = request.args.get('limit', 50, type=int)
    offset = request.args.get('offset', 0, type=int)
    sort = request.args.get('sort', '')
    filter_initiator = request.args.get('filter[initiator]', '')
    filter_status = request.args.get('filter[status]', 'ACTIVE')
    
    # æ„å»ºæŸ¥è¯¢å‚æ•°
    params = {
        'limit': min(limit, 50),  # æœ€å¤§50
        'offset': offset
    }
    
    if sort:
        params['sort'] = sort
    if filter_initiator:
        params['filter[initiator]'] = filter_initiator.lower() == 'true'
    if filter_status:
        params['filter[status]'] = filter_status
    
    try:
        # è°ƒç”¨ Autodesk Construction Cloud Reviews API
        workflows_url = f"{config.AUTODESK_API_BASE}/construction/reviews/v1/projects/{clean_project_id}/workflows"
        workflows_resp = requests.get(workflows_url, headers=headers, params=params)
        
        if workflows_resp.status_code != 200:
            raise Exception(f"Failed to get workflow list: {workflows_resp.status_code} - {workflows_resp.text}")
        
        workflows_data = workflows_resp.json()
        workflows_list = workflows_data.get("results", [])
        pagination = workflows_data.get("pagination", {})
        
        # ç”Ÿæˆå·¥ä½œæµåˆ†ææ•°æ®
        workflows_analysis = []
        for workflow in workflows_list:
            analysis = {
                "id": workflow.get("id"),
                "name": workflow.get("name"),
                "description": workflow.get("description", ""),
                "notes": workflow.get("notes", ""),
                "status": workflow.get("status"),
                "created_at": utils.format_timestamp(workflow.get("createdAt", "")),
                "updated_at": utils.format_timestamp(workflow.get("updatedAt", "")),
                "steps_count": len(workflow.get("steps", [])),
                "approval_options_count": len(workflow.get("approvalStatusOptions", [])),
                "has_copy_files": workflow.get("copyFilesOptions", {}).get("enabled", False),
                "has_attached_attributes": len(workflow.get("attachedAttributes", [])) > 0,
                "additional_options": workflow.get("additionalOptions", {}),
                "steps": workflow.get("steps", []),
                "approval_status_options": workflow.get("approvalStatusOptions", []),
                "copy_files_options": workflow.get("copyFilesOptions", {}),
                "attached_attributes": workflow.get("attachedAttributes", []),
                "update_attributes_options": workflow.get("updateAttributesOptions", {})
            }
            workflows_analysis.append(analysis)
        
        # ç”Ÿæˆè¯¦ç»†çš„å·¥ä½œæµæ­¥éª¤åˆ†æ
        detailed_analysis = []
        for i, workflow in enumerate(workflows_list):
            workflow_analysis = {
                "workflow_number": i + 1,
                "basic_info": {
                    "id": workflow.get('id', 'N/A'),
                    "name": workflow.get('name', 'N/A'),
                    "description": workflow.get('description', 'N/A'),
                    "status": workflow.get('status', 'N/A'),
                    "created_at": utils.format_timestamp(workflow.get('createdAt', '')),
                    "updated_at": utils.format_timestamp(workflow.get('updatedAt', '')),
                    "notes": workflow.get('notes', 'N/A')
                },
                "workflow_summary": {
                    "steps_count": len(workflow.get('steps', [])),
                    "approval_options_count": len(workflow.get('approvalStatusOptions', [])),
                    "has_copy_files": workflow.get('copyFilesOptions', {}).get('enabled', False),
                    "has_attached_attributes": len(workflow.get('attachedAttributes', [])) > 0,
                    "allow_initiator_edit": workflow.get('additionalOptions', {}).get('allowInitiatorToEdit', False)
                },
                "detailed_steps": []
            }
            
            # åˆ†æå·¥ä½œæµæ­¥éª¤
            steps = workflow.get("steps", [])
            if steps:
                for step_idx, step in enumerate(steps):
                    step_detail = {
                        "step_number": step_idx + 1,
                        "name": step.get('name', 'N/A'),
                        "type": step.get('type', 'N/A'),
                        "duration": step.get('duration', 0),
                        "due_date_type": step.get('dueDateType', 'N/A'),
                        "group_review": step.get('groupReview', {}),
                        "group_review_analysis": _analyze_group_review_config(step.get('groupReview', {})),
                        "candidates": {
                            "roles_count": len(step.get('candidates', {}).get('roles', [])),
                            "users_count": len(step.get('candidates', {}).get('users', [])),
                            "companies_count": len(step.get('candidates', {}).get('companies', [])),
                            "roles": step.get('candidates', {}).get('roles', []),
                            "users": step.get('candidates', {}).get('users', []),
                            "companies": step.get('candidates', {}).get('companies', [])
                        },
                        # æ·»åŠ å®¡é˜…è€…ç±»å‹åˆ†æï¼ˆåŸºäºå·¥ä½œæµå®šä¹‰ï¼‰
                        "reviewer_type_analysis": _analyze_workflow_step_reviewer_types(step)
                    }
                    workflow_analysis["detailed_steps"].append(step_detail)
            
            detailed_analysis.append(workflow_analysis)
        
        # ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
        total_workflows = pagination.get('totalResults', len(workflows_list))
        active_workflows = len([w for w in workflows_list if w.get('status') == 'ACTIVE'])
        inactive_workflows = len([w for w in workflows_list if w.get('status') == 'INACTIVE'])
        
        stats = {
            "total_workflows": total_workflows,
            "current_page_count": len(workflows_list),
            "active_workflows": active_workflows,
            "inactive_workflows": inactive_workflows,
            "avg_steps_per_workflow": round(sum(len(w.get('steps', [])) for w in workflows_list) / len(workflows_list), 1) if workflows_list else 0,
            "workflows_with_copy_files": len([w for w in workflows_list if w.get('copyFilesOptions', {}).get('enabled', False)]),
            "workflows_with_attributes": len([w for w in workflows_list if w.get('attachedAttributes')])
        }
        
        return jsonify({
            "success": True,
            "project_id": project_id,
            "query_params": params,
            "stats": stats,
            "workflows": workflows_analysis,
            "detailed_analysis": detailed_analysis,
            "pagination": pagination,
            "raw_data": workflows_list,
            "timestamp": datetime.now().isoformat()
        })
        
    except Exception as e:
        print(f"è·å–å·¥ä½œæµæ•°æ®æ—¶å‡ºé”™: {str(e)}")
        return jsonify({
            "error": f"è·å–å·¥ä½œæµæ•°æ®å¤±è´¥: {str(e)}",
            "status": "error"
        }), 500


@reviews_bp.route('/api/reviews/workflows/<project_id>/jarvis')
def get_jarvis_workflows(project_id=None):
    """è·å– isBIM JARVIS 2025 Dev é¡¹ç›®çš„å®¡æ‰¹å·¥ä½œæµæ•°æ®"""
    # å¦‚æœæ²¡æœ‰æä¾›project_idï¼Œä½¿ç”¨é»˜è®¤çš„JARVISé¡¹ç›®ID
    if not project_id:
        project_id = config.DEFAULT_PROJECT_ID
    
    return get_project_workflows(project_id)


@reviews_bp.route('/api/reviews/workflows/jarvis')
def get_jarvis_workflows_simple():
    """è·å–é¡¹ç›®çš„å®¡æ‰¹å·¥ä½œæµæ•°æ® - æ”¯æŒåŠ¨æ€é¡¹ç›®ID"""
    # è·å–é¡¹ç›®ID - å¿…é¡»é€šè¿‡å‚æ•°æä¾›
    project_id = request.args.get('projectId')
    
    if not project_id:
        return jsonify({
            "error": "ç¼ºå°‘å¿…éœ€çš„ projectId å‚æ•°",
            "message": "è¯·åœ¨è¯·æ±‚ä¸­æä¾› projectId å‚æ•°ï¼Œä¾‹å¦‚: ?projectId=your-project-id",
            "status": "error",
            "suggestion": "è¯·å…ˆé€‰æ‹©ä¸€ä¸ªé¡¹ç›®ï¼Œç„¶åé‡è¯•"
        }), 400
    print(f"ğŸš€ Workflows API: ä½¿ç”¨é¡¹ç›®ID: {project_id}")
    
    return get_project_workflows(project_id)


# ==================== å•ä¸ªè¯„å®¡å·¥ä½œæµæ¥å£ ====================

@reviews_bp.route('/api/reviews/<project_id>/<review_id>/workflow')
def get_review_workflow(project_id, review_id):
    """è·å–æŒ‡å®šè¯„å®¡çš„å…³è”å·¥ä½œæµ"""
    access_token = utils.get_access_token()
    if not access_token:
        return jsonify({
            "error": "æœªæ‰¾åˆ° Access Tokenï¼Œè¯·å…ˆè¿›è¡Œè®¤è¯",
            "status": "unauthorized"
        }), 401
    
    headers = {
        "Authorization": f"Bearer {access_token}",
        "Content-Type": "application/json"
    }
    
    try:
        # è°ƒç”¨ Autodesk Construction Cloud Reviews API
        workflow_url = f"{config.AUTODESK_API_BASE}/construction/reviews/v1/projects/{project_id}/reviews/{review_id}/workflow"
        
        print(f"APIè¯·æ±‚URL: {workflow_url}")
        print(f"APIè¯·æ±‚å¤´: {headers}")
        
        workflow_resp = requests.get(workflow_url, headers=headers)
        
        print(f"APIå“åº”çŠ¶æ€ç : {workflow_resp.status_code}")
        
        if workflow_resp.status_code != 200:
            error_text = workflow_resp.text
            print(f"APIé”™è¯¯å“åº”: {error_text}")
            raise Exception(f"Failed to get review workflow: {workflow_resp.status_code} - {error_text}")
        
        try:
            workflow_data = workflow_resp.json()
            print(f"APIå“åº”æ•°æ®: {workflow_data}")
        except json.JSONDecodeError as e:
            print(f"JSONè§£æé”™è¯¯: {e}")
            raise Exception(f"API response data format error: {str(e)}")
        
        if not workflow_data:
            print("APIè¿”å›ç©ºå·¥ä½œæµæ•°æ®")
            workflow_data = {}
        
        # ç”Ÿæˆå·¥ä½œæµåˆ†ææ•°æ®
        workflow_analysis = {
            "id": workflow_data.get("id", ""),
            "name": workflow_data.get("name", ""),
            "description": workflow_data.get("description", ""),
            "notes": workflow_data.get("notes", ""),
            "additional_options": workflow_data.get("additionalOptions") or {},
            "steps": workflow_data.get("steps") or [],
            "approval_status_options": workflow_data.get("approvalStatusOptions") or [],
            "copy_files_options": workflow_data.get("copyFilesOptions") or {},
            "attached_attributes": workflow_data.get("attachedAttributes") or [],
            "update_attributes_options": workflow_data.get("updateAttributesOptions") or {},
            # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
            "steps_count": len(workflow_data.get("steps", [])),
            "approval_options_count": len(workflow_data.get("approvalStatusOptions", [])),
            "has_copy_files": workflow_data.get("copyFilesOptions", {}).get("enabled", False),
            "has_attached_attributes": len(workflow_data.get("attachedAttributes", [])) > 0,
            "allow_initiator_edit": workflow_data.get("additionalOptions", {}).get("allowInitiatorToEdit", False)
        }
        
        # ç”Ÿæˆè¯¦ç»†çš„æ­¥éª¤åˆ†æ
        detailed_steps = []
        steps = workflow_data.get("steps", [])
        for step_idx, step in enumerate(steps):
            if not step:
                continue
                
            candidates = step.get("candidates") or {}
            step_detail = {
                "step_number": step_idx + 1,
                "id": step.get("id", ""),
                "name": step.get("name", ""),
                "type": step.get("type", ""),
                "duration": step.get("duration", 0),
                "due_date_type": step.get("dueDateType", ""),
                "group_review": step.get("groupReview") or {},
                "group_review_analysis": _analyze_group_review_config(step.get("groupReview") or {}),
                "candidates": {
                    "roles": candidates.get("roles") or [],
                    "users": candidates.get("users") or [],
                    "companies": candidates.get("companies") or [],
                    "roles_count": len(candidates.get("roles") or []),
                    "users_count": len(candidates.get("users") or []),
                    "companies_count": len(candidates.get("companies") or [])
                },
                # æ·»åŠ å®¡é˜…è€…ç±»å‹åˆ†æï¼ˆåŸºäºå·¥ä½œæµå®šä¹‰ï¼‰
                "reviewer_type_analysis": _analyze_workflow_step_reviewer_types(step)
            }
            detailed_steps.append(step_detail)
        
        # ç”Ÿæˆå®¡æ‰¹çŠ¶æ€é€‰é¡¹åˆ†æ
        approval_options_analysis = []
        for option in workflow_data.get("approvalStatusOptions", []):
            if not option:
                continue
            option_analysis = {
                "id": option.get("id", ""),
                "label": option.get("label", ""),
                "value": option.get("value", ""),
                "built_in": option.get("builtIn", False)
            }
            approval_options_analysis.append(option_analysis)
        
        return jsonify({
            "success": True,
            "project_id": project_id,
            "review_id": review_id,
            "workflow": workflow_analysis,
            "detailed_steps": detailed_steps,
            "approval_options": approval_options_analysis,
            "raw_data": workflow_data,
            "timestamp": datetime.now().isoformat()
        })
        
    except Exception as e:
        print(f"è·å–è¯„å®¡å·¥ä½œæµæ—¶å‡ºé”™: {str(e)}")
        return jsonify({
            "error": f"è·å–è¯„å®¡å·¥ä½œæµå¤±è´¥: {str(e)}",
            "status": "error"
        }), 500


@reviews_bp.route('/api/reviews/jarvis/<review_id>/workflow')
def get_jarvis_review_workflow(review_id):
    """è·å–æŒ‡å®šé¡¹ç›®ä¸­æŒ‡å®šè¯„å®¡çš„å·¥ä½œæµ"""
    project_id = request.args.get('projectId')
    
    if not project_id:
        return jsonify({
            "error": "ç¼ºå°‘å¿…éœ€çš„ projectId å‚æ•°",
            "message": "è¯·åœ¨è¯·æ±‚ä¸­æä¾› projectId å‚æ•°",
            "status": "error"
        }), 400
    
    return get_review_workflow(project_id, review_id)


# ==================== è¯„å®¡æ–‡ä»¶ç‰ˆæœ¬æ¥å£ ====================

@reviews_bp.route('/api/reviews/<project_id>/<review_id>/versions')
def get_review_versions(project_id, review_id):
    """è·å–æŒ‡å®šè¯„å®¡çš„æ–‡ä»¶ç‰ˆæœ¬åˆ—è¡¨"""
    access_token = utils.get_access_token()
    if not access_token:
        return jsonify({
            "error": "æœªæ‰¾åˆ° Access Tokenï¼Œè¯·å…ˆè¿›è¡Œè®¤è¯",
            "status": "unauthorized"
        }), 401
    
    headers = {
        "Authorization": f"Bearer {access_token}",
        "Content-Type": "application/json"
    }
    
    # è·å–æŸ¥è¯¢å‚æ•°
    limit = request.args.get('limit', 50, type=int)
    offset = request.args.get('offset', 0, type=int)
    filter_approve_status = request.args.getlist('filter[approveStatus]')
    
    # æ„å»ºæŸ¥è¯¢å‚æ•°
    params = {
        'limit': min(limit, 50),  # æœ€å¤§50
        'offset': offset
    }
    
    # æ·»åŠ å®¡æ‰¹çŠ¶æ€è¿‡æ»¤å™¨
    for status in filter_approve_status:
        if status:
            params.setdefault('filter[approveStatus]', []).append(status)
    
    try:
        # è°ƒç”¨ Autodesk Construction Cloud Reviews API
        versions_url = f"{config.AUTODESK_API_BASE}/construction/reviews/v1/projects/{project_id}/reviews/{review_id}/versions"
        
        print(f"APIè¯·æ±‚URL: {versions_url}")
        print(f"APIè¯·æ±‚å‚æ•°: {params}")
        
        versions_resp = requests.get(versions_url, headers=headers, params=params)
        
        print(f"APIå“åº”çŠ¶æ€ç : {versions_resp.status_code}")
        
        if versions_resp.status_code != 200:
            error_text = versions_resp.text
            print(f"APIé”™è¯¯å“åº”: {error_text}")
            raise Exception(f"Failed to get review file versions: {versions_resp.status_code} - {error_text}")
        
        try:
            versions_data = versions_resp.json()
            print(f"APIå“åº”æ•°æ®: {versions_data}")
            
        except json.JSONDecodeError as e:
            print(f"JSONè§£æé”™è¯¯: {e}")
            raise Exception(f"API response data format error: {str(e)}")
        
        if not versions_data:
            print("APIè¿”å›ç©ºæ–‡ä»¶ç‰ˆæœ¬æ•°æ®")
            versions_data = {"results": [], "pagination": {}}
        
        versions_list = versions_data.get("results", [])
        pagination = versions_data.get("pagination", {})
        
        # å¯¹æ–‡ä»¶ç‰ˆæœ¬è¿›è¡Œå»é‡å¤„ç†
        seen_urns = set()
        unique_versions = []
        duplicate_versions_count = 0
        
        for version in versions_list:
            if not version:
                continue
                
            version_urn = version.get("urn", "")
            if not version_urn:
                continue  # è·³è¿‡æ²¡æœ‰URNçš„ç‰ˆæœ¬
                
            if version_urn in seen_urns:
                duplicate_versions_count += 1
                continue  # è·³è¿‡é‡å¤çš„æ–‡ä»¶ç‰ˆæœ¬
            
            seen_urns.add(version_urn)
            unique_versions.append(version)
        
        original_versions_count = len(versions_list)
        versions_list = unique_versions
        
        if duplicate_versions_count > 0:
            print(f"æ–‡ä»¶ç‰ˆæœ¬å»é‡: åŸå§‹ {original_versions_count} -> å»é‡å {len(versions_list)} (ç§»é™¤ {duplicate_versions_count} ä¸ªé‡å¤)")
        
        # ç”Ÿæˆæ–‡ä»¶ç‰ˆæœ¬åˆ†ææ•°æ®
        versions_analysis = []
        for version in versions_list:
            if not version:
                continue
            
            approve_status = version.get("approveStatus") or {}
            review_content = version.get("reviewContent") or {}
            custom_attributes = review_content.get("customAttributes") or []
            
            # æå–æ›´å¤šæ ‡è¯†ç¬¦æ¥åŒºåˆ†æ–‡ä»¶
            version_number = extract_version_number(version.get("urn", ""))
            file_size = version.get("size", 0)
            created_date = version.get("createdDate", "")
            modified_date = version.get("modifiedDate", "")
            
            # å¤„ç†å®¡æ‰¹çŠ¶æ€ - åªæœ‰å½“å®¡æ‰¹çŠ¶æ€æœ‰æœ‰æ•ˆæ•°æ®æ—¶æ‰åˆ›å»ºå¯¹è±¡
            processed_approve_status = None
            if approve_status and (approve_status.get("id") or approve_status.get("label") or approve_status.get("value")):
                processed_approve_status = {
                    "id": approve_status.get("id", ""),
                    "label": approve_status.get("label", ""),
                    "value": approve_status.get("value", ""),
                    "status_type": get_approve_status_type(approve_status.get("value", ""))
                }
            
            analysis = {
                "urn": version.get("urn", ""),
                "item_urn": version.get("itemUrn", ""),
                "name": version.get("name", ""),
                "version_number": version_number,
                "file_size": file_size,
                "created_date": utils.format_timestamp(created_date) if created_date else "",
                "modified_date": utils.format_timestamp(modified_date) if modified_date else "",
                "approve_status": processed_approve_status,
                "review_content": {
                    "name": review_content.get("name", ""),
                    "custom_attributes": custom_attributes,
                    "custom_attributes_count": len(custom_attributes)
                },
                "copied_file_version_urn": version.get("copiedFileVersionUrn", ""),
                "has_copied_version": bool(version.get("copiedFileVersionUrn")),
                "file_extension": get_file_extension(version.get("name", "")),
                "is_pdf": version.get("name", "").lower().endswith('.pdf'),
                "unique_identifier": f"{version.get('itemUrn', '')}-{version_number}",
                "display_name": f"{version.get('name', '')} (v{version_number})" if version_number else version.get('name', ''),
                # ä¿ç•™åŸå§‹æ•°æ®ç”¨äºè°ƒè¯•
                "raw_version_data": version
            }
            versions_analysis.append(analysis)
        
        # ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
        total_versions = pagination.get('totalResults', len(versions_list))
        status_counts = {}
        file_type_counts = {}
        
        for version in versions_analysis:
            # ç»Ÿè®¡å®¡æ‰¹çŠ¶æ€
            if version["approve_status"]:
                status_label = version["approve_status"]["label"]
                if status_label:
                    status_counts[status_label] = status_counts.get(status_label, 0) + 1
            
            # ç»Ÿè®¡æ–‡ä»¶ç±»å‹
            file_ext = version["file_extension"]
            if file_ext:
                file_type_counts[file_ext] = file_type_counts.get(file_ext, 0) + 1
        
        copied_versions_count = len([v for v in versions_analysis if v["has_copied_version"]])
        with_custom_attributes = len([v for v in versions_analysis if v["review_content"]["custom_attributes_count"] > 0])
        
        stats = {
            "total_versions": total_versions,
            "current_page_count": len(versions_list),
            "original_versions_count": original_versions_count,
            "duplicate_versions_count": duplicate_versions_count,
            "unique_versions_count": len(versions_list),
            "status_counts": status_counts,
            "file_type_counts": file_type_counts,
            "copied_versions_count": copied_versions_count,
            "with_custom_attributes": with_custom_attributes,
            "pdf_files_count": len([v for v in versions_analysis if v["is_pdf"]])
        }
        
        return jsonify({
            "success": True,
            "project_id": project_id,
            "review_id": review_id,
            "query_params": params,
            "stats": stats,
            "versions": versions_analysis,
            "pagination": pagination,
            "raw_data": versions_list,
            "timestamp": datetime.now().isoformat()
        })
        
    except Exception as e:
        print(f"è·å–è¯„å®¡æ–‡ä»¶ç‰ˆæœ¬æ—¶å‡ºé”™: {str(e)}")
        return jsonify({
            "error": f"è·å–è¯„å®¡æ–‡ä»¶ç‰ˆæœ¬å¤±è´¥: {str(e)}",
            "status": "error"
        }), 500


def get_approve_status_type(status_value):
    """è·å–å®¡æ‰¹çŠ¶æ€çš„ç±»å‹ç”¨äºUIæ˜¾ç¤º"""
    status_map = {
        'APPROVED': 'success',
        'REJECTED': 'danger',
        'PENDING': 'warning',
        'VOID': 'info'
    }
    return status_map.get(status_value, 'info')


def get_file_extension(filename):
    """è·å–æ–‡ä»¶æ‰©å±•å"""
    if not filename:
        return ""
    return filename.split('.')[-1].upper() if '.' in filename else ""


def extract_version_number(urn):
    """ä»URNä¸­æå–ç‰ˆæœ¬å·"""
    if not urn:
        return ""
    
    # URNæ ¼å¼é€šå¸¸æ˜¯: urn:adsk.wipprod:fs.file:vf.xxxxx?version=N
    import re
    version_match = re.search(r'version=(\d+)', urn)
    if version_match:
        return version_match.group(1)
    
    # ä¹Ÿå¯èƒ½åœ¨URNçš„å…¶ä»–éƒ¨åˆ†
    version_match = re.search(r'v(\d+)', urn)
    if version_match:
        return version_match.group(1)
    
    return "1"  # é»˜è®¤ç‰ˆæœ¬å·


@reviews_bp.route('/api/reviews/jarvis/<review_id>/versions')
def get_jarvis_review_versions(review_id):
    """è·å–æŒ‡å®šé¡¹ç›®ä¸­æŒ‡å®šè¯„å®¡çš„æ–‡ä»¶ç‰ˆæœ¬"""
    project_id = request.args.get('projectId')
    
    if not project_id:
        return jsonify({
            "error": "ç¼ºå°‘å¿…éœ€çš„ projectId å‚æ•°",
            "message": "è¯·åœ¨è¯·æ±‚ä¸­æä¾› projectId å‚æ•°",
            "status": "error"
        }), 400
    
    return get_review_versions(project_id, review_id)


# ==================== æ–‡ä»¶ç‰ˆæœ¬å®¡æ‰¹å†å²æ¥å£ ====================

@reviews_bp.route('/api/versions/<project_id>/<path:version_id>/approval-statuses')
def get_version_approval_statuses(project_id, version_id):
    """è·å–æŒ‡å®šæ–‡ä»¶ç‰ˆæœ¬çš„å®¡æ‰¹å†å²å’Œè¯„å®¡è®°å½•"""
    access_token = utils.get_access_token()
    if not access_token:
        return jsonify({
            "error": "æœªæ‰¾åˆ° Access Tokenï¼Œè¯·å…ˆè¿›è¡Œè®¤è¯",
            "status": "unauthorized"
        }), 401
    
    headers = {
        "Authorization": f"Bearer {access_token}",
        "Content-Type": "application/json"
    }
    
    # è·å–æŸ¥è¯¢å‚æ•°
    limit = request.args.get('limit', 50, type=int)
    offset = request.args.get('offset', 0, type=int)
    
    # æ„å»ºæŸ¥è¯¢å‚æ•°
    params = {
        'limit': min(limit, 50),  # æœ€å¤§50
        'offset': offset
    }
    
    try:
        # URLç¼–ç ç‰ˆæœ¬IDï¼ˆé€šå¸¸æ˜¯URNï¼‰
        from urllib.parse import quote
        encoded_version_id = quote(version_id, safe='')
        
        # è°ƒç”¨ Autodesk Construction Cloud Reviews API
        approval_url = f"{config.AUTODESK_API_BASE}/construction/reviews/v1/projects/{project_id}/versions/{encoded_version_id}/approval-statuses"
        
        print(f"APIè¯·æ±‚URL: {approval_url}")
        print(f"APIè¯·æ±‚å‚æ•°: {params}")
        print(f"åŸå§‹ç‰ˆæœ¬ID: {version_id}")
        print(f"ç¼–ç ç‰ˆæœ¬ID: {encoded_version_id}")
        
        approval_resp = requests.get(approval_url, headers=headers, params=params)
        
        print(f"APIå“åº”çŠ¶æ€ç : {approval_resp.status_code}")
        
        if approval_resp.status_code != 200:
            error_text = approval_resp.text
            print(f"APIé”™è¯¯å“åº”: {error_text}")
            raise Exception(f"Failed to get file approval history: {approval_resp.status_code} - {error_text}")
        
        try:
            approval_data = approval_resp.json()
            print(f"APIå“åº”æ•°æ®: {approval_data}")
            
            # è¯¦ç»†è®°å½•ç¬¬ä¸€ä¸ªå®¡æ‰¹è®°å½•çš„ç»“æ„ï¼Œä»¥ä¾¿äº†è§£å¯ç”¨å­—æ®µ
            if approval_data and approval_data.get("results") and len(approval_data["results"]) > 0:
                first_approval = approval_data["results"][0]
                print(f"ç¬¬ä¸€ä¸ªå®¡æ‰¹è®°å½•çš„å®Œæ•´ç»“æ„: {json.dumps(first_approval, indent=2, ensure_ascii=False)}")
                print(f"ç¬¬ä¸€ä¸ªå®¡æ‰¹è®°å½•çš„æ‰€æœ‰å­—æ®µ: {list(first_approval.keys())}")
                
                # æ£€æŸ¥åµŒå¥—ç»“æ„
                if "approvalStatus" in first_approval:
                    print(f"approvalStatuså­—æ®µ: {list(first_approval['approvalStatus'].keys())}")
                if "review" in first_approval:
                    print(f"reviewå­—æ®µ: {list(first_approval['review'].keys())}")
        except json.JSONDecodeError as e:
            print(f"JSONè§£æé”™è¯¯: {e}")
            raise Exception(f"API response data format error: {str(e)}")
        
        if not approval_data:
            print("APIè¿”å›ç©ºå®¡æ‰¹å†å²æ•°æ®")
            approval_data = {"results": [], "pagination": {}}
        
        approval_list = approval_data.get("results", [])
        pagination = approval_data.get("pagination", {})
        
        # ç”Ÿæˆå®¡æ‰¹å†å²åˆ†ææ•°æ®
        approval_analysis = []
        for approval in approval_list:
            if not approval:
                continue
            
            approval_status = approval.get("approvalStatus") or {}
            review_info = approval.get("review") or {}
            
            # æå–ç”¨æˆ·ä¿¡æ¯ - æ£€æŸ¥æ‰€æœ‰å¯èƒ½çš„ç”¨æˆ·å­—æ®µ
            user_info = {}
            
            # æ£€æŸ¥å®¡æ‰¹çŠ¶æ€ä¸­çš„ç”¨æˆ·ä¿¡æ¯
            if "approvedBy" in approval:
                user_info["approved_by"] = approval.get("approvedBy") or {}
            if "reviewedBy" in approval:
                user_info["reviewed_by"] = approval.get("reviewedBy") or {}
            if "createdBy" in approval:
                user_info["created_by"] = approval.get("createdBy") or {}
            if "updatedBy" in approval:
                user_info["updated_by"] = approval.get("updatedBy") or {}
            if "assignedTo" in approval:
                user_info["assigned_to"] = approval.get("assignedTo") or {}
            
            # æ£€æŸ¥æ—¶é—´æˆ³ä¿¡æ¯
            timestamps = {}
            if "approvedAt" in approval:
                timestamps["approved_at"] = utils.format_timestamp(approval.get("approvedAt", ""))
            if "reviewedAt" in approval:
                timestamps["reviewed_at"] = utils.format_timestamp(approval.get("reviewedAt", ""))
            if "createdAt" in approval:
                timestamps["created_at"] = utils.format_timestamp(approval.get("createdAt", ""))
            if "updatedAt" in approval:
                timestamps["updated_at"] = utils.format_timestamp(approval.get("updatedAt", ""))
            
            # æ£€æŸ¥å®¡æ‰¹çŠ¶æ€ä¸­çš„ç”¨æˆ·ä¿¡æ¯
            if isinstance(approval_status, dict):
                if "approvedBy" in approval_status:
                    user_info["status_approved_by"] = approval_status.get("approvedBy") or {}
                if "assignedTo" in approval_status:
                    user_info["status_assigned_to"] = approval_status.get("assignedTo") or {}
            
            # æ£€æŸ¥è¯„å®¡ä¿¡æ¯ä¸­çš„ç”¨æˆ·ä¿¡æ¯
            if isinstance(review_info, dict):
                if "createdBy" in review_info:
                    user_info["review_created_by"] = review_info.get("createdBy") or {}
                if "assignedTo" in review_info:
                    user_info["review_assigned_to"] = review_info.get("assignedTo") or {}
                if "currentAssignee" in review_info:
                    user_info["current_assignee"] = review_info.get("currentAssignee") or {}
            
            analysis = {
                "approval_status": {
                    "id": approval_status.get("id", ""),
                    "label": approval_status.get("label", ""),
                    "value": approval_status.get("value", ""),
                    "status_type": get_approve_status_type(approval_status.get("value", ""))
                },
                "review": {
                    "id": review_info.get("id", ""),
                    "name": review_info.get("name", ""),
                    "sequence_id": review_info.get("sequenceId", 0),
                    "status": review_info.get("status", ""),
                    "status_type": get_review_status_type(review_info.get("status", ""))
                },
                "user_info": user_info,
                "timestamps": timestamps,
                "has_user_info": len(user_info) > 0,
                "has_timestamps": len(timestamps) > 0,
                "is_in_review": review_info.get("status") == "OPEN",
                "is_finished": review_info.get("status") in ["CLOSED", "VOID"],
                "sequence_display": f"#{review_info.get('sequenceId', 0)}"
            }
            approval_analysis.append(analysis)
        
        # ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
        total_approvals = pagination.get('totalResults', len(approval_list))
        
        # æŒ‰çŠ¶æ€åˆ†ç»„ç»Ÿè®¡
        approval_status_counts = {}
        review_status_counts = {}
        in_review_count = 0
        finished_count = 0
        
        for approval in approval_analysis:
            # ç»Ÿè®¡å®¡æ‰¹çŠ¶æ€
            approval_label = approval["approval_status"]["label"]
            if approval_label:
                approval_status_counts[approval_label] = approval_status_counts.get(approval_label, 0) + 1
            
            # ç»Ÿè®¡è¯„å®¡çŠ¶æ€
            review_status = approval["review"]["status"]
            if review_status:
                review_status_counts[review_status] = review_status_counts.get(review_status, 0) + 1
            
            # ç»Ÿè®¡è¿›è¡Œä¸­å’Œå·²å®Œæˆ
            if approval["is_in_review"]:
                in_review_count += 1
            elif approval["is_finished"]:
                finished_count += 1
        
        # æŒ‰åºåˆ—IDæ’åºï¼ˆå€’åºï¼‰
        approval_analysis.sort(key=lambda x: x["review"]["sequence_id"], reverse=True)
        
        # åˆ†ç»„æ•°æ®
        in_review_approvals = [a for a in approval_analysis if a["is_in_review"]]
        finished_approvals = [a for a in approval_analysis if a["is_finished"]]
        
        stats = {
            "total_approvals": total_approvals,
            "current_page_count": len(approval_list),
            "approval_status_counts": approval_status_counts,
            "review_status_counts": review_status_counts,
            "in_review_count": in_review_count,
            "finished_count": finished_count,
            "latest_sequence_id": max([a["review"]["sequence_id"] for a in approval_analysis], default=0)
        }
        
        return jsonify({
            "success": True,
            "project_id": project_id,
            "version_id": version_id,
            "encoded_version_id": encoded_version_id,
            "query_params": params,
            "stats": stats,
            "approval_history": approval_analysis,
            "in_review_approvals": in_review_approvals,
            "finished_approvals": finished_approvals,
            "pagination": pagination,
            "raw_data": approval_list,
            "timestamp": datetime.now().isoformat()
        })
        
    except Exception as e:
        print(f"è·å–æ–‡ä»¶å®¡æ‰¹å†å²æ—¶å‡ºé”™: {str(e)}")
        return jsonify({
            "error": f"è·å–æ–‡ä»¶å®¡æ‰¹å†å²å¤±è´¥: {str(e)}",
            "status": "error"
        }), 500


def get_review_status_type(status_value):
    """è·å–è¯„å®¡çŠ¶æ€çš„ç±»å‹ç”¨äºUIæ˜¾ç¤º"""
    status_map = {
        'OPEN': 'success',
        'CLOSED': 'info',
        'VOID': 'warning'
    }
    return status_map.get(status_value, 'info')


@reviews_bp.route('/api/versions/jarvis/<path:version_id>/approval-statuses')
def get_jarvis_version_approval_statuses(version_id):
    """è·å–æŒ‡å®šé¡¹ç›®ä¸­æŒ‡å®šæ–‡ä»¶ç‰ˆæœ¬çš„å®¡æ‰¹å†å²"""
    project_id = request.args.get('projectId')
    
    if not project_id:
        return jsonify({
            "error": "ç¼ºå°‘å¿…éœ€çš„ projectId å‚æ•°",
            "message": "è¯·åœ¨è¯·æ±‚ä¸­æä¾› projectId å‚æ•°",
            "status": "error"
        }), 400
    
    return get_version_approval_statuses(project_id, version_id)


@reviews_bp.route('/api/reviews/file-workflows/<project_id>/<path:file_id>', methods=['GET'])
def get_file_workflows(project_id, file_id):
    """è·å–æ–‡ä»¶å…³è”çš„å·¥ä½œæµï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼‰"""
    start_time = time.time()
    print(f"ğŸ” get_file_workflows - å¼€å§‹å¤„ç†è¯·æ±‚")
    print(f"ğŸ“‹ æ¥æ”¶å‚æ•°: project_id={project_id}, file_id={file_id}")
    
    try:
        access_token = utils.get_access_token()
        if not access_token:
            print("âŒ æœªæ‰¾åˆ°è®¿é—®ä»¤ç‰Œ")
            return jsonify({
                "success": False,
                "error": "Failed to get access token"
            }), 401
        
        headers = {
            "Authorization": f"Bearer {access_token}",
            "Content-Type": "application/json"
        }
        
        # è½¬æ¢é¡¹ç›®IDæ ¼å¼ï¼ˆç§»é™¤ 'b.' å‰ç¼€ï¼‰
        from api_modules.submittal_api import convert_project_id
        clean_project_id = convert_project_id(project_id)
        print(f"ğŸ”§ File Workflows API: åŸå§‹é¡¹ç›®ID: {project_id}, è½¬æ¢å: {clean_project_id}")
        
        # ç›´æ¥ä»APIè·å–è¯„å®¡æ•°æ®ï¼ˆç§»é™¤ç¼“å­˜ä»¥é¿å…è·¨æ–‡ä»¶æŸ¥è¯¢æ±¡æŸ“ï¼‰
        reviews_url = f"{config.AUTODESK_API_BASE}/construction/reviews/v1/projects/{clean_project_id}/reviews"
        print(f"ğŸ“¡ ä»APIè·å–é¡¹ç›®è¯„å®¡: {reviews_url}")
        
        # æ·»åŠ åˆ†é¡µå‚æ•°ä»¥è·å–æ›´å¤šæ•°æ®
        params = {
            'limit': 50,  # æ¯é¡µæœ€å¤§æ•°é‡
            'offset': 0
        }
        
        response = requests.get(reviews_url, headers=headers, params=params, timeout=30)
        
        if response.status_code != 200:
            error_msg = f"Failed to get project reviews: {response.status_code}"
            if response.text:
                try:
                    error_data = response.json()
                    error_msg += f" - {error_data.get('detail', response.text)}"
                except:
                    error_msg += f" - {response.text}"
            
            return jsonify({
                "success": False,
                "error": error_msg
            }), response.status_code
        
        reviews_data = response.json()
        
        all_reviews = reviews_data.get("results", [])
        print(f"ğŸ“Š æ€»è¯„å®¡æ•°é‡: {len(all_reviews)}")
        
        if not all_reviews:
            return jsonify({
                "success": True,
                "workflows": [],
                "total_count": 0,
                "message": "No reviews found in project",
                "processing_time": round(time.time() - start_time, 2)
            })
        
        # ä¼˜åŒ–ï¼šä½¿ç”¨æ›´ä¿å®ˆçš„å¹¶å‘ç­–ç•¥ä»¥é¿å…APIé™åˆ¶
        file_workflows = []
        max_workers = min(5, len(all_reviews))  # å‡å°‘å¹¶å‘æ•°ä»¥æé«˜ç¨³å®šæ€§
        
        print(f"ğŸš€ ä½¿ç”¨ {max_workers} ä¸ªçº¿ç¨‹å¹¶è¡Œæ£€æŸ¥è¯„å®¡ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼‰")
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_review = {
                executor.submit(_check_review_for_file, review, file_id, project_id, headers): review
                for review in all_reviews
            }
            
            # æ”¶é›†ç»“æœ
            for future in as_completed(future_to_review):
                try:
                    result = future.result(timeout=15)  # 15ç§’è¶…æ—¶
                    if result:
                        matching_review = result['review']
                        matched_version = result['matched_version']
                        
                        # ç§»é™¤å·¥ä½œæµè¿›åº¦æŸ¥è¯¢ä»¥ä¼˜åŒ–æ€§èƒ½
                        # å·¥ä½œæµè¿›åº¦ä¿¡æ¯å¯ä»¥åœ¨éœ€è¦æ—¶å•ç‹¬è·å–
                        workflow_progress = None
                        
                        # ç›´æ¥ä»å·²è·å–çš„ç‰ˆæœ¬ä¿¡æ¯ä¸­æå–æ–‡ä»¶å®¡é˜…çŠ¶æ€ï¼Œé¿å…é‡å¤APIè°ƒç”¨
                        file_approval_status = None
                        try:
                            approve_status = matched_version.get("approveStatus")
                            if approve_status:
                                file_approval_status = {
                                    "id": approve_status.get("id"),
                                    "label": approve_status.get("label"),
                                    "value": approve_status.get("value")
                                }
                        except Exception as e:
                            print(f"âš ï¸ æå–æ–‡ä»¶å®¡é˜…çŠ¶æ€å¤±è´¥: {str(e)}")
                        
                        # æ„å»ºå·¥ä½œæµä¿¡æ¯
                        workflow_info = {
                            "id": matching_review["id"],
                            "name": matching_review["name"],
                            "sequenceId": matching_review["sequenceId"],
                            "status": matching_review["status"],
                            "workflowId": matching_review.get("workflowId"),
                            "currentStepId": matching_review.get("currentStepId"),
                            "currentStepDueDate": matching_review.get("currentStepDueDate"),
                            "createdAt": matching_review.get("createdAt"),
                            "updatedAt": matching_review.get("updatedAt"),
                            "finishedAt": matching_review.get("finishedAt"),
                            "createdBy": matching_review.get("createdBy"),
                            "nextActionBy": matching_review.get("nextActionBy"),
                            "workflowProgress": workflow_progress,
                            "archived": matching_review.get("archived", False),
                            "archivedAt": matching_review.get("archivedAt"),
                            "archivedBy": matching_review.get("archivedBy"),
                            "fileApprovalStatus": file_approval_status  # æ–°å¢ï¼šæ–‡ä»¶å®¡é˜…çŠ¶æ€
                        }
                        
                        file_workflows.append(workflow_info)
                        print(f"âœ… æ‰¾åˆ°å·¥ä½œæµ: {matching_review['name']} (ID: {matching_review['id']})")
                
                except Exception as e:
                    print(f"âŒ å¤„ç†è¯„å®¡æ—¶å‡ºé”™: {str(e)}")
                    continue
        
        processing_time = round(time.time() - start_time, 2)
        print(f"ğŸ¯ æ‰¾åˆ° {len(file_workflows)} ä¸ªå·¥ä½œæµï¼Œè€—æ—¶ {processing_time} ç§’")
        
        response = jsonify({
            "success": True,
            "workflows": file_workflows,
            "total_count": len(file_workflows),
            "total_reviews_checked": len(all_reviews),
            "processing_time": processing_time,
            "message": f"Successfully found {len(file_workflows)} workflows for file"
        })
        
        # æ·»åŠ é˜²ç¼“å­˜å¤´
        response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate'
        response.headers['Pragma'] = 'no-cache'
        response.headers['Expires'] = '0'
        
        return response
        
    except Exception as e:
        processing_time = round(time.time() - start_time, 2)
        print(f"âŒ get_file_workflows å‡ºé”™: {str(e)}")
        response = jsonify({
            "success": False,
            "error": f"Internal server error: {str(e)}",
            "processing_time": processing_time
        })
        
        # æ·»åŠ é˜²ç¼“å­˜å¤´
        response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate'
        response.headers['Pragma'] = 'no-cache'
        response.headers['Expires'] = '0'
        
        return response, 500


# ==================== ä¾¿æ·çš„æ–‡ä»¶å·¥ä½œæµæŸ¥è¯¢æ¥å£ ====================

# ==================== å•ä¸ªå·¥ä½œæµæŸ¥è¯¢æ¥å£ ====================

@reviews_bp.route('/api/workflows/<project_id>/<workflow_id>')
def get_single_workflow(project_id, workflow_id):
    """è·å–æŒ‡å®šé¡¹ç›®ä¸­çš„å•ä¸ªå·¥ä½œæµè¯¦æƒ…"""
    access_token = utils.get_access_token()
    if not access_token:
        return jsonify({
            "error": "æœªæ‰¾åˆ° Access Tokenï¼Œè¯·å…ˆè¿›è¡Œè®¤è¯",
            "status": "unauthorized"
        }), 401
    
    headers = {
        "Authorization": f"Bearer {access_token}",
        "Content-Type": "application/json"
    }
    
    # è½¬æ¢é¡¹ç›®IDæ ¼å¼ï¼ˆç§»é™¤ 'b.' å‰ç¼€ï¼‰
    from api_modules.submittal_api import convert_project_id
    clean_project_id = convert_project_id(project_id)
    print(f"ğŸ”§ Single Workflow API: åŸå§‹é¡¹ç›®ID: {project_id}, è½¬æ¢å: {clean_project_id}")
    
    try:
        # è°ƒç”¨ Autodesk Construction Cloud Reviews API
        workflow_url = f"{config.AUTODESK_API_BASE}/construction/reviews/v1/projects/{clean_project_id}/workflows/{workflow_id}"
        
        print(f"APIè¯·æ±‚URL: {workflow_url}")
        
        workflow_resp = requests.get(workflow_url, headers=headers, timeout=30)
        
        print(f"APIå“åº”çŠ¶æ€ç : {workflow_resp.status_code}")
        
        if workflow_resp.status_code != 200:
            error_text = workflow_resp.text
            print(f"APIé”™è¯¯å“åº”: {error_text}")
            raise Exception(f"Failed to get workflow details: {workflow_resp.status_code} - {error_text}")
        
        try:
            workflow_data = workflow_resp.json()
            print(f"APIå“åº”æ•°æ®: {workflow_data}")
        except json.JSONDecodeError as e:
            print(f"JSONè§£æé”™è¯¯: {e}")
            raise Exception(f"API response data format error: {str(e)}")
        
        if not workflow_data:
            print("APIè¿”å›ç©ºå·¥ä½œæµæ•°æ®")
            workflow_data = {}
        
        # ç”Ÿæˆå·¥ä½œæµåˆ†ææ•°æ®
        workflow_analysis = {
            "id": workflow_data.get("id", ""),
            "name": workflow_data.get("name", ""),
            "description": workflow_data.get("description", ""),
            "notes": workflow_data.get("notes", ""),
            "status": workflow_data.get("status", ""),
            "created_at": utils.format_timestamp(workflow_data.get("createdAt", "")),
            "updated_at": utils.format_timestamp(workflow_data.get("updatedAt", "")),
            "steps_count": len(workflow_data.get("steps", [])),
            "approval_options_count": len(workflow_data.get("approvalStatusOptions", [])),
            "has_copy_files": workflow_data.get("copyFilesOptions", {}).get("enabled", False),
            "has_attached_attributes": len(workflow_data.get("attachedAttributes", [])) > 0,
            "additional_options": workflow_data.get("additionalOptions", {}),
            "steps": workflow_data.get("steps", []),
            "approval_status_options": workflow_data.get("approvalStatusOptions", []),
            "copy_files_options": workflow_data.get("copyFilesOptions", {}),
            "attached_attributes": workflow_data.get("attachedAttributes", []),
            "update_attributes_options": workflow_data.get("updateAttributesOptions", {})
        }
        
        # ç”Ÿæˆè¯¦ç»†çš„æ­¥éª¤åˆ†æ
        detailed_steps = []
        steps = workflow_data.get("steps", [])
        for step_idx, step in enumerate(steps):
            if not step:
                continue
                
            candidates = step.get("candidates") or {}
            step_detail = {
                "step_number": step_idx + 1,
                "id": step.get("id", ""),
                "name": step.get("name", ""),
                "type": step.get("type", ""),
                "duration": step.get("duration", 0),
                "due_date_type": step.get("dueDateType", ""),
                "group_review": step.get("groupReview") or {},
                "group_review_analysis": _analyze_group_review_config(step.get("groupReview") or {}),
                "candidates": {
                    "roles": candidates.get("roles") or [],
                    "users": candidates.get("users") or [],
                    "companies": candidates.get("companies") or [],
                    "roles_count": len(candidates.get("roles") or []),
                    "users_count": len(candidates.get("users") or []),
                    "companies_count": len(candidates.get("companies") or [])
                },
                # æ·»åŠ å®¡é˜…è€…ç±»å‹åˆ†æï¼ˆåŸºäºå·¥ä½œæµå®šä¹‰ï¼‰
                "reviewer_type_analysis": _analyze_workflow_step_reviewer_types(step)
            }
            detailed_steps.append(step_detail)
        
        # ç”Ÿæˆå®¡æ‰¹çŠ¶æ€é€‰é¡¹åˆ†æ
        approval_options_analysis = []
        for option in workflow_data.get("approvalStatusOptions", []):
            if not option:
                continue
            option_analysis = {
                "id": option.get("id", ""),
                "label": option.get("label", ""),
                "value": option.get("value", ""),
                "built_in": option.get("builtIn", False)
            }
            approval_options_analysis.append(option_analysis)
        
        return jsonify({
            "success": True,
            "project_id": project_id,
            "workflow_id": workflow_id,
            "workflow": workflow_analysis,
            "detailed_steps": detailed_steps,
            "approval_options": approval_options_analysis,
            "raw_data": workflow_data,
            "timestamp": datetime.now().isoformat()
        })
        
    except Exception as e:
        print(f"è·å–å•ä¸ªå·¥ä½œæµæ—¶å‡ºé”™: {str(e)}")
        return jsonify({
            "error": f"è·å–å·¥ä½œæµè¯¦æƒ…å¤±è´¥: {str(e)}",
            "status": "error"
        }), 500


@reviews_bp.route('/api/workflows/jarvis/<workflow_id>')
def get_jarvis_single_workflow(workflow_id):
    """è·å–æŒ‡å®šé¡¹ç›®ä¸­çš„å•ä¸ªå·¥ä½œæµè¯¦æƒ…ï¼ˆç®€åŒ–è·¯ç”±ï¼‰"""
    project_id = request.args.get('projectId')
    
    if not project_id:
        return jsonify({
            "error": "ç¼ºå°‘å¿…éœ€çš„ projectId å‚æ•°",
            "message": "è¯·åœ¨è¯·æ±‚ä¸­æä¾› projectId å‚æ•°",
            "status": "error"
        }), 400
    
    return get_single_workflow(project_id, workflow_id)


# ==================== å•ä¸ªè¯„å®¡æŸ¥è¯¢æ¥å£ ====================

@reviews_bp.route('/api/review/<project_id>/<review_id>')
def get_single_review(project_id, review_id):
    """è·å–æŒ‡å®šé¡¹ç›®ä¸­çš„å•ä¸ªè¯„å®¡è¯¦æƒ…"""
    access_token = utils.get_access_token()
    if not access_token:
        return jsonify({
            "error": "æœªæ‰¾åˆ° Access Tokenï¼Œè¯·å…ˆè¿›è¡Œè®¤è¯",
            "status": "unauthorized"
        }), 401
    
    headers = {
        "Authorization": f"Bearer {access_token}",
        "Content-Type": "application/json"
    }
    
    try:
        # è°ƒç”¨ Autodesk Construction Cloud Reviews API
        review_url = f"{config.AUTODESK_API_BASE}/construction/reviews/v1/projects/{project_id}/reviews/{review_id}"
        
        print(f"APIè¯·æ±‚URL: {review_url}")
        
        review_resp = requests.get(review_url, headers=headers, timeout=30)
        
        print(f"APIå“åº”çŠ¶æ€ç : {review_resp.status_code}")
        
        if review_resp.status_code != 200:
            error_text = review_resp.text
            print(f"APIé”™è¯¯å“åº”: {error_text}")
            raise Exception(f"Failed to get review details: {review_resp.status_code} - {error_text}")
        
        try:
            review_data = review_resp.json()
            print(f"APIå“åº”æ•°æ®: {review_data}")
        except json.JSONDecodeError as e:
            print(f"JSONè§£æé”™è¯¯: {e}")
            raise Exception(f"API response data format error: {str(e)}")
        
        if not review_data:
            print("APIè¿”å›ç©ºè¯„å®¡æ•°æ®")
            review_data = {}
        
        # å®‰å…¨è·å–nextActionByæ•°æ®
        next_action_by = review_data.get("nextActionBy") or {}
        claimed_by = next_action_by.get("claimedBy") or []
        candidates = next_action_by.get("candidates") or {}
        
        # è·å–å·¥ä½œæµæ­¥éª¤è¿›åº¦ä¿¡æ¯
        workflow_id = review_data.get("workflowId", "")
        current_step_id = review_data.get("currentStepId", "")
        review_status = review_data.get("status", "")
        step_progress = get_workflow_step_info(project_id, workflow_id, current_step_id, access_token, review_status)
        
        # åˆ†æå®¡é˜…è€…ç±»å‹ï¼ˆä¸»è¦ vs å¯é€‰ï¼‰
        reviewer_analysis = _analyze_reviewer_types(claimed_by, candidates)
        
        # ç”Ÿæˆè¯„å®¡åˆ†ææ•°æ®
        review_analysis = {
            "id": review_data.get("id", ""),
            "sequence_id": review_data.get("sequenceId", 0),
            "name": review_data.get("name", ""),
            "status": review_data.get("status", ""),
            "current_step_id": current_step_id,
            "current_step_due_date": utils.format_timestamp(review_data.get("currentStepDueDate", "")),
            "created_by": review_data.get("createdBy") or {},
            "created_at": utils.format_timestamp(review_data.get("createdAt", "")),
            "updated_at": utils.format_timestamp(review_data.get("updatedAt", "")),
            "finished_at": utils.format_timestamp(review_data.get("finishedAt", "")),
            "archived": review_data.get("archived", False),
            "archived_by": review_data.get("archivedBy") or {},
            "archived_at": utils.format_timestamp(review_data.get("archivedAt", "")),
            "workflow_id": workflow_id,
            "next_action_by": next_action_by,
            "has_claimed_users": len(claimed_by) > 0,
            "candidates_count": {
                "roles": len(candidates.get("roles") or []),
                "users": len(candidates.get("users") or []),
                "companies": len(candidates.get("companies") or [])
            },
            # å®¡é˜…è€…ç±»å‹åˆ†æ
            "reviewer_analysis": reviewer_analysis,
            # å·¥ä½œæµæ­¥éª¤è¿›åº¦ä¿¡æ¯
            "workflow_progress": step_progress
        }
        
        return jsonify({
            "success": True,
            "project_id": project_id,
            "review_id": review_id,
            "review": review_analysis,
            "raw_data": review_data,
            "timestamp": datetime.now().isoformat()
        })
        
    except Exception as e:
        print(f"è·å–å•ä¸ªè¯„å®¡æ—¶å‡ºé”™: {str(e)}")
        return jsonify({
            "error": f"è·å–è¯„å®¡è¯¦æƒ…å¤±è´¥: {str(e)}",
            "status": "error"
        }), 500


@reviews_bp.route('/api/review/jarvis/<review_id>')
def get_jarvis_single_review(review_id):
    """è·å–æŒ‡å®šé¡¹ç›®ä¸­çš„å•ä¸ªè¯„å®¡è¯¦æƒ…ï¼ˆç®€åŒ–è·¯ç”±ï¼‰"""
    project_id = request.args.get('projectId')
    
    if not project_id:
        return jsonify({
            "error": "ç¼ºå°‘å¿…éœ€çš„ projectId å‚æ•°",
            "message": "è¯·åœ¨è¯·æ±‚ä¸­æä¾› projectId å‚æ•°",
            "status": "error"
        }), 400
    
    return get_single_review(project_id, review_id)


# ==================== è¯„å®¡è¿›åº¦å†å²æ¥å£ ====================

@reviews_bp.route('/api/reviews/<project_id>/<review_id>/progress')
def get_review_progress(project_id, review_id):
    """è·å–æŒ‡å®šè¯„å®¡çš„è¿›åº¦å†å²è®°å½•"""
    access_token = utils.get_access_token()
    if not access_token:
        return jsonify({
            "error": "æœªæ‰¾åˆ° Access Tokenï¼Œè¯·å…ˆè¿›è¡Œè®¤è¯",
            "status": "unauthorized"
        }), 401
    
    headers = {
        "Authorization": f"Bearer {access_token}",
        "Content-Type": "application/json"
    }
    
    # è·å–æŸ¥è¯¢å‚æ•°
    limit = request.args.get('limit', 50, type=int)
    offset = request.args.get('offset', 0, type=int)
    
    # æ„å»ºæŸ¥è¯¢å‚æ•°
    params = {
        'limit': min(limit, 50),  # æœ€å¤§50
        'offset': offset
    }
    
    try:
        # è°ƒç”¨ Autodesk Construction Cloud Reviews API
        progress_url = f"{config.AUTODESK_API_BASE}/construction/reviews/v1/projects/{project_id}/reviews/{review_id}/progress"
        
        print(f"APIè¯·æ±‚URL: {progress_url}")
        print(f"APIè¯·æ±‚å‚æ•°: {params}")
        
        progress_resp = requests.get(progress_url, headers=headers, params=params, timeout=30)
        
        print(f"APIå“åº”çŠ¶æ€ç : {progress_resp.status_code}")
        
        if progress_resp.status_code != 200:
            error_text = progress_resp.text
            print(f"APIé”™è¯¯å“åº”: {error_text}")
            raise Exception(f"Failed to get review progress: {progress_resp.status_code} - {error_text}")
        
        try:
            progress_data = progress_resp.json()
            print(f"APIå“åº”æ•°æ®: {progress_data}")
        except json.JSONDecodeError as e:
            print(f"JSONè§£æé”™è¯¯: {e}")
            raise Exception(f"API response data format error: {str(e)}")
        
        if not progress_data:
            print("APIè¿”å›ç©ºè¿›åº¦æ•°æ®")
            progress_data = {"results": [], "pagination": {}}
        
        progress_list = progress_data.get("results", [])
        pagination = progress_data.get("pagination", {})
        
        # ç”Ÿæˆè¿›åº¦åˆ†ææ•°æ®
        progress_analysis = []
        for progress in progress_list:
            if not progress:
                continue
            
            candidates = progress.get("candidates") or {}
            claimed_by = progress.get("claimedBy") or {}
            action_by = progress.get("actionBy") or {}
            
            analysis = {
                "step_id": progress.get("stepId", ""),
                "step_name": progress.get("stepName", ""),
                "status": progress.get("status", ""),
                "claimed_by": claimed_by,
                "action_by": action_by,
                "candidates": {
                    "roles": candidates.get("roles") or [],
                    "users": candidates.get("users") or [],
                    "companies": candidates.get("companies") or [],
                    "roles_count": len(candidates.get("roles") or []),
                    "users_count": len(candidates.get("users") or []),
                    "companies_count": len(candidates.get("companies") or [])
                },
                "end_time": utils.format_timestamp(progress.get("endTime", "")),
                "notes": progress.get("notes", ""),
                "has_claimed_user": bool(claimed_by),
                "has_action_user": bool(action_by),
                "is_completed": progress.get("status") in ["SUBMITTED", "APPROVED", "REJECTED"],
                "is_claimed": progress.get("status") == "CLAIMED",
                "is_pending": progress.get("status") == "PENDING",
                "step_type": get_step_type_from_candidates(candidates),
                "action_summary": get_action_summary(progress.get("status"), claimed_by, action_by)
            }
            progress_analysis.append(analysis)
        
        # ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
        total_progress = pagination.get('totalResults', len(progress_list))
        status_counts = {}
        for progress in progress_analysis:
            status = progress["status"]
            if status:
                status_counts[status] = status_counts.get(status, 0) + 1
        
        completed_count = len([p for p in progress_analysis if p["is_completed"]])
        claimed_count = len([p for p in progress_analysis if p["is_claimed"]])
        pending_count = len([p for p in progress_analysis if p["is_pending"]])
        
        stats = {
            "total_progress": total_progress,
            "current_page_count": len(progress_list),
            "status_counts": status_counts,
            "completed_count": completed_count,
            "claimed_count": claimed_count,
            "pending_count": pending_count,
            "progress_completion_rate": round((completed_count / len(progress_analysis)) * 100, 1) if progress_analysis else 0
        }
        
        return jsonify({
            "success": True,
            "project_id": project_id,
            "review_id": review_id,
            "query_params": params,
            "stats": stats,
            "progress": progress_analysis,
            "pagination": pagination,
            "raw_data": progress_list,
            "timestamp": datetime.now().isoformat()
        })
        
    except Exception as e:
        print(f"è·å–è¯„å®¡è¿›åº¦æ—¶å‡ºé”™: {str(e)}")
        return jsonify({
            "error": f"è·å–è¯„å®¡è¿›åº¦å¤±è´¥: {str(e)}",
            "status": "error"
        }), 500


@reviews_bp.route('/api/reviews/jarvis/<review_id>/progress')
def get_jarvis_review_progress(review_id):
    """è·å–æŒ‡å®šé¡¹ç›®ä¸­æŒ‡å®šè¯„å®¡çš„è¿›åº¦å†å²ï¼ˆç®€åŒ–è·¯ç”±ï¼‰"""
    project_id = request.args.get('projectId')
    
    if not project_id:
        return jsonify({
            "error": "ç¼ºå°‘å¿…éœ€çš„ projectId å‚æ•°",
            "message": "è¯·åœ¨è¯·æ±‚ä¸­æä¾› projectId å‚æ•°",
            "status": "error"
        }), 400
    
    return get_review_progress(project_id, review_id)


# è¾…åŠ©å‡½æ•°
def get_step_type_from_candidates(candidates):
    """æ ¹æ®å€™é€‰è€…ä¿¡æ¯æ¨æ–­æ­¥éª¤ç±»å‹"""
    if not candidates:
        return "unknown"
    
    users = candidates.get("users", [])
    roles = candidates.get("roles", [])
    companies = candidates.get("companies", [])
    
    if users and not roles and not companies:
        return "direct_assignment"
    elif roles and not users and not companies:
        return "role_based"
    elif companies and not users and not roles:
        return "company_based"
    elif users or roles or companies:
        return "mixed_assignment"
    else:
        return "no_assignment"


def get_action_summary(status, claimed_by, action_by):
    """ç”Ÿæˆæ“ä½œæ‘˜è¦"""
    if not status:
        return "No status information"
    
    if status == "PENDING":
        return "Waiting to be claimed"
    elif status == "CLAIMED":
        if claimed_by:
            return f"Claimed by {claimed_by.get('name', 'Unknown user')}"
        return "Claimed"
    elif status == "SUBMITTED":
        if action_by:
            return f"Submitted by {action_by.get('name', 'Unknown user')}"
        return "Submitted"
    elif status == "APPROVED":
        if action_by:
            return f"Approved by {action_by.get('name', 'Unknown user')}"
        return "Approved"
    elif status == "REJECTED":
        if action_by:
            return f"Rejected by {action_by.get('name', 'Unknown user')}"
        return "Rejected"
    else:
        return f"Status: {status}"


@reviews_bp.route('/api/reviews/by-file/<project_id>/<path:file_id>')
def get_reviews_by_file(project_id, file_id):
    """
    é€šè¿‡æ–‡ä»¶IDè·å–ç›¸å…³çš„è¯„å®¡å·¥ä½œæµï¼ˆæ–°çš„ä¾¿æ·æ¥å£ï¼‰
    
    è¿™ä¸ªæ¥å£ç»“åˆäº†ä¼˜åŒ–çš„æ–‡ä»¶åŒ¹é…å’ŒReviews APIçš„æ–‡ä»¶è¿‡æ»¤åŠŸèƒ½
    æä¾›æ›´å¥½çš„æ€§èƒ½å’Œå‡†ç¡®æ€§
    
    å‚æ•°ï¼š
    - project_id: é¡¹ç›®ID
    - file_id: æ–‡ä»¶ID/URN
    
    è¿”å›ï¼šåŒ…å«å·¥ä½œæµä¿¡æ¯çš„è¯„å®¡åˆ—è¡¨
    """
    start_time = time.time()
    print(f"ğŸ” get_reviews_by_file - å¼€å§‹å¤„ç†è¯·æ±‚")
    print(f"ğŸ“‹ æ¥æ”¶å‚æ•°: project_id={project_id}, file_id={file_id}")
    
    try:
        access_token = utils.get_access_token()
        if not access_token:
            return jsonify({
                "success": False,
                "error": "Failed to get access token"
            }), 401
        
        # ä½¿ç”¨æ‰©å±•çš„Reviews APIè¿›è¡Œæ–‡ä»¶è¿‡æ»¤æŸ¥è¯¢
        # æ„å»ºæŸ¥è¯¢å‚æ•°ï¼Œä½¿ç”¨æ–‡ä»¶URNè¿‡æ»¤
        from flask import request as flask_request
        
        # ä¸´æ—¶ä¿®æ”¹request.argsæ¥ä¼ é€’è¿‡æ»¤å‚æ•°
        original_args = flask_request.args
        
        # åˆ›å»ºæ–°çš„æŸ¥è¯¢å‚æ•°
        new_args = dict(original_args)
        new_args['filter[fileUrn]'] = file_id
        new_args['limit'] = '50'  # å¢åŠ é™åˆ¶ä»¥è·å–æ›´å¤šç»“æœ
        
        # ä¸´æ—¶æ›¿æ¢request.args
        flask_request.args = type(original_args)(new_args)
        
        try:
            # è°ƒç”¨ä¼˜åŒ–çš„è¯„å®¡æŸ¥è¯¢å‡½æ•°
            result = get_project_reviews(project_id)
            
            # ä»ç»“æœä¸­æå–è¯„å®¡æ•°æ®
            if hasattr(result, 'get_json'):
                result_data = result.get_json()
            else:
                result_data = result
            
            if result_data and result_data.get('success'):
                reviews = result_data.get('reviews', [])
                
                # è½¬æ¢ä¸ºå·¥ä½œæµæ ¼å¼
                workflows = []
                for review in reviews:
                    workflow_info = {
                        "id": review.get("id"),
                        "name": review.get("name"),
                        "sequenceId": review.get("sequence_id"),
                        "status": review.get("status"),
                        "workflowId": review.get("workflow_id"),
                        "currentStepId": review.get("current_step_id"),
                        "currentStepDueDate": review.get("current_step_due_date"),
                        "createdAt": review.get("created_at"),
                        "updatedAt": review.get("updated_at"),
                        "finishedAt": review.get("finished_at"),
                        "createdBy": review.get("created_by"),
                        "nextActionBy": review.get("next_action_by"),
                        "workflowProgress": review.get("workflow_progress"),
                        "archived": review.get("archived", False),
                        "archivedAt": review.get("archived_at"),
                        "archivedBy": review.get("archived_by")
                    }
                    workflows.append(workflow_info)
                
                processing_time = round(time.time() - start_time, 2)
                
                response = jsonify({
                    "success": True,
                    "workflows": workflows,
                    "total_count": len(workflows),
                    "processing_time": processing_time,
                    "method": "enhanced_reviews_api_filtering",
                    "message": f"Successfully found {len(workflows)} workflows using enhanced API filtering"
                })
                
                # æ·»åŠ é˜²ç¼“å­˜å¤´
                response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate'
                response.headers['Pragma'] = 'no-cache'
                response.headers['Expires'] = '0'
                
                return response
            else:
                # å¦‚æœAPIè¿‡æ»¤å¤±è´¥ï¼Œå›é€€åˆ°åŸå§‹æ–¹æ³•
                print("âš ï¸ APIè¿‡æ»¤å¤±è´¥ï¼Œå›é€€åˆ°åŸå§‹æ–‡ä»¶å·¥ä½œæµæŸ¥è¯¢æ–¹æ³•")
                return get_file_workflows(project_id, file_id)
                
        finally:
            # æ¢å¤åŸå§‹çš„request.args
            flask_request.args = original_args
        
    except Exception as e:
        processing_time = round(time.time() - start_time, 2)
        print(f"âŒ get_reviews_by_file å‡ºé”™: {str(e)}")
        
        # å‡ºé”™æ—¶å›é€€åˆ°åŸå§‹æ–¹æ³•
        print("âš ï¸ å‡ºé”™ï¼Œå›é€€åˆ°åŸå§‹æ–‡ä»¶å·¥ä½œæµæŸ¥è¯¢æ–¹æ³•")
        return get_file_workflows(project_id, file_id)


