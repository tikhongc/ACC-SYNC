# -*- coding: utf-8 -*-
"""
Issues API æ¨¡å—
å¤„ç† Autodesk Construction Cloud (ACC) Issues API çš„åŠŸèƒ½
æ”¯æŒè®®é¢˜çš„å³æ—¶åŒæ­¥ã€è·å–è¯¦ç»†ä¿¡æ¯ã€ç•™è¨€å’Œé™„ä»¶ç­‰æ“ä½œ
"""

import requests
import json
import time
from datetime import datetime, timedelta
from flask import Blueprint, jsonify, request
import config
import utils
from .urn_download_simple import get_document_info_by_urn

issues_bp = Blueprint('issues', __name__)

# é…ç½®å¸¸é‡ - åŸºäºæ€§èƒ½æµ‹è¯•ç»“æœ
DEFAULT_ISSUES_LIMIT = 50  # æœ€ä½³æ€§èƒ½å€¼ï¼ˆæµ‹è¯•ç»“æœï¼š24ç§’å“åº”ï¼‰
MAX_ISSUES_LIMIT = 100     # API æœ€å¤§æ”¯æŒå€¼
BATCH_SIZE = 50            # æ‰¹é‡å¤„ç†å¤§å°


def normalize_project_id(project_id):
    """
    ç§»é™¤é¡¹ç›®IDä¸­çš„ 'b.' å‰ç¼€ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    ACC Issues API éœ€è¦ä¸å¸¦å‰ç¼€çš„é¡¹ç›®ID
    
    Args:
        project_id (str): é¡¹ç›®IDï¼ˆå¯èƒ½åŒ…å« 'b.' å‰ç¼€ï¼‰
    
    Returns:
        str: æ¸…ç†åçš„é¡¹ç›®ID
    """
    return project_id.replace("b.", "") if project_id.startswith("b.") else project_id


def enhance_linked_documents(linked_documents, project_id, access_token=None):
    """
    å¢å¼ºlinkedDocumentsä¿¡æ¯ï¼Œé€šè¿‡URNè·å–å…·ä½“çš„æ–‡ä»¶åç§°å’Œè¯¦ç»†ä¿¡æ¯
    
    Args:
        linked_documents (list): åŸå§‹linkedDocumentsæ•°æ®
        project_id (str): é¡¹ç›®ID
        access_token (str): è®¿é—®ä»¤ç‰Œ
    
    Returns:
        list: å¢å¼ºåçš„linkedDocumentsæ•°æ®
    """
    if not linked_documents or not isinstance(linked_documents, list):
        return linked_documents
    
    if not access_token:
        access_token = utils.get_access_token()
    
    if not access_token:
        print("âš ï¸ æ— æ³•è·å–è®¿é—®ä»¤ç‰Œï¼Œè·³è¿‡linkedDocumentså¢å¼º")
        return linked_documents
    
    enhanced_documents = []
    
    for doc in linked_documents:
        try:
            # ä¿ç•™åŸå§‹æ•°æ®
            enhanced_doc = doc.copy()
            
            # è·å–URN
            urn = doc.get('urn')
            if not urn:
                print(f"âš ï¸ linkedDocumentç¼ºå°‘URN: {doc}")
                enhanced_documents.append(enhanced_doc)
                continue
            
            print(f"ğŸ” å¢å¼ºlinkedDocument URN: {urn}")
            
            # é€šè¿‡URNè·å–æ–‡æ¡£è¯¦ç»†ä¿¡æ¯
            doc_info_result = get_document_info_by_urn(urn, project_id, access_token)
            
            if doc_info_result and doc_info_result.get('success'):
                doc_info = doc_info_result.get('document_info', {})
                
                # å¢å¼ºæ–‡æ¡£ä¿¡æ¯
                enhanced_doc['enhanced_info'] = {
                    'name': doc_info.get('name', 'Unknown Document'),
                    'file_type': doc_info.get('file_type', 'unknown'),
                    'file_size': doc_info.get('file_size', 0),
                    'mime_type': doc_info.get('mime_type', 'application/octet-stream'),
                    'version_number': doc_info.get('version_number', 1),
                    'create_time': doc_info.get('create_time'),
                    'last_modified_time': doc_info.get('last_modified_time'),
                    'storage_urn': doc_info.get('storage_urn'),
                    'enhanced_at': datetime.now().isoformat()
                }
                
                # ä¸ºäº†å‘åå…¼å®¹ï¼Œä¹Ÿåœ¨æ ¹çº§åˆ«æ·»åŠ nameå­—æ®µ
                if not enhanced_doc.get('name'):
                    enhanced_doc['name'] = doc_info.get('name', 'Unknown Document')
                
                print(f"âœ… æˆåŠŸå¢å¼ºæ–‡æ¡£ä¿¡æ¯: {doc_info.get('name')}")
            else:
                # å¦‚æœæ— æ³•è·å–è¯¦ç»†ä¿¡æ¯ï¼Œæ·»åŠ åŸºæœ¬çš„å¢å¼ºä¿¡æ¯
                enhanced_doc['enhanced_info'] = {
                    'name': 'Unknown Document',
                    'file_type': 'unknown',
                    'file_size': 0,
                    'mime_type': 'application/octet-stream',
                    'version_number': 1,
                    'create_time': None,
                    'last_modified_time': None,
                    'storage_urn': urn,
                    'enhanced_at': datetime.now().isoformat(),
                    'error': doc_info_result.get('error') if doc_info_result else 'Failed to get document info'
                }
                
                if not enhanced_doc.get('name'):
                    enhanced_doc['name'] = 'Unknown Document'
                
                print(f"âš ï¸ æ— æ³•è·å–æ–‡æ¡£è¯¦ç»†ä¿¡æ¯: {doc_info_result.get('error') if doc_info_result else 'Unknown error'}")
            
            enhanced_documents.append(enhanced_doc)
            
        except Exception as e:
            print(f"âŒ å¢å¼ºlinkedDocumentæ—¶å‡ºé”™: {str(e)}")
            # å‡ºé”™æ—¶ä¿ç•™åŸå§‹æ•°æ®
            enhanced_documents.append(doc)
    
    return enhanced_documents


def calculate_quick_statistics(issues):
    """
    åŸºäºå½“å‰è®®é¢˜æ•°æ®å¿«é€Ÿè®¡ç®—ç»Ÿè®¡ä¿¡æ¯
    é¿å…é‡å¤APIè°ƒç”¨ï¼Œæé«˜æ€§èƒ½
    
    Args:
        issues (list): è®®é¢˜åˆ—è¡¨
    
    Returns:
        dict: å¿«é€Ÿç»Ÿè®¡ä¿¡æ¯
    """
    if not issues:
        return {
            "total_issues": 0,
            "status_breakdown": {},
            "assignee_type_breakdown": {},
            "recent_activity": 0,
            "note": "Quick statistics based on current page data"
        }
    
    stats = {
        "total_issues": len(issues),
        "status_breakdown": {},
        "assignee_type_breakdown": {},
        "recent_activity": 0,
        "note": f"åŸºäºå½“å‰ {len(issues)} ä¸ªè®®é¢˜çš„å¿«é€Ÿç»Ÿè®¡"
    }
    
    # ç»Ÿè®¡çŠ¶æ€åˆ†å¸ƒ
    for issue in issues:
        status = issue.get('status', 'unknown')
        stats['status_breakdown'][status] = stats['status_breakdown'].get(status, 0) + 1
        
        # ç»Ÿè®¡åˆ†é…ç±»å‹
        assigned_type = issue.get('assignedToType', 'unassigned')
        if not issue.get('assignedTo'):
            assigned_type = 'unassigned'
        stats['assignee_type_breakdown'][assigned_type] = stats['assignee_type_breakdown'].get(assigned_type, 0) + 1
        
        # ç»Ÿè®¡æœ€è¿‘æ´»åŠ¨ï¼ˆ24å°æ—¶å†…æ›´æ–°çš„è®®é¢˜ï¼‰
        if issue.get('updatedAt'):
            try:
                updated_time = datetime.fromisoformat(issue['updatedAt'].replace('Z', '+00:00'))
                if (datetime.now().replace(tzinfo=updated_time.tzinfo) - updated_time).days < 1:
                    stats['recent_activity'] += 1
            except:
                pass
    
    return stats


def get_user_profile(project_id, headers):
    """
    è·å–å½“å‰ç”¨æˆ·æ¡£æ¡ˆå’Œæƒé™
    
    Args:
        project_id (str): é¡¹ç›®ID
        headers (dict): è¯·æ±‚å¤´
    
    Returns:
        dict: ç”¨æˆ·æ¡£æ¡ˆä¿¡æ¯
    """
    try:
        # è§„èŒƒåŒ–é¡¹ç›®IDï¼ˆç§»é™¤ 'b.' å‰ç¼€ï¼‰
        project_id = normalize_project_id(project_id)
        user_url = f"{config.AUTODESK_API_BASE}/construction/issues/v1/projects/{project_id}/users/me"
        
        print(f"ğŸ” è·å–ç”¨æˆ·æ¡£æ¡ˆ: {project_id}")
        
        response = requests.get(user_url, headers=headers, timeout=(10, 30))
        
        if response.status_code == 200:
            user_data = response.json()
            print(f"âœ… æˆåŠŸè·å–ç”¨æˆ·æ¡£æ¡ˆ")
            return {
                "success": True,
                "data": user_data
            }
        else:
            print(f"âŒ è·å–ç”¨æˆ·æ¡£æ¡ˆå¤±è´¥: {response.status_code} - {response.text}")
            return {
                "success": False,
                "error": f"HTTP {response.status_code}: {response.text}",
                "status_code": response.status_code
            }
            
    except Exception as e:
        print(f"âŒ è·å–ç”¨æˆ·æ¡£æ¡ˆæ—¶å‡ºé”™: {str(e)}")
        return {
            "success": False,
            "error": str(e)
        }


def get_issue_types(project_id, headers, include_subtypes=False, filters=None, pagination=None):
    """
    è·å–é¡¹ç›®çš„è®®é¢˜ç±»å‹ï¼ˆç±»åˆ«å’Œå­ç±»å‹ï¼‰
    
    Args:
        project_id (str): é¡¹ç›®ID
        headers (dict): è¯·æ±‚å¤´
        include_subtypes (bool): æ˜¯å¦åŒ…å«å­ç±»å‹
        filters (dict): è¿‡æ»¤æ¡ä»¶
        pagination (dict): åˆ†é¡µå‚æ•°
    
    Returns:
        dict: è®®é¢˜ç±»å‹æ•°æ®
    """
    try:
        # è§„èŒƒåŒ–é¡¹ç›®IDï¼ˆç§»é™¤ 'b.' å‰ç¼€ï¼‰
        project_id = normalize_project_id(project_id)
        types_url = f"{config.AUTODESK_API_BASE}/construction/issues/v1/projects/{project_id}/issue-types"
        
        # æ„å»ºæŸ¥è¯¢å‚æ•°
        params = {}
        
        if include_subtypes:
            params['include'] = 'subtypes'
        
        # æ·»åŠ è¿‡æ»¤æ¡ä»¶
        if filters:
            if filters.get('updatedAt'):
                params['filter[updatedAt]'] = filters['updatedAt']
            if filters.get('isActive') is not None:
                params['filter[isActive]'] = str(filters['isActive']).lower()
        
        # æ·»åŠ åˆ†é¡µå‚æ•°
        if pagination:
            if pagination.get('limit'):
                params['limit'] = pagination['limit']
            if pagination.get('offset'):
                params['offset'] = pagination['offset']
        
        print(f"ğŸ” è·å–è®®é¢˜ç±»å‹: {project_id}")
        
        response = requests.get(types_url, headers=headers, params=params, timeout=(10, 30))
        
        if response.status_code == 200:
            types_data = response.json()
            print(f"âœ… æˆåŠŸè·å– {len(types_data.get('results', []))} ä¸ªè®®é¢˜ç±»å‹")
            return {
                "success": True,
                "data": types_data
            }
        else:
            print(f"âŒ è·å–è®®é¢˜ç±»å‹å¤±è´¥: {response.status_code} - {response.text}")
            return {
                "success": False,
                "error": f"HTTP {response.status_code}: {response.text}",
                "status_code": response.status_code
            }
            
    except Exception as e:
        print(f"âŒ è·å–è®®é¢˜ç±»å‹æ—¶å‡ºé”™: {str(e)}")
        return {
            "success": False,
            "error": str(e)
        }


def get_attribute_definitions(project_id, headers, filters=None, pagination=None):
    """
    è·å–è®®é¢˜è‡ªå®šä¹‰å±æ€§å®šä¹‰ï¼ˆè‡ªå®šä¹‰å­—æ®µï¼‰
    
    Args:
        project_id (str): é¡¹ç›®ID
        headers (dict): è¯·æ±‚å¤´
        filters (dict): è¿‡æ»¤æ¡ä»¶
        pagination (dict): åˆ†é¡µå‚æ•°
    
    Returns:
        dict: å±æ€§å®šä¹‰æ•°æ®
    """
    try:
        # è§„èŒƒåŒ–é¡¹ç›®IDï¼ˆç§»é™¤ 'b.' å‰ç¼€ï¼‰
        project_id = normalize_project_id(project_id)
        attrs_url = f"{config.AUTODESK_API_BASE}/construction/issues/v1/projects/{project_id}/issue-attribute-definitions"
        
        # æ„å»ºæŸ¥è¯¢å‚æ•°
        params = {}
        
        # æ·»åŠ è¿‡æ»¤æ¡ä»¶
        if filters:
            if filters.get('createdAt'):
                params['filter[createdAt]'] = filters['createdAt']
            if filters.get('updatedAt'):
                params['filter[updatedAt]'] = filters['updatedAt']
            if filters.get('deletedAt'):
                params['filter[deletedAt]'] = filters['deletedAt']
            if filters.get('dataType'):
                params['filter[dataType]'] = filters['dataType']
        
        # æ·»åŠ åˆ†é¡µå‚æ•°
        if pagination:
            if pagination.get('limit'):
                params['limit'] = pagination['limit']
            if pagination.get('offset'):
                params['offset'] = pagination['offset']
        else:
            params['limit'] = 200  # é»˜è®¤æœ€å¤§å€¼
        
        print(f"ğŸ” è·å–è®®é¢˜å±æ€§å®šä¹‰: {project_id}")
        
        response = requests.get(attrs_url, headers=headers, params=params, timeout=(10, 30))
        
        if response.status_code == 200:
            attrs_data = response.json()
            print(f"âœ… æˆåŠŸè·å– {len(attrs_data.get('results', []))} ä¸ªå±æ€§å®šä¹‰")
            return {
                "success": True,
                "data": attrs_data
            }
        else:
            print(f"âŒ è·å–å±æ€§å®šä¹‰å¤±è´¥: {response.status_code} - {response.text}")
            return {
                "success": False,
                "error": f"HTTP {response.status_code}: {response.text}",
                "status_code": response.status_code
            }
            
    except Exception as e:
        print(f"âŒ è·å–å±æ€§å®šä¹‰æ—¶å‡ºé”™: {str(e)}")
        return {
            "success": False,
            "error": str(e)
        }


def get_attribute_mappings(project_id, headers, filters=None, pagination=None):
    """
    è·å–è®®é¢˜è‡ªå®šä¹‰å±æ€§æ˜ å°„ï¼ˆå­—æ®µåˆ†é…åˆ°ç±»å‹ï¼‰
    
    Args:
        project_id (str): é¡¹ç›®ID
        headers (dict): è¯·æ±‚å¤´
        filters (dict): è¿‡æ»¤æ¡ä»¶
        pagination (dict): åˆ†é¡µå‚æ•°
    
    Returns:
        dict: å±æ€§æ˜ å°„æ•°æ®
    """
    try:
        # è§„èŒƒåŒ–é¡¹ç›®IDï¼ˆç§»é™¤ 'b.' å‰ç¼€ï¼‰
        project_id = normalize_project_id(project_id)
        mappings_url = f"{config.AUTODESK_API_BASE}/construction/issues/v1/projects/{project_id}/issue-attribute-mappings"
        
        # æ„å»ºæŸ¥è¯¢å‚æ•°
        params = {}
        
        # æ·»åŠ è¿‡æ»¤æ¡ä»¶
        if filters:
            if filters.get('createdAt'):
                params['filter[createdAt]'] = filters['createdAt']
            if filters.get('updatedAt'):
                params['filter[updatedAt]'] = filters['updatedAt']
            if filters.get('deletedAt'):
                params['filter[deletedAt]'] = filters['deletedAt']
            if filters.get('attributeDefinitionId'):
                params['filter[attributeDefinitionId]'] = filters['attributeDefinitionId']
            if filters.get('mappedItemId'):
                params['filter[mappedItemId]'] = filters['mappedItemId']
        
        # æ·»åŠ åˆ†é¡µå‚æ•°
        if pagination:
            if pagination.get('limit'):
                params['limit'] = pagination['limit']
            if pagination.get('offset'):
                params['offset'] = pagination['offset']
        else:
            params['limit'] = 200  # é»˜è®¤æœ€å¤§å€¼
        
        print(f"ğŸ” è·å–è®®é¢˜å±æ€§æ˜ å°„: {project_id}")
        
        response = requests.get(mappings_url, headers=headers, params=params, timeout=(10, 30))
        
        if response.status_code == 200:
            mappings_data = response.json()
            print(f"âœ… æˆåŠŸè·å– {len(mappings_data.get('results', []))} ä¸ªå±æ€§æ˜ å°„")
            return {
                "success": True,
                "data": mappings_data
            }
        else:
            print(f"âŒ è·å–å±æ€§æ˜ å°„å¤±è´¥: {response.status_code} - {response.text}")
            return {
                "success": False,
                "error": f"HTTP {response.status_code}: {response.text}",
                "status_code": response.status_code
            }
            
    except Exception as e:
        print(f"âŒ è·å–å±æ€§æ˜ å°„æ—¶å‡ºé”™: {str(e)}")
        return {
            "success": False,
            "error": str(e)
        }


def get_root_cause_categories(project_id, headers, include_root_causes=False, filters=None, pagination=None):
    """
    è·å–è®®é¢˜æ ¹æœ¬åŸå› ç±»åˆ«
    
    Args:
        project_id (str): é¡¹ç›®ID
        headers (dict): è¯·æ±‚å¤´
        include_root_causes (bool): æ˜¯å¦åŒ…å«æ ¹æœ¬åŸå› è¯¦æƒ…
        filters (dict): è¿‡æ»¤æ¡ä»¶
        pagination (dict): åˆ†é¡µå‚æ•°
    
    Returns:
        dict: æ ¹æœ¬åŸå› ç±»åˆ«æ•°æ®
    """
    try:
        # è§„èŒƒåŒ–é¡¹ç›®IDï¼ˆç§»é™¤ 'b.' å‰ç¼€ï¼‰
        project_id = normalize_project_id(project_id)
        root_causes_url = f"{config.AUTODESK_API_BASE}/construction/issues/v1/projects/{project_id}/issue-root-cause-categories"
        
        # æ„å»ºæŸ¥è¯¢å‚æ•°
        params = {}
        
        if include_root_causes:
            params['include'] = 'rootcauses'
        
        # æ·»åŠ è¿‡æ»¤æ¡ä»¶
        if filters:
            if filters.get('updatedAt'):
                params['filter[updatedAt]'] = filters['updatedAt']
        
        # æ·»åŠ åˆ†é¡µå‚æ•°
        if pagination:
            if pagination.get('limit'):
                params['limit'] = pagination['limit']
            if pagination.get('offset'):
                params['offset'] = pagination['offset']
        
        print(f"ğŸ” è·å–æ ¹æœ¬åŸå› ç±»åˆ«: {project_id}")
        
        response = requests.get(root_causes_url, headers=headers, params=params, timeout=(10, 30))
        
        if response.status_code == 200:
            root_causes_data = response.json()
            print(f"âœ… æˆåŠŸè·å– {len(root_causes_data.get('results', []))} ä¸ªæ ¹æœ¬åŸå› ç±»åˆ«")
            return {
                "success": True,
                "data": root_causes_data
            }
        else:
            print(f"âŒ è·å–æ ¹æœ¬åŸå› ç±»åˆ«å¤±è´¥: {response.status_code} - {response.text}")
            return {
                "success": False,
                "error": f"HTTP {response.status_code}: {response.text}",
                "status_code": response.status_code
            }
            
    except Exception as e:
        print(f"âŒ è·å–æ ¹æœ¬åŸå› ç±»åˆ«æ—¶å‡ºé”™: {str(e)}")
        return {
            "success": False,
            "error": str(e)
        }


def get_markups(container_id, headers, filters=None, pagination=None, sort=None):
    """
    è·å–é¡¹ç›®ä¸­çš„æ ‡è®°ï¼ˆMarkupsï¼‰
    
    Args:
        container_id (str): å®¹å™¨ID
        headers (dict): è¯·æ±‚å¤´
        filters (dict): è¿‡æ»¤æ¡ä»¶
        pagination (dict): åˆ†é¡µå‚æ•°
        sort (str): æ’åºå­—æ®µ
    
    Returns:
        dict: æ ‡è®°æ•°æ®
    """
    try:
        markups_url = f"https://developer.api.autodesk.com/issues/v1/containers/{container_id}/markups"
        
        # æ„å»ºæŸ¥è¯¢å‚æ•°
        params = {}
        
        # æ·»åŠ è¿‡æ»¤æ¡ä»¶
        if filters:
            if filters.get('target_urn'):
                params['filter[target_urn]'] = filters['target_urn']
            if filters.get('synced_after'):
                params['filter[synced_after]'] = filters['synced_after']
            if filters.get('created_at'):
                params['filter[created_at]'] = filters['created_at']
            if filters.get('created_by'):
                params['filter[created_by]'] = filters['created_by']
            if filters.get('status'):
                params['filter[status]'] = filters['status']
        
        # æ·»åŠ åˆ†é¡µå‚æ•°
        if pagination:
            if pagination.get('limit'):
                params['page[limit]'] = pagination['limit']
            if pagination.get('offset'):
                params['page[offset]'] = pagination['offset']
        else:
            params['page[limit]'] = 10  # é»˜è®¤å€¼
        
        # æ·»åŠ æ’åº
        if sort:
            params['sort'] = sort
        
        # ä¿®æ”¹headersä»¥ç¬¦åˆMarkups APIè¦æ±‚
        markups_headers = headers.copy()
        markups_headers['Content-Type'] = 'application/vnd.api+json'
        
        print(f"ğŸ” è·å–æ ‡è®°: {container_id}")
        
        response = requests.get(markups_url, headers=markups_headers, params=params, timeout=(10, 30))
        
        if response.status_code == 200:
            markups_data = response.json()
            print(f"âœ… æˆåŠŸè·å–æ ‡è®°æ•°æ®")
            return {
                "success": True,
                "data": markups_data
            }
        else:
            print(f"âŒ è·å–æ ‡è®°å¤±è´¥: {response.status_code} - {response.text}")
            return {
                "success": False,
                "error": f"HTTP {response.status_code}: {response.text}",
                "status_code": response.status_code
            }
            
    except Exception as e:
        print(f"âŒ è·å–æ ‡è®°æ—¶å‡ºé”™: {str(e)}")
        return {
            "success": False,
            "error": str(e)
        }


def get_issues_list(project_id, headers, filters=None, pagination=None, max_retries=3):
    """
    è·å–é¡¹ç›®ä¸­çš„è®®é¢˜åˆ—è¡¨ - å¸¦é‡è¯•æœºåˆ¶å’Œè¶…æ—¶ä¼˜åŒ–
    
    Args:
        project_id (str): é¡¹ç›®ID
        headers (dict): è¯·æ±‚å¤´
        filters (dict): è¿‡æ»¤æ¡ä»¶
        pagination (dict): åˆ†é¡µå‚æ•°
        max_retries (int): æœ€å¤§é‡è¯•æ¬¡æ•° (é»˜è®¤3æ¬¡)
    
    Returns:
        dict: è®®é¢˜åˆ—è¡¨æ•°æ®
    """
    # è§„èŒƒåŒ–é¡¹ç›®IDï¼ˆç§»é™¤ 'b.' å‰ç¼€ï¼‰
    project_id = normalize_project_id(project_id)
    # æ„å»ºAPI URL
    issues_url = f"{config.AUTODESK_API_BASE}/construction/issues/v1/projects/{project_id}/issues"
    
    # æ„å»ºæŸ¥è¯¢å‚æ•°
    params = {}
    
    # æ·»åŠ è¿‡æ»¤æ¡ä»¶
    if filters:
        if filters.get('status'):
            params['filter[status]'] = filters['status']
        if filters.get('assignedTo'):
            params['filter[assignedTo]'] = filters['assignedTo']
        if filters.get('issueTypeId'):
            params['filter[issueTypeId]'] = filters['issueTypeId']
        if filters.get('createdBy'):
            params['filter[createdBy]'] = filters['createdBy']
        if filters.get('updatedSince'):
            params['filter[updatedAt][gte]'] = filters['updatedSince']
        if filters.get('createdSince'):
            params['filter[createdAt][gte]'] = filters['createdSince']
        if filters.get('dueDate'):
            params['filter[dueDate]'] = filters['dueDate']
        if filters.get('linkedDocumentUrn'):
            params['filter[linkedDocumentUrn]'] = filters['linkedDocumentUrn']
    
    # æ·»åŠ åˆ†é¡µå‚æ•°ï¼Œå¦‚æœè¯·æ±‚è¶…è¿‡100æ¡ï¼Œè‡ªåŠ¨åˆ†é¡µ
    if pagination:
        requested_limit = pagination.get('limit', DEFAULT_ISSUES_LIMIT)
        params['limit'] = min(requested_limit, MAX_ISSUES_LIMIT)  # APIæœ€å¤§æ”¯æŒ100æ¡/æ¬¡
        if pagination.get('offset'):
            params['offset'] = pagination['offset']
    else:
        params['limit'] = DEFAULT_ISSUES_LIMIT  # é»˜è®¤é™åˆ¶ï¼š50ï¼ˆæœ€ä½³æ€§èƒ½ï¼‰
    
    print(f"ğŸ” è·å–è®®é¢˜åˆ—è¡¨: {project_id}")
    print(f"ğŸ“‹ æŸ¥è¯¢å‚æ•°: {params}")
    
    # é‡è¯•æœºåˆ¶ - é’ˆå¯¹504è¶…æ—¶é”™è¯¯
    for attempt in range(max_retries):
        try:
            # å¢åŠ è¶…æ—¶æ—¶é—´ï¼šè¿æ¥15ç§’ï¼Œè¯»å–60ç§’
            response = requests.get(issues_url, headers=headers, params=params, timeout=(15, 60))
            
            if response.status_code == 200:
                issues_data = response.json()
                results = issues_data.get('results', [])
                print(f"âœ… æˆåŠŸè·å– {len(results)} ä¸ªè®®é¢˜")
                
                # å¦‚æœéœ€è¦è·å–æ›´å¤šæ•°æ®ï¼ˆè¶…è¿‡100æ¡ï¼‰ï¼Œè‡ªåŠ¨åˆ†é¡µè·å–
                if pagination and pagination.get('limit', 0) > 100:
                    return get_issues_list_paginated(project_id, headers, filters, pagination, max_retries)
                
                return {
                    "success": True,
                    "data": issues_data,
                    "total_count": len(results),
                    "has_more": len(results) == params.get('limit', 100)
                }
            elif response.status_code == 504:
                # Gateway Timeout - éœ€è¦é‡è¯•
                print(f"â° å°è¯• {attempt + 1}/{max_retries}: APIç½‘å…³è¶…æ—¶ (504)")
                if attempt < max_retries - 1:
                    wait_time = (2 ** attempt) * 2  # æŒ‡æ•°é€€é¿: 2s, 4s, 8s
                    print(f"â³ ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                    time.sleep(wait_time)
                    continue
                else:
                    return {
                        "success": False,
                        "error": "APIç½‘å…³è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•æˆ–å‡å°‘è¯·æ±‚æ•°æ®é‡",
                        "status_code": 504,
                        "retry_suggestion": "å»ºè®®å‡å°‘ limit å‚æ•°ï¼ˆå¦‚è®¾ä¸º50ï¼‰æˆ–ç¨åå†è¯•"
                    }
            elif response.status_code == 429:
                # Rate Limit - éœ€è¦ç­‰å¾…
                print(f"â° å°è¯• {attempt + 1}/{max_retries}: APIè¯·æ±‚é¢‘ç‡é™åˆ¶ (429)")
                if attempt < max_retries - 1:
                    wait_time = 5 * (attempt + 1)  # 5s, 10s, 15s
                    print(f"â³ é‡åˆ°é¢‘ç‡é™åˆ¶ï¼Œç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                    time.sleep(wait_time)
                    continue
                else:
                    return {
                        "success": False,
                        "error": "APIè¯·æ±‚é¢‘ç‡è¶…é™ï¼Œè¯·ç¨åé‡è¯•",
                        "status_code": 429
                    }
            else:
                print(f"âŒ è·å–è®®é¢˜åˆ—è¡¨å¤±è´¥: {response.status_code} - {response.text}")
                return {
                    "success": False,
                    "error": f"HTTP {response.status_code}: {response.text}",
                    "status_code": response.status_code
                }
                
        except requests.exceptions.Timeout:
            print(f"â° å°è¯• {attempt + 1}/{max_retries}: è¯·æ±‚è¶…æ—¶")
            if attempt < max_retries - 1:
                wait_time = (2 ** attempt) * 2
                print(f"â³ ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                time.sleep(wait_time)
                continue
            else:
                return {
                    "success": False,
                    "error": "è¯·æ±‚è¶…æ—¶ï¼ŒæœåŠ¡å™¨å“åº”æ—¶é—´è¿‡é•¿",
                    "status_code": 408,
                    "retry_suggestion": "å»ºè®®å‡å°‘ limit å‚æ•°ï¼ˆå¦‚è®¾ä¸º50ï¼‰æˆ–ç¨åå†è¯•"
                }
        except Exception as e:
            print(f"âŒ è·å–è®®é¢˜åˆ—è¡¨æ—¶å‡ºé”™: {str(e)}")
            return {
                "success": False,
                "error": str(e)
            }
    
    # å¦‚æœæ‰€æœ‰é‡è¯•éƒ½å¤±è´¥
    return {
        "success": False,
        "error": "All retry attempts failed",
        "status_code": 500
    }


def get_issues_list_paginated(project_id, headers, filters=None, pagination=None, max_retries=3):
    """
    è‡ªåŠ¨åˆ†é¡µè·å–è®®é¢˜åˆ—è¡¨ï¼ˆç”¨äºå¤§é‡æ•°æ®è¯·æ±‚ï¼‰
    
    Args:
        project_id (str): é¡¹ç›®ID
        headers (dict): è¯·æ±‚å¤´
        filters (dict): è¿‡æ»¤æ¡ä»¶ (å¯é€‰)
        pagination (dict): åˆ†é¡µå‚æ•° (å¿…é¡»åŒ…å«limit)
        max_retries (int): æ¯æ¬¡è¯·æ±‚çš„æœ€å¤§é‡è¯•æ¬¡æ•°
    
    Returns:
        dict: åˆå¹¶åçš„è®®é¢˜åˆ—è¡¨æ•°æ®
    """
    try:
        requested_limit = pagination.get('limit', 100)
        all_results = []
        offset = pagination.get('offset', 0)
        
        print(f"ğŸ“„ å¼€å§‹åˆ†é¡µè·å–è®®é¢˜ï¼Œç›®æ ‡: {requested_limit} æ¡ï¼Œèµ·å§‹åç§»: {offset}")
        
        while len(all_results) < requested_limit:
            # è®¡ç®—æœ¬æ¬¡è¯·æ±‚çš„æ•°é‡ï¼ˆæœ€å¤š100æ¡ï¼‰
            remaining = requested_limit - len(all_results)
            current_limit = min(remaining, 100)
            
            # æ„å»ºæœ¬æ¬¡è¯·æ±‚çš„åˆ†é¡µå‚æ•°
            current_pagination = {
                'limit': current_limit,
                'offset': offset + len(all_results)
            }
            
            # è·å–æœ¬æ‰¹æ•°æ®
            result = get_issues_list(project_id, headers, filters, current_pagination, max_retries)
            
            if not result['success']:
                # å¦‚æœå¤±è´¥ä½†å·²ç»è·å–äº†éƒ¨åˆ†æ•°æ®ï¼Œè¿”å›éƒ¨åˆ†æ•°æ®
                if all_results:
                    print(f"âš ï¸ éƒ¨åˆ†è·å–æˆåŠŸï¼Œè¿”å›å·²è·å–çš„ {len(all_results)} æ¡æ•°æ®")
                    return {
                        "success": True,
                        "data": {"results": all_results},
                        "total_count": len(all_results),
                        "has_more": True,
                        "partial": True,
                        "warning": f"æœªèƒ½è·å–å…¨éƒ¨æ•°æ®: {result.get('error')}"
                    }
                else:
                    return result
            
            batch_results = result['data'].get('results', [])
            all_results.extend(batch_results)
            
            print(f"ğŸ“Š å·²è·å– {len(all_results)}/{requested_limit} æ¡è®®é¢˜")
            
            # å¦‚æœæœ¬æ‰¹æ•°æ®å°‘äºè¯·æ±‚æ•°é‡ï¼Œè¯´æ˜æ²¡æœ‰æ›´å¤šæ•°æ®äº†
            if len(batch_results) < current_limit:
                print(f"âœ… å·²è·å–æ‰€æœ‰å¯ç”¨æ•°æ®: {len(all_results)} æ¡")
                break
        
        return {
            "success": True,
            "data": {"results": all_results},
            "total_count": len(all_results),
            "has_more": len(all_results) == requested_limit
        }
        
    except Exception as e:
        print(f"âŒ åˆ†é¡µè·å–è®®é¢˜æ—¶å‡ºé”™: {str(e)}")
        return {
            "success": False,
            "error": str(e)
        }


def get_issue_details(project_id, issue_id, headers, enhance_documents=True):
    """
    è·å–å•ä¸€è®®é¢˜çš„è¯¦ç»†ä¿¡æ¯
    
    Args:
        project_id (str): é¡¹ç›®ID
        issue_id (str): è®®é¢˜ID
        headers (dict): è¯·æ±‚å¤´
        enhance_documents (bool): æ˜¯å¦å¢å¼ºlinkedDocumentsä¿¡æ¯
    
    Returns:
        dict: è®®é¢˜è¯¦ç»†ä¿¡æ¯
    """
    try:
        # è§„èŒƒåŒ–é¡¹ç›®IDï¼ˆç§»é™¤ 'b.' å‰ç¼€ï¼‰
        normalized_project_id = normalize_project_id(project_id)
        issue_url = f"{config.AUTODESK_API_BASE}/construction/issues/v1/projects/{normalized_project_id}/issues/{issue_id}"
        
        print(f"ğŸ” è·å–è®®é¢˜è¯¦æƒ…: {issue_id}")
        
        response = requests.get(issue_url, headers=headers, timeout=(10, 30))
        
        if response.status_code == 200:
            issue_data = response.json()
            print(f"âœ… æˆåŠŸè·å–è®®é¢˜è¯¦æƒ…: {issue_data.get('title', 'Unknown')}")
            
            # å¢å¼ºlinkedDocumentsä¿¡æ¯
            if enhance_documents and issue_data.get('linkedDocuments'):
                print(f"ğŸ”§ å¼€å§‹å¢å¼ºlinkedDocumentsä¿¡æ¯...")
                access_token = headers.get('Authorization', '').replace('Bearer ', '')
                enhanced_linked_docs = enhance_linked_documents(
                    issue_data['linkedDocuments'], 
                    project_id,  # ä½¿ç”¨åŸå§‹project_idï¼ˆå¯èƒ½åŒ…å«b.å‰ç¼€ï¼‰
                    access_token
                )
                issue_data['linkedDocuments'] = enhanced_linked_docs
                print(f"âœ… linkedDocumentså¢å¼ºå®Œæˆ")
            
            return {
                "success": True,
                "data": issue_data
            }
        else:
            print(f"âŒ è·å–è®®é¢˜è¯¦æƒ…å¤±è´¥: {response.status_code} - {response.text}")
            return {
                "success": False,
                "error": f"HTTP {response.status_code}: {response.text}",
                "status_code": response.status_code
            }
            
    except Exception as e:
        print(f"âŒ è·å–è®®é¢˜è¯¦æƒ…æ—¶å‡ºé”™: {str(e)}")
        return {
            "success": False,
            "error": str(e)
        }


def get_issue_comments(project_id, issue_id, headers, pagination=None):
    """
    è·å–è®®é¢˜çš„ç•™è¨€
    
    Args:
        project_id (str): é¡¹ç›®ID
        issue_id (str): è®®é¢˜ID
        headers (dict): è¯·æ±‚å¤´
        pagination (dict): åˆ†é¡µå‚æ•°
    
    Returns:
        dict: ç•™è¨€æ•°æ®
    """
    try:
        # è§„èŒƒåŒ–é¡¹ç›®IDï¼ˆç§»é™¤ 'b.' å‰ç¼€ï¼‰
        project_id = normalize_project_id(project_id)
        comments_url = f"{config.AUTODESK_API_BASE}/construction/issues/v1/projects/{project_id}/issues/{issue_id}/comments"
        
        # æ„å»ºæŸ¥è¯¢å‚æ•°
        params = {}
        if pagination:
            if pagination.get('limit'):
                params['limit'] = pagination['limit']
            if pagination.get('offset'):
                params['offset'] = pagination['offset']
        else:
            params['limit'] = 50  # é»˜è®¤é™åˆ¶
        
        # æ³¨æ„: å¦‚æœ API æ”¯æŒ sortï¼Œå¯ä»¥æ·»åŠ  params['sort'] = 'createdAt'
        
        print(f"ğŸ” è·å–è®®é¢˜ç•™è¨€: {issue_id}")
        
        response = requests.get(comments_url, headers=headers, params=params, timeout=(10, 30))
        
        if response.status_code == 200:
            comments_data = response.json()
            print(f"âœ… æˆåŠŸè·å– {len(comments_data.get('results', []))} æ¡ç•™è¨€")
            return {
                "success": True,
                "data": comments_data,
                "total_count": len(comments_data.get('results', []))
            }
        else:
            print(f"âŒ è·å–è®®é¢˜ç•™è¨€å¤±è´¥: {response.status_code} - {response.text}")
            return {
                "success": False,
                "error": f"HTTP {response.status_code}: {response.text}",
                "status_code": response.status_code
            }
            
    except Exception as e:
        print(f"âŒ è·å–è®®é¢˜ç•™è¨€æ—¶å‡ºé”™: {str(e)}")
        return {
            "success": False,
            "error": str(e)
        }


def get_issue_attachments(project_id, issue_id, headers):
    """
    è·å–è®®é¢˜çš„é™„ä»¶
    
    Args:
        project_id (str): é¡¹ç›®ID
        issue_id (str): è®®é¢˜ID
        headers (dict): è¯·æ±‚å¤´
    
    Returns:
        dict: é™„ä»¶æ•°æ®
    """
    try:
        # è§„èŒƒåŒ–é¡¹ç›®IDï¼ˆç§»é™¤ 'b.' å‰ç¼€ï¼‰
        project_id = normalize_project_id(project_id)
        attachments_url = f"{config.AUTODESK_API_BASE}/construction/issues/v1/projects/{project_id}/attachments/{issue_id}/items"
        
        print(f"ğŸ” è·å–è®®é¢˜é™„ä»¶: {issue_id}")
        
        response = requests.get(attachments_url, headers=headers, timeout=(10, 30))
        
        if response.status_code == 200:
            attachments_data = response.json()
            # Autodesk Issues API è¿”å›çš„é™„ä»¶æ•¸æ“šåœ¨ 'attachments' å­—æ®µä¸­ï¼Œè€Œä¸æ˜¯ 'results'
            attachments_list = attachments_data.get('attachments', [])
            print(f"âœ… æˆåŠŸè·å– {len(attachments_list)} ä¸ªé™„ä»¶")
            
            # ç‚ºäº†ä¿æŒèˆ‡å‰ç«¯çš„å…¼å®¹æ€§ï¼Œå°‡æ•¸æ“šæ ¼å¼åŒ–ç‚ºæœŸæœ›çš„çµæ§‹
            formatted_response = {
                "results": attachments_list,
                "pagination": attachments_data.get('pagination', {}),
                "raw_data": attachments_data  # ä¿ç•™åŸå§‹æ•¸æ“šä¾›èª¿è©¦
            }
            
            return {
                "success": True,
                "data": formatted_response,
                "total_count": len(attachments_list)
            }
        else:
            print(f"âŒ è·å–è®®é¢˜é™„ä»¶å¤±è´¥: {response.status_code} - {response.text}")
            return {
                "success": False,
                "error": f"HTTP {response.status_code}: {response.text}",
                "status_code": response.status_code
            }
            
    except Exception as e:
        print(f"âŒ è·å–è®®é¢˜é™„ä»¶æ—¶å‡ºé”™: {str(e)}")
        return {
            "success": False,
            "error": str(e)
        }


def sync_issues_incremental(project_id, headers, last_sync_time=None, batch_size=100):
    """
    å¢é‡åŒæ­¥è®®é¢˜æ•°æ®
    
    Args:
        project_id (str): é¡¹ç›®ID
        headers (dict): è¯·æ±‚å¤´
        last_sync_time (str): ä¸Šæ¬¡åŒæ­¥æ—¶é—´ (ISOæ ¼å¼)
        batch_size (int): æ‰¹æ¬¡å¤§å°
    
    Returns:
        dict: åŒæ­¥ç»“æœ
    """
    try:
        # è§„èŒƒåŒ–é¡¹ç›®IDï¼ˆç§»é™¤ 'b.' å‰ç¼€ï¼‰
        project_id = normalize_project_id(project_id)
        print(f"ğŸ”„ å¼€å§‹å¢é‡åŒæ­¥è®®é¢˜: {project_id}")
        
        # å¦‚æœæ²¡æœ‰æŒ‡å®šä¸Šæ¬¡åŒæ­¥æ—¶é—´ï¼Œä½¿ç”¨24å°æ—¶å‰
        if not last_sync_time:
            last_sync_time = (datetime.now() - timedelta(hours=24)).isoformat()
        
        print(f"ğŸ“… åŒæ­¥æ—¶é—´èŒƒå›´: {last_sync_time} è‡³ä»Š")
        
        # è®¾ç½®è¿‡æ»¤æ¡ä»¶ - è·å–æŒ‡å®šæ—¶é—´åæ›´æ–°çš„è®®é¢˜
        filters = {
            'updatedSince': last_sync_time
        }
        
        all_issues = []
        offset = 0
        has_more = True
        
        while has_more:
            pagination = {
                'limit': batch_size,
                'offset': offset
            }
            
            # è·å–è®®é¢˜åˆ—è¡¨
            result = get_issues_list(project_id, headers, filters, pagination)
            
            if not result['success']:
                return {
                    "success": False,
                    "error": f"è·å–è®®é¢˜åˆ—è¡¨å¤±è´¥: {result['error']}"
                }
            
            issues_batch = result['data'].get('results', [])
            all_issues.extend(issues_batch)
            
            # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æ›´å¤šæ•°æ®
            has_more = result.get('has_more', False) and len(issues_batch) == batch_size
            offset += batch_size
            
            print(f"ğŸ“‹ å·²è·å– {len(all_issues)} ä¸ªæ›´æ–°çš„è®®é¢˜")
        
        # ä¸ºæ¯ä¸ªè®®é¢˜è·å–è¯¦ç»†ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
        enhanced_issues = []
        for issue in all_issues:
            issue_id = issue.get('id')
            if issue_id:
                # è·å–è®®é¢˜è¯¦æƒ…
                details_result = get_issue_details(project_id, issue_id, headers)
                if details_result['success']:
                    enhanced_issue = details_result['data']
                    
                    # è·å–ç•™è¨€æ•°é‡ï¼ˆä¸è·å–å…·ä½“å†…å®¹ä»¥æé«˜æ€§èƒ½ï¼‰
                    comments_result = get_issue_comments(project_id, issue_id, headers, {'limit': 1})
                    if comments_result['success']:
                        enhanced_issue['comments_available'] = comments_result['total_count'] > 0
                    
                    # è·å–é™„ä»¶æ•°é‡
                    attachments_result = get_issue_attachments(project_id, issue_id, headers)
                    if attachments_result['success']:
                        enhanced_issue['attachments_available'] = attachments_result['total_count'] > 0
                        enhanced_issue['attachments_count'] = attachments_result['total_count']
                    
                    enhanced_issues.append(enhanced_issue)
                else:
                    # å¦‚æœæ— æ³•è·å–è¯¦æƒ…ï¼Œä½¿ç”¨åŸå§‹æ•°æ®
                    enhanced_issues.append(issue)
        
        sync_result = {
            "success": True,
            "sync_time": datetime.now().isoformat(),
            "last_sync_time": last_sync_time,
            "total_issues": len(enhanced_issues),
            "issues": enhanced_issues,
            "statistics": {
                "new_issues": 0,
                "updated_issues": len(enhanced_issues),
                "closed_issues": 0
            }
        }
        
        # åˆ†æè®®é¢˜çŠ¶æ€ç»Ÿè®¡
        status_counts = {}
        for issue in enhanced_issues:
            status = issue.get('status', 'unknown')
            status_counts[status] = status_counts.get(status, 0) + 1
        
        sync_result['statistics']['status_breakdown'] = status_counts
        
        print(f"âœ… å¢é‡åŒæ­¥å®Œæˆ: {len(enhanced_issues)} ä¸ªè®®é¢˜")
        return sync_result
        
    except Exception as e:
        print(f"âŒ å¢é‡åŒæ­¥è®®é¢˜æ—¶å‡ºé”™: {str(e)}")
        return {
            "success": False,
            "error": str(e)
        }


# API è·¯ç”±å®šä¹‰

@issues_bp.route('/api/issues/projects/<project_id>/list')
def get_issues_list_api(project_id):
    """è·å–é¡¹ç›®è®®é¢˜åˆ—è¡¨çš„APIç«¯ç‚¹"""
    access_token = utils.get_access_token()
    if not access_token:
        return jsonify({
            "error": "æœªæ‰¾åˆ° Access Tokenï¼Œè¯·å…ˆè¿›è¡Œè®¤è¯",
            "status": "unauthorized"
        }), 401
    
    headers = {
        "Authorization": f"Bearer {access_token}",
        "Content-Type": "application/json"
    }
    
    try:
        start_time = time.time()
        print(f"ğŸš€ [ä¼˜åŒ–] è·å–è®®é¢˜åˆ—è¡¨: {project_id}")
        
        # è·å–æŸ¥è¯¢å‚æ•°
        filters = {}
        if request.args.get('status'):
            filters['status'] = request.args.get('status')
        if request.args.get('assignedTo'):
            filters['assignedTo'] = request.args.get('assignedTo')
        if request.args.get('issueTypeId'):
            filters['issueTypeId'] = request.args.get('issueTypeId')
        if request.args.get('updatedSince'):
            filters['updatedSince'] = request.args.get('updatedSince')
        if request.args.get('createdSince'):
            filters['createdSince'] = request.args.get('createdSince')
        
        # ä¼˜åŒ–ï¼šé™åˆ¶é»˜è®¤è¯·æ±‚é‡ï¼Œæé«˜å“åº”é€Ÿåº¦
        requested_limit = request.args.get('limit', DEFAULT_ISSUES_LIMIT, type=int)
        if requested_limit > 100:
            print(f"âš ï¸ è¯·æ±‚é‡è¿‡å¤§ ({requested_limit})ï¼Œé™åˆ¶ä¸º100ä»¥æé«˜æ€§èƒ½")
            requested_limit = 100
            
        pagination = {
            'limit': requested_limit,
            'offset': request.args.get('offset', 0, type=int)
        }
        
        # æ˜¯å¦åŒ…å«ç»Ÿè®¡ä¿¡æ¯
        include_stats = request.args.get('include_stats', 'true').lower() == 'true'
        
        result = get_issues_list(project_id, headers, filters, pagination)
        
        if result['success']:
            response_data = {
                "status": "success",
                "project_id": project_id,
                "data": result['data'],
                "pagination": {
                    "limit": pagination['limit'],
                    "offset": pagination['offset'],
                    "has_more": result.get('has_more', False)
                },
                "response_time_seconds": round(time.time() - start_time, 2)
            }
            
            # ä¼˜åŒ–ï¼šåŸºäºå½“å‰æ•°æ®è®¡ç®—å¿«é€Ÿç»Ÿè®¡ä¿¡æ¯ï¼Œé¿å…é‡å¤APIè°ƒç”¨
            if include_stats:
                issues = result['data'].get('results', [])
                quick_stats = calculate_quick_statistics(issues)
                response_data['quick_statistics'] = quick_stats
                print(f"âœ… åŒ…å«å¿«é€Ÿç»Ÿè®¡ä¿¡æ¯: {len(issues)} ä¸ªè®®é¢˜")
            
            print(f"âœ… [ä¼˜åŒ–] è®®é¢˜åˆ—è¡¨è·å–å®Œæˆ: {len(result['data'].get('results', []))} ä¸ªè®®é¢˜ï¼Œè€—æ—¶: {response_data['response_time_seconds']}s")
            
            return jsonify(response_data)
        else:
            return jsonify({
                "status": "error",
                "error": result['error'],
                "project_id": project_id,
                "response_time_seconds": round(time.time() - start_time, 2)
            }), result.get('status_code', 500)
            
    except Exception as e:
        print(f"âŒ è®®é¢˜åˆ—è¡¨APIå‡ºé”™: {str(e)}")
        return jsonify({
            "status": "error",
            "error": f"è·å–è®®é¢˜åˆ—è¡¨å¤±è´¥: {str(e)}"
        }), 500


@issues_bp.route('/api/issues/projects/<project_id>/issues/<issue_id>')
def get_issue_details_api(project_id, issue_id):
    """è·å–å•ä¸€è®®é¢˜è¯¦ç»†ä¿¡æ¯çš„APIç«¯ç‚¹"""
    access_token = utils.get_access_token()
    if not access_token:
        return jsonify({
            "error": "æœªæ‰¾åˆ° Access Tokenï¼Œè¯·å…ˆè¿›è¡Œè®¤è¯",
            "status": "unauthorized"
        }), 401
    
    headers = {
        "Authorization": f"Bearer {access_token}",
        "Content-Type": "application/json"
    }
    
    try:
        # æ£€æŸ¥æ˜¯å¦éœ€è¦å¢å¼ºlinkedDocumentsä¿¡æ¯
        enhance_documents = request.args.get('enhanceDocuments', 'true').lower() == 'true'
        
        result = get_issue_details(project_id, issue_id, headers, enhance_documents)
        
        if result['success']:
            response_data = {
                "status": "success",
                "project_id": project_id,
                "issue_id": issue_id,
                "data": result['data']
            }
            
            # å¦‚æœå¯ç”¨äº†æ–‡æ¡£å¢å¼ºï¼Œæ·»åŠ ç›¸å…³ä¿¡æ¯
            if enhance_documents:
                linked_docs = result['data'].get('linkedDocuments', [])
                enhanced_count = sum(1 for doc in linked_docs if doc.get('enhanced_info'))
                response_data['enhancement_info'] = {
                    'documents_enhanced': enhanced_count,
                    'total_documents': len(linked_docs),
                    'enhancement_enabled': True
                }
            else:
                response_data['enhancement_info'] = {
                    'enhancement_enabled': False
                }
            
            return jsonify(response_data)
        else:
            return jsonify({
                "status": "error",
                "error": result['error'],
                "project_id": project_id,
                "issue_id": issue_id
            }), result.get('status_code', 500)
            
    except Exception as e:
        print(f"âŒ è®®é¢˜è¯¦æƒ…APIå‡ºé”™: {str(e)}")
        return jsonify({
            "status": "error",
            "error": f"è·å–è®®é¢˜è¯¦æƒ…å¤±è´¥: {str(e)}"
        }), 500


@issues_bp.route('/api/issues/projects/<project_id>/issues/<issue_id>/comments')
def get_issue_comments_api(project_id, issue_id):
    """è·å–è®®é¢˜ç•™è¨€çš„APIç«¯ç‚¹"""
    access_token = utils.get_access_token()
    if not access_token:
        return jsonify({
            "error": "æœªæ‰¾åˆ° Access Tokenï¼Œè¯·å…ˆè¿›è¡Œè®¤è¯",
            "status": "unauthorized"
        }), 401
    
    headers = {
        "Authorization": f"Bearer {access_token}",
        "Content-Type": "application/json"
    }
    
    try:
        # åˆ†é¡µå‚æ•°
        pagination = {
            'limit': request.args.get('limit', 50, type=int),
            'offset': request.args.get('offset', 0, type=int)
        }
        
        result = get_issue_comments(project_id, issue_id, headers, pagination)
        
        if result['success']:
            return jsonify({
                "status": "success",
                "project_id": project_id,
                "issue_id": issue_id,
                "data": result['data'],
                "pagination": pagination
            })
        else:
            return jsonify({
                "status": "error",
                "error": result['error'],
                "project_id": project_id,
                "issue_id": issue_id
            }), result.get('status_code', 500)
            
    except Exception as e:
        print(f"âŒ è®®é¢˜ç•™è¨€APIå‡ºé”™: {str(e)}")
        return jsonify({
            "status": "error",
            "error": f"è·å–è®®é¢˜ç•™è¨€å¤±è´¥: {str(e)}"
        }), 500


@issues_bp.route('/api/issues/projects/<project_id>/issues/<issue_id>/attachments')
def get_issue_attachments_api(project_id, issue_id):
    """è·å–è®®é¢˜é™„ä»¶çš„APIç«¯ç‚¹"""
    access_token = utils.get_access_token()
    if not access_token:
        return jsonify({
            "error": "æœªæ‰¾åˆ° Access Tokenï¼Œè¯·å…ˆè¿›è¡Œè®¤è¯",
            "status": "unauthorized"
        }), 401
    
    headers = {
        "Authorization": f"Bearer {access_token}",
        "Content-Type": "application/json"
    }
    
    try:
        result = get_issue_attachments(project_id, issue_id, headers)
        
        if result['success']:
            return jsonify({
                "status": "success",
                "project_id": project_id,
                "issue_id": issue_id,
                "data": result['data']
            })
        else:
            return jsonify({
                "status": "error",
                "error": result['error'],
                "project_id": project_id,
                "issue_id": issue_id
            }), result.get('status_code', 500)
            
    except Exception as e:
        print(f"âŒ è®®é¢˜é™„ä»¶APIå‡ºé”™: {str(e)}")
        return jsonify({
            "status": "error",
            "error": f"è·å–è®®é¢˜é™„ä»¶å¤±è´¥: {str(e)}"
        }), 500


@issues_bp.route('/api/issues/projects/<project_id>/sync')
def sync_issues_api(project_id):
    """å¢é‡åŒæ­¥è®®é¢˜çš„APIç«¯ç‚¹"""
    access_token = utils.get_access_token()
    if not access_token:
        return jsonify({
            "error": "æœªæ‰¾åˆ° Access Tokenï¼Œè¯·å…ˆè¿›è¡Œè®¤è¯",
            "status": "unauthorized"
        }), 401
    
    headers = {
        "Authorization": f"Bearer {access_token}",
        "Content-Type": "application/json"
    }
    
    try:
        # è·å–åŒæ­¥å‚æ•°
        last_sync_time = request.args.get('lastSyncTime')
        batch_size = request.args.get('batchSize', 100, type=int)
        include_details = request.args.get('includeDetails', 'true').lower() == 'true'
        
        print(f"ğŸ”„ å¼€å§‹åŒæ­¥è®®é¢˜ - é¡¹ç›®: {project_id}, ä¸Šæ¬¡åŒæ­¥: {last_sync_time}")
        
        result = sync_issues_incremental(project_id, headers, last_sync_time, batch_size)
        
        if result['success']:
            response_data = {
                "status": "success",
                "project_id": project_id,
                "sync_result": result
            }
            
            # å¦‚æœä¸éœ€è¦è¯¦ç»†ä¿¡æ¯ï¼Œç§»é™¤è®®é¢˜è¯¦æƒ…ä»¥å‡å°‘å“åº”å¤§å°
            if not include_details:
                simplified_issues = []
                for issue in result['issues']:
                    simplified_issue = {
                        'id': issue.get('id'),
                        'displayId': issue.get('displayId'),
                        'title': issue.get('title'),
                        'status': issue.get('status'),
                        'updatedAt': issue.get('updatedAt'),
                        'assignedTo': issue.get('assignedTo')
                    }
                    simplified_issues.append(simplified_issue)
                
                response_data['sync_result']['issues'] = simplified_issues
            
            return jsonify(response_data)
        else:
            return jsonify({
                "status": "error",
                "error": result['error'],
                "project_id": project_id
            }), 500
            
    except Exception as e:
        print(f"âŒ åŒæ­¥è®®é¢˜APIå‡ºé”™: {str(e)}")
        return jsonify({
            "status": "error",
            "error": f"åŒæ­¥è®®é¢˜å¤±è´¥: {str(e)}"
        }), 500


@issues_bp.route('/api/issues/projects/<project_id>/user-profile')
def get_user_profile_api(project_id):
    """è·å–å½“å‰ç”¨æˆ·æ¡£æ¡ˆçš„APIç«¯ç‚¹"""
    access_token = utils.get_access_token()
    if not access_token:
        return jsonify({
            "error": "æœªæ‰¾åˆ° Access Tokenï¼Œè¯·å…ˆè¿›è¡Œè®¤è¯",
            "status": "unauthorized"
        }), 401
    
    headers = {
        "Authorization": f"Bearer {access_token}",
        "Content-Type": "application/json"
    }
    
    try:
        result = get_user_profile(project_id, headers)
        
        if result['success']:
            return jsonify({
                "status": "success",
                "project_id": project_id,
                "data": result['data']
            })
        else:
            return jsonify({
                "status": "error",
                "error": result['error'],
                "project_id": project_id
            }), result.get('status_code', 500)
            
    except Exception as e:
        print(f"âŒ ç”¨æˆ·æ¡£æ¡ˆAPIå‡ºé”™: {str(e)}")
        return jsonify({
            "status": "error",
            "error": f"è·å–ç”¨æˆ·æ¡£æ¡ˆå¤±è´¥: {str(e)}"
        }), 500


@issues_bp.route('/api/issues/projects/<project_id>/issue-types')
def get_issue_types_api(project_id):
    """è·å–è®®é¢˜ç±»å‹çš„APIç«¯ç‚¹"""
    access_token = utils.get_access_token()
    if not access_token:
        return jsonify({
            "error": "æœªæ‰¾åˆ° Access Tokenï¼Œè¯·å…ˆè¿›è¡Œè®¤è¯",
            "status": "unauthorized"
        }), 401
    
    headers = {
        "Authorization": f"Bearer {access_token}",
        "Content-Type": "application/json"
    }
    
    try:
        # è·å–æŸ¥è¯¢å‚æ•°
        include_subtypes = request.args.get('includeSubtypes', 'false').lower() == 'true'
        
        filters = {}
        if request.args.get('updatedAt'):
            filters['updatedAt'] = request.args.get('updatedAt')
        if request.args.get('isActive'):
            filters['isActive'] = request.args.get('isActive').lower() == 'true'
        
        pagination = {
            'limit': request.args.get('limit', 100, type=int),
            'offset': request.args.get('offset', 0, type=int)
        }
        
        result = get_issue_types(project_id, headers, include_subtypes, filters, pagination)
        
        if result['success']:
            return jsonify({
                "status": "success",
                "project_id": project_id,
                "data": result['data']
            })
        else:
            return jsonify({
                "status": "error",
                "error": result['error'],
                "project_id": project_id
            }), result.get('status_code', 500)
            
    except Exception as e:
        print(f"âŒ è®®é¢˜ç±»å‹APIå‡ºé”™: {str(e)}")
        return jsonify({
            "status": "error",
            "error": f"è·å–è®®é¢˜ç±»å‹å¤±è´¥: {str(e)}"
        }), 500


@issues_bp.route('/api/issues/projects/<project_id>/attribute-definitions')
def get_attribute_definitions_api(project_id):
    """è·å–å±æ€§å®šä¹‰çš„APIç«¯ç‚¹"""
    access_token = utils.get_access_token()
    if not access_token:
        return jsonify({
            "error": "æœªæ‰¾åˆ° Access Tokenï¼Œè¯·å…ˆè¿›è¡Œè®¤è¯",
            "status": "unauthorized"
        }), 401
    
    headers = {
        "Authorization": f"Bearer {access_token}",
        "Content-Type": "application/json"
    }
    
    try:
        filters = {}
        if request.args.get('dataType'):
            filters['dataType'] = request.args.get('dataType')
        
        pagination = {
            'limit': request.args.get('limit', 200, type=int),
            'offset': request.args.get('offset', 0, type=int)
        }
        
        result = get_attribute_definitions(project_id, headers, filters, pagination)
        
        if result['success']:
            return jsonify({
                "status": "success",
                "project_id": project_id,
                "data": result['data']
            })
        else:
            return jsonify({
                "status": "error",
                "error": result['error'],
                "project_id": project_id
            }), result.get('status_code', 500)
            
    except Exception as e:
        print(f"âŒ å±æ€§å®šä¹‰APIå‡ºé”™: {str(e)}")
        return jsonify({
            "status": "error",
            "error": f"è·å–å±æ€§å®šä¹‰å¤±è´¥: {str(e)}"
        }), 500


@issues_bp.route('/api/issues/projects/<project_id>/attribute-mappings')
def get_attribute_mappings_api(project_id):
    """è·å–å±æ€§æ˜ å°„çš„APIç«¯ç‚¹"""
    access_token = utils.get_access_token()
    if not access_token:
        return jsonify({
            "error": "æœªæ‰¾åˆ° Access Tokenï¼Œè¯·å…ˆè¿›è¡Œè®¤è¯",
            "status": "unauthorized"
        }), 401
    
    headers = {
        "Authorization": f"Bearer {access_token}",
        "Content-Type": "application/json"
    }
    
    try:
        filters = {}
        if request.args.get('attributeDefinitionId'):
            filters['attributeDefinitionId'] = request.args.get('attributeDefinitionId')
        if request.args.get('mappedItemId'):
            filters['mappedItemId'] = request.args.get('mappedItemId')
        
        pagination = {
            'limit': request.args.get('limit', 200, type=int),
            'offset': request.args.get('offset', 0, type=int)
        }
        
        result = get_attribute_mappings(project_id, headers, filters, pagination)
        
        if result['success']:
            return jsonify({
                "status": "success",
                "project_id": project_id,
                "data": result['data']
            })
        else:
            return jsonify({
                "status": "error",
                "error": result['error'],
                "project_id": project_id
            }), result.get('status_code', 500)
            
    except Exception as e:
        print(f"âŒ å±æ€§æ˜ å°„APIå‡ºé”™: {str(e)}")
        return jsonify({
            "status": "error",
            "error": f"è·å–å±æ€§æ˜ å°„å¤±è´¥: {str(e)}"
        }), 500


@issues_bp.route('/api/issues/projects/<project_id>/root-cause-categories')
def get_root_cause_categories_api(project_id):
    """è·å–æ ¹æœ¬åŸå› ç±»åˆ«çš„APIç«¯ç‚¹"""
    access_token = utils.get_access_token()
    if not access_token:
        return jsonify({
            "error": "æœªæ‰¾åˆ° Access Tokenï¼Œè¯·å…ˆè¿›è¡Œè®¤è¯",
            "status": "unauthorized"
        }), 401
    
    headers = {
        "Authorization": f"Bearer {access_token}",
        "Content-Type": "application/json"
    }
    
    try:
        include_root_causes = request.args.get('includeRootCauses', 'false').lower() == 'true'
        
        pagination = {
            'limit': request.args.get('limit', 100, type=int),
            'offset': request.args.get('offset', 0, type=int)
        }
        
        result = get_root_cause_categories(project_id, headers, include_root_causes, None, pagination)
        
        if result['success']:
            return jsonify({
                "status": "success",
                "project_id": project_id,
                "data": result['data']
            })
        else:
            return jsonify({
                "status": "error",
                "error": result['error'],
                "project_id": project_id
            }), result.get('status_code', 500)
            
    except Exception as e:
        print(f"âŒ æ ¹æœ¬åŸå› ç±»åˆ«APIå‡ºé”™: {str(e)}")
        return jsonify({
            "status": "error",
            "error": f"è·å–æ ¹æœ¬åŸå› ç±»åˆ«å¤±è´¥: {str(e)}"
        }), 500


@issues_bp.route('/api/issues/containers/<container_id>/markups')
def get_markups_api(container_id):
    """è·å–æ ‡è®°çš„APIç«¯ç‚¹"""
    access_token = utils.get_access_token()
    if not access_token:
        return jsonify({
            "error": "æœªæ‰¾åˆ° Access Tokenï¼Œè¯·å…ˆè¿›è¡Œè®¤è¯",
            "status": "unauthorized"
        }), 401
    
    headers = {
        "Authorization": f"Bearer {access_token}",
        "Content-Type": "application/vnd.api+json"  # Required by Markups API
    }
    
    # Add x-user-id header for two-legged authentication as required by Markups API
    # This is critical for the API to work properly
    try:
        # Get user ID from user profile API
        user_resp = requests.get(
            f"{config.AUTODESK_API_BASE}/userprofile/v1/users/@me",
            headers={"Authorization": f"Bearer {access_token}"},
            timeout=(5, 10)
        )
        
        if user_resp.status_code == 200:
            user_data = user_resp.json()
            user_id = user_data.get('userId')
            if user_id:
                headers['x-user-id'] = user_id
                print(f"ğŸ”‘ æ·»åŠ  x-user-id header: {user_id}")
            else:
                print("âš ï¸ ç”¨æˆ·èµ„æ–™ä¸­æœªæ‰¾åˆ°userIdï¼Œå¯èƒ½å½±å“Markups APIè®¿é—®")
        else:
            print(f"âš ï¸ è·å–ç”¨æˆ·èµ„æ–™å¤±è´¥ ({user_resp.status_code})ï¼Œå¯èƒ½å½±å“Markups APIè®¿é—®")
    except Exception as e:
        print(f"âš ï¸ è·å–ç”¨æˆ·IDæ—¶å‡ºé”™: {str(e)}")
        # Continue without x-user-id header
    
    try:
        filters = {}
        if request.args.get('target_urn'):
            filters['target_urn'] = request.args.get('target_urn')
        if request.args.get('status'):
            filters['status'] = request.args.get('status')
        if request.args.get('created_by'):
            filters['created_by'] = request.args.get('created_by')
        
        pagination = {
            'limit': request.args.get('limit', 10, type=int),
            'offset': request.args.get('offset', 0, type=int)
        }
        
        sort = request.args.get('sort')
        
        result = get_markups(container_id, headers, filters, pagination, sort)
        
        if result['success']:
            return jsonify({
                "status": "success",
                "container_id": container_id,
                "data": result['data']
            })
        else:
            return jsonify({
                "status": "error",
                "error": result['error'],
                "container_id": container_id
            }), result.get('status_code', 500)
            
    except Exception as e:
        print(f"âŒ æ ‡è®°APIå‡ºé”™: {str(e)}")
        return jsonify({
            "status": "error",
            "error": f"è·å–æ ‡è®°å¤±è´¥: {str(e)}"
        }), 500


@issues_bp.route('/api/issues/projects/<project_id>/statistics')
def get_issues_statistics_api(project_id):
    """è·å–é¡¹ç›®è®®é¢˜ç»Ÿè®¡ä¿¡æ¯çš„APIç«¯ç‚¹ - ä¼˜åŒ–ç‰ˆæœ¬"""
    access_token = utils.get_access_token()
    if not access_token:
        return jsonify({
            "error": "æœªæ‰¾åˆ° Access Tokenï¼Œè¯·å…ˆè¿›è¡Œè®¤è¯",
            "status": "unauthorized"
        }), 401
    
    headers = {
        "Authorization": f"Bearer {access_token}",
        "Content-Type": "application/json"
    }
    
    try:
        start_time = time.time()
        print(f"ğŸ“Š [ä¼˜åŒ–] è·å–è®®é¢˜ç»Ÿè®¡ä¿¡æ¯: {project_id}")
        
        # ä¼˜åŒ–ï¼šæ£€æŸ¥æ˜¯å¦éœ€è¦å®Œæ•´ç»Ÿè®¡
        full_stats = request.args.get('full', 'false').lower() == 'true'
        
        if not full_stats:
            # å¿«é€Ÿæ¨¡å¼ï¼šåªè·å–ç¬¬ä¸€é¡µæ•°æ®è¿›è¡Œä¼°ç®—
            print("âš¡ ä½¿ç”¨å¿«é€Ÿç»Ÿè®¡æ¨¡å¼")
            result = get_issues_list(project_id, headers, pagination={'limit': 100, 'offset': 0})
            
            if not result['success']:
                return jsonify({
                    "status": "error",
                    "error": result['error'],
                    "project_id": project_id
                }), result.get('status_code', 500)
            
            issues = result['data'].get('results', [])
            quick_stats = calculate_quick_statistics(issues)
            
            return jsonify({
                "status": "success",
                "project_id": project_id,
                "statistics": quick_stats,
                "mode": "quick",
                "response_time_seconds": round(time.time() - start_time, 2)
            })
        
        # å®Œæ•´æ¨¡å¼ï¼šè·å–æ‰€æœ‰æ•°æ®ï¼ˆä¿ç•™åŸæœ‰é€»è¾‘ï¼‰
        print("ğŸ”„ ä½¿ç”¨å®Œæ•´ç»Ÿè®¡æ¨¡å¼ï¼ˆè¾ƒæ…¢ï¼‰")
        all_issues = []
        offset = 0
        batch_size = BATCH_SIZE  # ä½¿ç”¨ 50 è·å¾—æœ€ä½³æ€§èƒ½
        
        while True:
            result = get_issues_list(project_id, headers, pagination={'limit': batch_size, 'offset': offset})
            
            if not result['success']:
                return jsonify({
                    "status": "error",
                    "error": result['error'],
                    "project_id": project_id,
                    "response_time_seconds": round(time.time() - start_time, 2)
                }), result.get('status_code', 500)
            
            batch_issues = result['data'].get('results', [])
            if not batch_issues:
                break  # æ²¡æœ‰æ›´å¤šæ•°æ®
                
            all_issues.extend(batch_issues)
            
            # å¦‚æœè¿”å›çš„æ•°æ®å°‘äºè¯·æ±‚çš„é™åˆ¶ï¼Œè¯´æ˜å·²ç»æ˜¯æœ€åä¸€é¡µ
            if len(batch_issues) < batch_size:
                break
                
            offset += batch_size
            print(f"ğŸ“Š å·²è·å– {len(all_issues)} ä¸ªè®®é¢˜ï¼Œç»§ç»­è·å–...")
        
        print(f"ğŸ“Š ç»Ÿè®¡å®Œæˆï¼Œå…± {len(all_issues)} ä¸ªè®®é¢˜")
        issues = all_issues
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        statistics = {
            "total_issues": len(issues),
            "status_breakdown": {},
            "priority_breakdown": {},
            "assignee_breakdown": {},
            "type_breakdown": {},
            "recent_activity": {
                "created_last_7_days": 0,
                "updated_last_7_days": 0,
                "closed_last_7_days": 0
            }
        }
        
        # æ—¶é—´è®¡ç®—
        now = datetime.now()
        seven_days_ago = now - timedelta(days=7)
        
        for issue in issues:
            # çŠ¶æ€ç»Ÿè®¡
            status = issue.get('status', 'unknown')
            statistics['status_breakdown'][status] = statistics['status_breakdown'].get(status, 0) + 1
            
            # ä¼˜å…ˆçº§ç»Ÿè®¡
            priority = issue.get('priority', 'unknown')
            statistics['priority_breakdown'][priority] = statistics['priority_breakdown'].get(priority, 0) + 1
            
            # åˆ†é…äººç»Ÿè®¡
            assigned_to = issue.get('assignedTo', 'unassigned')
            statistics['assignee_breakdown'][assigned_to] = statistics['assignee_breakdown'].get(assigned_to, 0) + 1
            
            # ç±»å‹ç»Ÿè®¡
            issue_type = issue.get('issueTypeId', 'unknown')
            statistics['type_breakdown'][issue_type] = statistics['type_breakdown'].get(issue_type, 0) + 1
            
            # æœ€è¿‘æ´»åŠ¨ç»Ÿè®¡
            try:
                created_at = datetime.fromisoformat(issue.get('createdAt', '').replace('Z', '+00:00'))
                if created_at >= seven_days_ago:
                    statistics['recent_activity']['created_last_7_days'] += 1
            except:
                pass
            
            try:
                updated_at = datetime.fromisoformat(issue.get('updatedAt', '').replace('Z', '+00:00'))
                if updated_at >= seven_days_ago:
                    statistics['recent_activity']['updated_last_7_days'] += 1
            except:
                pass
            
            if status in ['closed', 'resolved']:
                try:
                    closed_at = datetime.fromisoformat(issue.get('closedAt', '').replace('Z', '+00:00'))
                    if closed_at >= seven_days_ago:
                        statistics['recent_activity']['closed_last_7_days'] += 1
                except:
                    pass
        
        return jsonify({
            "status": "success",
            "project_id": project_id,
            "statistics": statistics,
            "generated_at": now.isoformat()
        })
        
    except Exception as e:
        print(f"âŒ è·å–è®®é¢˜ç»Ÿè®¡APIå‡ºé”™: {str(e)}")
        return jsonify({
            "status": "error",
            "error": f"è·å–è®®é¢˜ç»Ÿè®¡å¤±è´¥: {str(e)}"
        }), 500


def get_issues_by_file_urn(project_id, file_urn, access_token=None):
    """
    æ ¹æ®æ–‡ä»¶URNè·å–ç›¸å…³çš„è®®é¢˜
    ä½¿ç”¨ç°æœ‰çš„ filter[linkedDocumentUrn] å‚æ•°
    
    Args:
        project_id (str): é¡¹ç›®ID
        file_urn (str): æ–‡ä»¶URN
        access_token (str): è®¿é—®ä»¤ç‰Œï¼ˆå¯é€‰ï¼‰
    
    Returns:
        dict: åŒ…å«ç›¸å…³è®®é¢˜çš„ç»“æœ
    """
    try:
        # è·å–è®¿é—®ä»¤ç‰Œ
        if not access_token:
            access_token = utils.get_access_token()
            
        if not access_token:
            return {
                'success': False,
                'error': 'Access token not found'
            }
        
        # æ„å»ºè¯·æ±‚å¤´
        headers = {
            "Authorization": f"Bearer {access_token}",
            "Content-Type": "application/json"
        }
        
        # æ„å»ºè¿‡æ»¤æ¡ä»¶
        filters = {
            'linkedDocumentUrn': file_urn
        }
        
        # è®¾ç½®åˆ†é¡µå‚æ•°
        pagination = {
            'limit': 100  # è·å–æœ€å¤š100ä¸ªç›¸å…³è®®é¢˜
        }
        
        print(f"ğŸ” æ ¹æ®æ–‡ä»¶URNè·å–ç›¸å…³è®®é¢˜: {file_urn}")
        
        # è°ƒç”¨ç°æœ‰çš„get_issues_listå‡½æ•°
        response = get_issues_list(project_id, headers, filters, pagination)
        
        if response.get('success'):
            issues = response.get('data', {}).get('results', [])
            
            # å¤„ç†è®®é¢˜æ•°æ®ï¼Œæ·»åŠ å…³è”ç±»å‹ä¿¡æ¯
            processed_issues = []
            for issue in issues:
                # åˆ†æå…³è”ç±»å‹
                relation_type = 'unknown'
                relation_info = {}
                
                # æ£€æŸ¥linkedDocuments
                linked_docs = issue.get('linkedDocuments', [])
                for doc in linked_docs:
                    if doc.get('urn') == file_urn:
                        relation_type = 'linked_document'
                        relation_info = {
                            'type': doc.get('type', 'unknown'),
                            'createdBy': doc.get('createdBy'),
                            'createdAt': doc.get('createdAt'),
                            'details': doc.get('details', {})
                        }
                        break
                
                # å¦‚æœæ²¡æœ‰åœ¨linkedDocumentsä¸­æ‰¾åˆ°ï¼Œæ£€æŸ¥pushpin
                if relation_type == 'unknown':
                    # æ£€æŸ¥pushpinå±æ€§ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                    pushpin_attrs = issue.get('pushpinAttributes', [])
                    for pushpin in pushpin_attrs:
                        if file_urn in str(pushpin.get('objectId', '')):
                            relation_type = 'pushpin'
                            relation_info = pushpin
                            break
                
                processed_issue = {
                    'issue': issue,
                    'relation_type': relation_type,
                    'relation_info': relation_info
                }
                processed_issues.append(processed_issue)
            
            result = {
                'success': True,
                'data': {
                    'file_urn': file_urn,
                    'project_id': project_id,
                    'related_issues': processed_issues,
                    'count': len(processed_issues),
                    'total_found': len(issues)
                }
            }
            
            print(f"âœ… æ‰¾åˆ° {len(processed_issues)} ä¸ªä¸æ–‡ä»¶ {file_urn} ç›¸å…³çš„è®®é¢˜")
            return result
        else:
            return response
            
    except Exception as e:
        print(f"âŒ æ ¹æ®æ–‡ä»¶URNè·å–è®®é¢˜å¤±è´¥: {str(e)}")
        return {
            'success': False,
            'error': str(e)
        }


@issues_bp.route('/api/issues/projects/<project_id>/files/<path:file_urn>/issues', methods=['GET'])
def get_issues_by_file_urn_api(project_id, file_urn):
    """
    æ ¹æ®æ–‡ä»¶URNè·å–ç›¸å…³è®®é¢˜çš„APIç«¯ç‚¹
    
    Args:
        project_id (str): é¡¹ç›®ID
        file_urn (str): æ–‡ä»¶URNï¼ˆURLç¼–ç ï¼‰
    
    Returns:
        JSON: ç›¸å…³è®®é¢˜åˆ—è¡¨
    """
    try:
        # URLè§£ç æ–‡ä»¶URN
        from urllib.parse import unquote
        decoded_file_urn = unquote(file_urn)
        
        print(f"ğŸ” APIè¯·æ±‚: è·å–æ–‡ä»¶ç›¸å…³è®®é¢˜")
        print(f"ğŸ“ é¡¹ç›®ID: {project_id}")
        print(f"ğŸ“„ æ–‡ä»¶URN: {decoded_file_urn}")
        
        # è·å–è®¿é—®ä»¤ç‰Œ
        access_token = utils.get_access_token()
        if not access_token:
            return jsonify({
                'success': False,
                'error': 'Access token not found'
            }), 401
        
        # è°ƒç”¨æ ¸å¿ƒå‡½æ•°
        result = get_issues_by_file_urn(project_id, decoded_file_urn, access_token)
        
        if result.get('success'):
            return jsonify(result), 200
        else:
            return jsonify(result), 500
            
    except Exception as e:
        print(f"âŒ æ–‡ä»¶è®®é¢˜APIå‡ºé”™: {str(e)}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500
