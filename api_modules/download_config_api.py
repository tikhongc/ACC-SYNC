# -*- coding: utf-8 -*-
"""
ä¸‹è½½é…ç½® API æ¨¡å—
å¤„ç†æ–‡ä»¶ä¸‹è½½é…ç½®ã€ç¼“å­˜å’Œå¼‚æ­¥ä¸‹è½½åŠŸèƒ½
"""

import requests
import json
import os
import threading
import time
from datetime import datetime, timedelta
from flask import Blueprint, request, jsonify, send_file
from concurrent.futures import ThreadPoolExecutor
import config
import utils
from .urn_download_simple import download_by_urn, download_oss_object

download_config_bp = Blueprint('download_config', __name__)

# ç¼“å­˜é…ç½®
CACHE_DIR = os.path.join(os.path.dirname(__file__), '..', 'cache')
DOWNLOAD_DIR = os.path.join(os.path.dirname(__file__), '..', 'ACC_BACKUP', 'assets')
CACHE_EXPIRY_HOURS = 24  # ç¼“å­˜24å°æ—¶

# å¼‚æ­¥ä¸‹è½½ä»»åŠ¡é˜Ÿåˆ—
download_tasks = {}
executor = None  # å»¶è¿Ÿåˆå§‹åŒ–

def get_executor():
    """è·å–çº¿ç¨‹æ± æ‰§è¡Œå™¨ï¼Œå»¶è¿Ÿåˆå§‹åŒ–"""
    global executor
    if executor is None:
        executor = ThreadPoolExecutor(max_workers=4)
    return executor

def shutdown_executor():
    """å…³é—­çº¿ç¨‹æ± æ‰§è¡Œå™¨"""
    global executor
    if executor is not None:
        print("[Download] Shutting down ThreadPoolExecutor...")
        executor.shutdown(wait=True)
        executor = None
        print("[Download] ThreadPoolExecutor shutdown complete")

# ç¡®ä¿ç›®å½•å­˜åœ¨
os.makedirs(CACHE_DIR, exist_ok=True)
os.makedirs(DOWNLOAD_DIR, exist_ok=True)

def get_project_name_from_cache(project_id):
    """ä»å‰ç«¯localStorageç¼“å­˜ä¸­è·å–é¡¹ç›®åç§°"""
    try:
        # å°è¯•ä»sessionä¸­è·å–é¡¹ç›®ç¼“å­˜ä¿¡æ¯
        from flask import session
        
        # æ£€æŸ¥sessionä¸­æ˜¯å¦æœ‰é¡¹ç›®ä¿¡æ¯
        if 'project_cache' in session:
            project_cache = session['project_cache']
            if isinstance(project_cache, dict) and project_id in project_cache:
                cached_name = project_cache[project_id]
                print(f"âœ… ä»sessionç¼“å­˜è·å–é¡¹ç›®åç§°: {cached_name} (ID: {project_id})")
                return cached_name
        
        # å¦‚æœsessionä¸­æ²¡æœ‰ï¼Œå°è¯•ä»APIè·å–ï¼ˆä½œä¸ºå¤‡é€‰æ–¹æ¡ˆï¼‰
        return get_project_name_by_id_from_api(project_id)
        
    except Exception as e:
        print(f"âŒ ä»ç¼“å­˜è·å–é¡¹ç›®åç§°æ—¶å‡ºé”™: {str(e)}")
        return get_project_name_by_id_from_api(project_id)

def get_project_name_by_id_from_api(project_id):
    """é€šè¿‡é¡¹ç›®IDä»APIè·å–é¡¹ç›®åç§°ï¼ˆå¤‡é€‰æ–¹æ¡ˆï¼‰"""
    try:
        access_token = utils.get_access_token()
        if not access_token:
            print("âš ï¸ æ— æ³•è·å–è®¿é—®ä»¤ç‰Œï¼Œä½¿ç”¨é»˜è®¤é¡¹ç›®åç§°")
            return 'Project Files'
        
        headers = {
            "Authorization": f"Bearer {access_token}",
            "Content-Type": "application/json"
        }
        
        # è·å–Hubä¿¡æ¯
        hubs_resp = requests.get(f"{config.AUTODESK_API_BASE}/project/v1/hubs", headers=headers)
        if hubs_resp.status_code != 200:
            print(f"âš ï¸ æ— æ³•è·å–Hubä¿¡æ¯: {hubs_resp.status_code}")
            return 'Project Files'
            
        hubs_data = hubs_resp.json()
        
        # éå†æ‰€æœ‰HubæŸ¥æ‰¾é¡¹ç›®
        for hub in hubs_data.get('data', []):
            hub_id = hub.get('id')
            
            # è·å–è¯¥Hubä¸‹çš„é¡¹ç›®
            projects_resp = requests.get(
                f"{config.AUTODESK_API_BASE}/project/v1/hubs/{hub_id}/projects",
                headers=headers
            )
            
            if projects_resp.status_code == 200:
                projects_data = projects_resp.json()
                
                for project in projects_data.get('data', []):
                    if project.get('id') == project_id:
                        project_name = project.get('attributes', {}).get('name', 'Project Files')
                        print(f"âœ… æ‰¾åˆ°é¡¹ç›®: {project_name} (ID: {project_id})")
                        return project_name
        
        print(f"âš ï¸ æœªæ‰¾åˆ°é¡¹ç›®ID: {project_id}")
        return 'Project Files'
        
    except Exception as e:
        print(f"âŒ è·å–é¡¹ç›®åç§°æ—¶å‡ºé”™: {str(e)}")
        return 'Project Files'

def get_project_name_by_id(project_id):
    """é€šè¿‡é¡¹ç›®IDè·å–é¡¹ç›®åç§°ï¼ˆä¼˜å…ˆä»ç¼“å­˜è·å–ï¼‰"""
    return get_project_name_from_cache(project_id)

def safe_write_file(file_path, content, filename=None, create_dirs=True):
    """å®‰å…¨å†™å…¥æ–‡ä»¶ï¼Œå¤„ç†æƒé™é”™è¯¯å’Œæ–‡ä»¶åå†²çªï¼Œæ”¯æŒåˆ›å»ºç›®å½•ç»“æ„"""
    try:
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        if create_dirs:
            dir_path = os.path.dirname(file_path)
            os.makedirs(dir_path, exist_ok=True)
        
        # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œæ·»åŠ æ—¶é—´æˆ³é¿å…å†²çª
        if os.path.exists(file_path):
            dir_path = os.path.dirname(file_path)
            base_name, ext = os.path.splitext(os.path.basename(file_path))
            timestamp = int(time.time())
            new_filename = f"{base_name}_{timestamp}{ext}"
            file_path = os.path.join(dir_path, new_filename)
            if filename:
                filename = new_filename
        
        with open(file_path, 'wb') as f:
            f.write(content)
        
        return {
            'success': True,
            'file_path': file_path,
            'filename': filename or os.path.basename(file_path)
        }
        
    except PermissionError as pe:
        print(f"âŒ æƒé™é”™è¯¯ï¼Œå°è¯•ä½¿ç”¨å¤‡ç”¨æ–‡ä»¶å: {str(pe)}")
        # ä½¿ç”¨æ—¶é—´æˆ³åˆ›å»ºå”¯ä¸€æ–‡ä»¶å
        dir_path = os.path.dirname(file_path)
        base_name, ext = os.path.splitext(os.path.basename(file_path))
        timestamp = int(time.time())
        backup_filename = f"{base_name}_backup_{timestamp}{ext}"
        backup_path = os.path.join(dir_path, backup_filename)
        
        with open(backup_path, 'wb') as f:
            f.write(content)
        
        return {
            'success': True,
            'file_path': backup_path,
            'filename': backup_filename
        }
    except Exception as e:
        print(f"âŒ æ–‡ä»¶å†™å…¥å¤±è´¥: {str(e)}")
        return {
            'success': False,
            'error': str(e)
        }

@download_config_bp.route('/api/download-config/projects', methods=['GET'])
def get_available_projects():
    """è·å–å¯ç”¨çš„é¡¹ç›®åˆ—è¡¨"""
    access_token = utils.get_access_token()
    if not access_token:
        return jsonify({
            "error": "æœªæ‰¾åˆ° Access Tokenï¼Œè¯·å…ˆè¿›è¡Œè®¤è¯",
            "status": "unauthorized"
        }), 401
    
    headers = {
        "Authorization": f"Bearer {access_token}",
        "Content-Type": "application/json"
    }
    
    try:
        # è·å–Hubä¿¡æ¯
        hubs_resp = requests.get(f"{config.AUTODESK_API_BASE}/project/v1/hubs", headers=headers)
        if hubs_resp.status_code != 200:
            return jsonify({
                "error": f"æ— æ³•è·å–Hubä¿¡æ¯: {hubs_resp.status_code}",
                "status": "error"
            }), 400
        
        hubs_data = hubs_resp.json()
        projects = []
        
        for hub in hubs_data.get('data', []):
            hub_id = hub.get('id')
            hub_name = hub.get('attributes', {}).get('name', 'Unknown Hub')
            
            # è·å–è¯¥Hubä¸‹çš„é¡¹ç›®
            projects_resp = requests.get(
                f"{config.AUTODESK_API_BASE}/project/v1/hubs/{hub_id}/projects",
                headers=headers
            )
            
            if projects_resp.status_code == 200:
                projects_data = projects_resp.json()
                
                for project in projects_data.get('data', []):
                    project_info = {
                        'id': project.get('id'),
                        'name': project.get('attributes', {}).get('name', 'Unknown Project'),
                        'hub_id': hub_id,
                        'hub_name': hub_name,
                        'type': project.get('attributes', {}).get('extension', {}).get('data', {}).get('projectType', 'Unknown')
                    }
                    projects.append(project_info)
        
        return jsonify({
            "status": "success",
            "projects": projects,
            "count": len(projects)
        })
        
    except Exception as e:
        return jsonify({
            "error": f"è·å–é¡¹ç›®åˆ—è¡¨å¤±è´¥: {str(e)}",
            "status": "error"
        }), 500

@download_config_bp.route('/api/download-config/project/<project_id>/folders', methods=['GET'])
def get_project_folders(project_id):
    """è·å–é¡¹ç›®çš„æ–‡ä»¶å¤¹ç»“æ„"""
    access_token = utils.get_access_token()
    if not access_token:
        return jsonify({
            "error": "æœªæ‰¾åˆ° Access Tokenï¼Œè¯·å…ˆè¿›è¡Œè®¤è¯",
            "status": "unauthorized"
        }), 401
    
    # æ£€æŸ¥ç¼“å­˜
    cache_key = f"folders_{project_id}"
    cached_data = get_cached_data(cache_key)
    if cached_data:
        return jsonify({
            "status": "success",
            "data": cached_data,
            "cached": True
        })
    
    try:
        # è·å–maxDepthå‚æ•°
        max_depth = request.args.get('maxDepth', 20, type=int)
        
        # è·å–é¡¹ç›®æ–‡ä»¶æ ‘ï¼ˆéå†æ‰€æœ‰æ–‡ä»¶æ‰¾å¯»æ–‡ä»¶å¤¹ï¼‰
        tree_url = f"http://localhost:{config.PORT}/api/file-sync/project/{project_id}/tree"
        params = {'maxDepth': max_depth, 'includeVersions': 'false'}  # ä½¿ç”¨åŠ¨æ€æ·±åº¦å‚æ•°
        
        response = requests.get(tree_url, params=params, timeout=60)
        
        if response.status_code == 200:
            data = response.json()
            if data.get('status') == 'success':
                tree_data = data.get('data', {})
                
                # æå–æ–‡ä»¶å¤¹ç»“æ„
                folders = []
                
                def extract_folders(node, path="", level=0):
                    if level > 20:  # å¢åŠ é€’å½’æ·±åº¦ä»¥éå†æ‰€æœ‰æ–‡ä»¶å¤¹
                        return
                    
                    current_path = f"{path}/{node.get('name', '')}" if path else node.get('name', '')
                    
                    if node.get('type') == 'folder':
                        folder_info = {
                            'id': node.get('id'),
                            'name': node.get('name'),
                            'path': current_path,
                            'level': level,
                            'file_count': count_files_in_folder(node),
                            'folder_count': count_folders_in_folder(node)
                        }
                        folders.append(folder_info)
                    
                    for child in node.get('children', []):
                        extract_folders(child, current_path, level + 1)
                
                for top_folder in tree_data.get('top_folders', []):
                    extract_folders(top_folder)
                
                # ç¼“å­˜ç»“æœ
                cache_data(cache_key, folders)
                
                return jsonify({
                    "status": "success",
                    "folders": folders,
                    "count": len(folders),
                    "cached": False
                })
            else:
                return jsonify({
                    "error": data.get('error', 'Unknown error'),
                    "status": "error"
                }), 400
        else:
            return jsonify({
                "error": f"è·å–æ–‡ä»¶å¤¹å¤±è´¥: {response.status_code}",
                "status": "error"
            }), 400
            
    except Exception as e:
        return jsonify({
            "error": f"è·å–æ–‡ä»¶å¤¹å¤±è´¥: {str(e)}",
            "status": "error"
        }), 500

@download_config_bp.route('/api/download-config/project/<project_id>/files', methods=['GET'])
def get_project_files(project_id):
    """è·å–é¡¹ç›®çš„æ–‡ä»¶åˆ—è¡¨"""
    access_token = utils.get_access_token()
    if not access_token:
        return jsonify({
            "error": "æœªæ‰¾åˆ° Access Tokenï¼Œè¯·å…ˆè¿›è¡Œè®¤è¯",
            "status": "unauthorized"
        }), 401
    
    # è·å–æŸ¥è¯¢å‚æ•° - æ”¯æŒå¤šç§æ ¼å¼
    folder_ids = request.args.getlist('folder_ids')  # æ”¯æŒå¤šä¸ªæ–‡ä»¶å¤¹
    if not folder_ids:
        # å°è¯•å…¶ä»–å¯èƒ½çš„å‚æ•°å
        folder_ids = request.args.getlist('folder_ids[]')
    if not folder_ids and 'folder_ids' in request.args:
        # å•ä¸ªå€¼çš„æƒ…å†µ
        folder_ids = [request.args.get('folder_ids')]
    
    file_types = request.args.getlist('file_types')  # æ”¯æŒå¤šä¸ªæ–‡ä»¶ç±»å‹
    if not file_types:
        file_types = request.args.getlist('file_types[]')
    if not file_types and 'file_types' in request.args:
        file_types = [request.args.get('file_types')]
    
    # è°ƒè¯•å‚æ•°è§£æ
    print(f"ğŸ” APIå‚æ•°è§£æ: folder_ids={folder_ids}, file_types={file_types}")
    print(f"ğŸ” åŸå§‹è¯·æ±‚å‚æ•°: {dict(request.args)}")
    
    # è·å–maxDepthå‚æ•°ï¼Œæ”¯æŒæ— é™é€’å½’
    max_depth = request.args.get('maxDepth', 20, type=int)
    # å¦‚æœmaxDepthè®¾ç½®ä¸º999æˆ–æ›´å¤§ï¼Œåˆ™è®¾ç½®ä¸ºä¸€ä¸ªå¾ˆå¤§çš„å€¼æ¥å®ç°æ— é™é€’å½’
    if max_depth >= 999:
        max_depth = 9999  # è®¾ç½®ä¸€ä¸ªå®é™…ä¸Šä¸å¯èƒ½è¾¾åˆ°çš„æ·±åº¦
    
    # å¯¹äºæ–‡ä»¶å¤¹è¿‡æ»¤ï¼Œç¡®ä¿æœ‰è¶³å¤Ÿçš„æ·±åº¦æ¥éå†æ‰€æœ‰å¯èƒ½çš„å­æ–‡ä»¶å¤¹
    if folder_ids and max_depth < 15:
        max_depth = 15  # ç¡®ä¿èƒ½å¤Ÿéå†åˆ°æ·±å±‚åµŒå¥—çš„æ–‡ä»¶å¤¹
        print(f"ğŸ”§ ä¸ºæ–‡ä»¶å¤¹è¿‡æ»¤è°ƒæ•´æœ€å¤§æ·±åº¦åˆ°: {max_depth}")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰æ—¶é—´æˆ³å‚æ•°ï¼Œå¦‚æœæœ‰åˆ™è·³è¿‡ç¼“å­˜
    bypass_cache = request.args.get('_t') is not None
    if bypass_cache:
        print(f"âš¡ æ£€æµ‹åˆ°æ—¶é—´æˆ³å‚æ•°ï¼Œè·³è¿‡ç¼“å­˜ç›´æ¥è·å–æœ€æ–°æ•°æ®")
    
    try:
        
        # ç›´æ¥ä»åç«¯è·å–é¡¹ç›®åç§°
        project_name = get_project_name_by_id(project_id)
        print(f"ğŸ“‹ æ–‡ä»¶é¢„è§ˆAPI - ä»åç«¯è·å–é¡¹ç›®åç§°: '{project_name}', é¡¹ç›®ID: {project_id}")
        
        # æ£€æŸ¥ç¼“å­˜ï¼ˆåŒ…å«é¡¹ç›®åç§°å’Œæœç´¢æ·±åº¦åœ¨ç¼“å­˜é”®ä¸­ï¼‰
        # æ¸…ç†æ–‡ä»¶å¤¹IDä¸­çš„æ— æ•ˆå­—ç¬¦ï¼ˆWindowsæ–‡ä»¶åä¸å…è®¸å†’å·ç­‰å­—ç¬¦ï¼‰
        safe_folder_ids = []
        if folder_ids:
            for folder_id in sorted(folder_ids):
                # ç§»é™¤URNå‰ç¼€å’Œæ— æ•ˆå­—ç¬¦ï¼Œåªä¿ç•™æœ€åçš„IDéƒ¨åˆ†
                safe_id = folder_id.replace('urn:adsk.wipprod:fs.folder:co.', '').replace(':', '_')
                safe_folder_ids.append(safe_id)
        folder_key = '-'.join(safe_folder_ids) if safe_folder_ids else 'all'
        
        file_type_key = '-'.join(sorted(file_types)) if file_types else 'all'
        # ä½¿ç”¨é¡¹ç›®åç§°çš„å®‰å…¨ç‰ˆæœ¬ä½œä¸ºç¼“å­˜é”®çš„ä¸€éƒ¨åˆ†
        safe_project_name = "".join(c for c in project_name if c.isalnum() or c in (' ', '-', '_')).replace(' ', '_')
        # åŒ…å«æœç´¢æ·±åº¦ä»¥åŒºåˆ†ä¸åŒçš„æœç´¢è¯·æ±‚
        depth_key = f"d{max_depth}"
        cache_key = f"files_{project_id}_{safe_project_name}_{folder_key}_{file_type_key}_{depth_key}"
        
        # åªæœ‰åœ¨ä¸è·³è¿‡ç¼“å­˜æ—¶æ‰æ£€æŸ¥å’Œä½¿ç”¨ç¼“å­˜
        if not bypass_cache:
            cached_data = get_cached_data(cache_key)
            if cached_data:
                print(f"ğŸ“¦ ä½¿ç”¨ç¼“å­˜æ•°æ®ï¼Œé¿å…é‡å¤æ–‡ä»¶æ ‘éå†")
                print(f"   ç¼“å­˜é”®: {cache_key}")
                print(f"   ç¼“å­˜æ–‡ä»¶æ•°: {len(cached_data.get('files', []))}")
                return jsonify({
                    "status": "success",
                    "data": cached_data,
                    "cached": True,
                    "message": "ä½¿ç”¨ç¼“å­˜æ•°æ®ï¼Œé¿å…é‡å¤æ–‡ä»¶æ ‘éå†"
                })
        else:
            print(f"âš¡ è·³è¿‡ç¼“å­˜æ£€æŸ¥ï¼Œç›´æ¥è·å–æœ€æ–°æ•°æ®")
        
        # å¦‚æœæœ‰æ–‡ä»¶å¤¹è¿‡æ»¤ï¼Œå…ˆè·å–æ–‡ä»¶å¤¹ç»“æ„å»ºç«‹IDåˆ°è·¯å¾„çš„æ˜ å°„
        folder_path_mapping = {}
        if folder_ids:
            folders_url = f"http://localhost:{config.PORT}/api/download-config/project/{project_id}/folders"
            folders_response = requests.get(folders_url, params={'maxDepth': 10}, timeout=60)
            if folders_response.status_code == 200:
                folders_data = folders_response.json()
                if folders_data.get('status') == 'success':
                    folders_list = folders_data.get('data', [])
                    for folder in folders_list:
                        folder_id = folder.get('id')
                        folder_path = folder.get('path', '')
                        folder_name = folder.get('name', '')
                        if folder_id:
                            folder_path_mapping[folder_id] = {
                                'path': folder_path,
                                'name': folder_name
                            }
            print(f"ğŸ—‚ï¸ å»ºç«‹æ–‡ä»¶å¤¹æ˜ å°„: {len(folder_path_mapping)} ä¸ªæ–‡ä»¶å¤¹")
            # è°ƒè¯•ï¼šæ‰“å°ç›®æ ‡æ–‡ä»¶å¤¹çš„æ˜ å°„ä¿¡æ¯
            for target_folder_id in folder_ids:
                if target_folder_id in folder_path_mapping:
                    mapping_info = folder_path_mapping[target_folder_id]
                    print(f"   ğŸ“ ç›®æ ‡æ–‡ä»¶å¤¹ {target_folder_id}: è·¯å¾„='{mapping_info['path']}', åç§°='{mapping_info['name']}'")
                else:
                    print(f"   âŒ ç›®æ ‡æ–‡ä»¶å¤¹ {target_folder_id} æœªåœ¨æ˜ å°„ä¸­æ‰¾åˆ°")
        
        # ä¼˜åŒ–ï¼šå½“åªéœ€è¦ç‰¹å®šæ–‡ä»¶å¤¹æ—¶ï¼Œä½¿ç”¨æ›´åˆç†çš„æœç´¢æ·±åº¦
        print(f"ğŸ”§ DEBUG: å‡†å¤‡ä½¿ç”¨ max_depth: {max_depth}")
        if folder_ids:
            print(f"ğŸ¯ æ–‡ä»¶å¤¹è¿‡æ»¤æ¨¡å¼ï¼šç›®æ ‡æ–‡ä»¶å¤¹ {folder_ids}")
            # å¯¹äºæ–‡ä»¶å¤¹è¿‡æ»¤ï¼Œç¡®ä¿æœ‰è¶³å¤Ÿçš„æ·±åº¦æ¥éå†æ·±å±‚åµŒå¥—çš„æ–‡ä»¶å¤¹
            # ç‰¹åˆ«æ˜¯testæ–‡ä»¶å¤¹æœ‰11å±‚æ·±çš„åµŒå¥—
            optimized_max_depth = max(max_depth, 25)  # ç¡®ä¿è‡³å°‘25å±‚æ·±åº¦
            print(f"ğŸš€ ä¼˜åŒ–æœç´¢æ·±åº¦ï¼šè°ƒæ•´åˆ° {optimized_max_depth} å±‚ä»¥æ”¯æŒæ·±å±‚åµŒå¥—")
        else:
            optimized_max_depth = max_depth
            print(f"ğŸ”§ DEBUG: ä½¿ç”¨åŸå§‹ max_depth: {optimized_max_depth}")
        
        # è·å–é¡¹ç›®æ–‡ä»¶æ ‘
        tree_url = f"http://localhost:{config.PORT}/api/file-sync/project/{project_id}/tree"
        params = {'maxDepth': optimized_max_depth, 'includeVersions': 'true'}
        
        # å¦‚æœæœ‰ç›®æ ‡æ–‡ä»¶å¤¹è¿‡æ»¤ï¼Œä½¿ç”¨ä¼˜åŒ–çš„éå†ç­–ç•¥
        if folder_ids:
            # æ­£ç¡®ä¼ é€’åˆ—è¡¨å‚æ•°
            for i, folder_id in enumerate(folder_ids):
                params[f'target_folder_ids[{i}]'] = folder_id
            params['optimize_traversal'] = 'true'  # å¯ç”¨åˆ†æ”¯è·³è¿‡ä¼˜åŒ–
            print(f"ğŸ¯ ä¼ é€’ç›®æ ‡æ–‡ä»¶å¤¹è¿‡æ»¤å‚æ•°: {folder_ids}")
            print(f"âš¡ å¯ç”¨åˆ†æ”¯è·³è¿‡ä¼˜åŒ–")
            print(f"ğŸ”§ å‚æ•°æ ¼å¼: {[(k, v) for k, v in params.items() if 'target_folder_ids' in k or 'optimize_traversal' in k]}")
        
        # æ ¹æ®æ·±åº¦è°ƒæ•´è¶…æ—¶æ—¶é—´
        timeout = 180 if optimized_max_depth >= 20 else 120
        
        response = requests.get(tree_url, params=params, timeout=timeout)
        
        if response.status_code == 200:
            data = response.json()
            if data.get('status') == 'success':
                tree_data = data.get('data', {})
                
                # æå–æ–‡ä»¶ä¿¡æ¯å’Œæ–‡ä»¶å¤¾ä¿¡æ¯
                files = []
                folders = []  # æ·»åŠ æ–‡ä»¶å¤¾åˆ—è¡¨
                
                def extract_files(node, path="", proj_name="Project Files", is_root=True, parent_folder_id=None):
                    # ä½¿ç”¨èˆ‡file_sync_apiä¸€è‡´çš„è·¯å¾‘æ§‹å»ºé‚è¼¯
                    node_name = node.get('name', '')
                    node_type = node.get('type', '')
                    
                    # æ„å»ºå½“å‰é¡¹ç›®çš„è·¯å¾„ - èˆ‡file_sync_apiä¿æŒä¸€è‡´
                    if path and path != "Project Files":
                        current_path = f"{path}/{node_name}"
                    else:
                        current_path = node_name
                    
                    # ç¡®å®šå½“å‰èŠ‚ç‚¹çš„æ–‡ä»¶å¤¹ID
                    if node_type == 'folder':
                        current_folder_id = node.get('id')
                        
                        # æ”¶é›†æ–‡ä»¶å¤¹ä¿¡æ¯ï¼ˆè·³éæ ¹ç¯€é» "Project Files"ï¼‰
                        if not (is_root and node_name == 'Project Files'):
                            folder_info = {
                                'id': current_folder_id,
                                'name': node_name,
                                'path': current_path,  # æ–‡ä»¶å¤¹çš„å®Œæ•´è·¯å¾„
                                'parent_id': parent_folder_id
                            }
                            folders.append(folder_info)
                            print(f"   ğŸ“ æ”¶é›†æ–‡ä»¶å¤¾ä¿¡æ¯: {node_name} -> {current_path}")
                    else:
                        current_folder_id = parent_folder_id
                    
                    # è°ƒè¯•ä¿¡æ¯ï¼šæ‰“å°è·¯å¾„æ„å»ºè¿‡ç¨‹
                    node_name = node.get('name', '')
                    node_type = node.get('type', '')
                    print(f"   ğŸ” å¤„ç†èŠ‚ç‚¹: åç§°='{node_name}', ç±»å‹='{node_type}', è·¯å¾„='{current_path}', æ–‡ä»¶å¤¹ID='{current_folder_id}'")
                    
                    # å¦‚æœæ˜¯æ ¹èŠ‚ç‚¹ä¸”åç§°æ˜¯"Project Files"ï¼Œè·³è¿‡è¿™ä¸ªåç§°
                    if is_root and node_name == 'Project Files':
                        # ç›´æ¥å¤„ç†å­èŠ‚ç‚¹ï¼Œä¸æ·»åŠ æ ¹èŠ‚ç‚¹åç§°åˆ°è·¯å¾„
                        print(f"   ğŸ“ å¤„ç†æ ¹èŠ‚ç‚¹ 'Project Files'ï¼Œè·³è¿‡æ ¹èŠ‚ç‚¹åç§°")
                        for child in node.get('children', []):
                            extract_files(child, "", proj_name, False, current_folder_id)
                        return
                    
                    # ä¼˜åŒ–ï¼šå¦‚æœæŒ‡å®šäº†æ–‡ä»¶å¤¹è¿‡æ»¤ï¼Œæ£€æŸ¥å½“å‰åˆ†æ”¯æ˜¯å¦å¯èƒ½åŒ…å«ç›®æ ‡æ–‡ä»¶å¤¹
                    if folder_ids and node.get('type') == 'folder':
                        current_node_id = node.get('id')
                        node_name = node.get('name', '')
                        
                        # æ£€æŸ¥å½“å‰æ–‡ä»¶å¤¹æ˜¯å¦æ˜¯ç›®æ ‡æ–‡ä»¶å¤¹ä¹‹ä¸€
                        is_target_folder = current_node_id in folder_ids
                        
                        # æ£€æŸ¥å½“å‰æ–‡ä»¶å¤¹æ˜¯å¦å¯èƒ½æ˜¯ç›®æ ‡æ–‡ä»¶å¤¹çš„çˆ¶æ–‡ä»¶å¤¹
                        might_contain_target = False
                        
                        # æ–¹æ³•1: ä½¿ç”¨æ–‡ä»¶å¤¹æ˜ å°„æ£€æŸ¥
                        for target_folder_id in folder_ids:
                            if target_folder_id in folder_path_mapping:
                                target_path = folder_path_mapping[target_folder_id]['path']
                                target_name = folder_path_mapping[target_folder_id]['name']
                                # æ£€æŸ¥ç›®æ ‡è·¯å¾„æ˜¯å¦åŒ…å«å½“å‰æ–‡ä»¶å¤¹åç§°
                                if node_name in target_path or current_path in target_path:
                                    might_contain_target = True
                                    break
                        
                        # æ–¹æ³•2: å¦‚æœæ–‡ä»¶å¤¹æ˜ å°„ä¸å®Œæ•´ï¼Œä½¿ç”¨å®½æ¾çš„åŒ¹é…ç­–ç•¥
                        if not might_contain_target:
                            # å¯¹äºæ ¹çº§åˆ«çš„æ–‡ä»¶å¤¹ï¼Œæ€»æ˜¯ç»§ç»­éå†ï¼ˆé¿å…è¿‡æ—©è·³è¿‡ï¼‰
                            if path == "" or "/" not in current_path:
                                might_contain_target = True
                                print(f"   ğŸ” æ ¹çº§åˆ«æ–‡ä»¶å¤¹ï¼Œç»§ç»­éå†: {node_name}")
                            else:
                                # å¯¹äºæ·±å±‚æ–‡ä»¶å¤¹ï¼Œæ£€æŸ¥åç§°æ˜¯å¦åŒ¹é…ç›®æ ‡æ–‡ä»¶å¤¹çš„æŸäº›ç‰¹å¾
                                for target_folder_id in folder_ids:
                                    if target_folder_id in folder_path_mapping:
                                        target_info = folder_path_mapping[target_folder_id]
                                        target_name = target_info.get('name', '')
                                        target_path = target_info.get('path', '')
                                        
                                        # æ£€æŸ¥å½“å‰è·¯å¾„æ˜¯å¦æ˜¯ç›®æ ‡æ–‡ä»¶å¤¹è·¯å¾„çš„ä¸€éƒ¨åˆ†
                                        if target_path:
                                            normalized_target_path = target_path.replace('Project Files/', '')
                                            # å¦‚æœå½“å‰è·¯å¾„æ˜¯ç›®æ ‡è·¯å¾„çš„å‰ç¼€ï¼Œæˆ–è€…ç›®æ ‡è·¯å¾„åŒ…å«å½“å‰è·¯å¾„
                                            if (normalized_target_path.startswith(current_path + '/') or 
                                                current_path.startswith(normalized_target_path.split('/')[0])):
                                                might_contain_target = True
                                                print(f"   ğŸ” è·¯å¾„åŒ¹é…ï¼Œç»§ç»­éå†: {node_name} (å½“å‰: {current_path}, ç›®æ ‡: {normalized_target_path})")
                                                break
                                        
                                        # æ£€æŸ¥æ–‡ä»¶å¤¹åç§°æ˜¯å¦åŒ¹é…
                                        if target_name and (node_name.lower() == target_name.lower() or 
                                                          target_name.lower() in current_path.lower() or
                                                          current_path.lower().startswith(target_name.lower())):
                                            might_contain_target = True
                                            print(f"   ğŸ” åç§°åŒ¹é…ï¼Œç»§ç»­éå†: {node_name}")
                                            break
                        
                        # æ™ºèƒ½åˆ†æ”¯è·³è¿‡ä¼˜åŒ– - åªéå†ç›¸å…³çš„æ–‡ä»¶å¤¹åˆ†æ”¯
                        if not is_target_folder and not might_contain_target:
                            print(f"   â­ï¸ è·³è¿‡ä¸ç›¸å…³åˆ†æ”¯: {node_name} (è·¯å¾„: {current_path})")
                            return
                        
                        # æ˜¾ç¤ºåˆ†æ”¯éå†å†³ç­–
                        if is_target_folder:
                            print(f"   âœ… ç›®æ ‡æ–‡ä»¶å¤¹ï¼Œç»§ç»­éå†: {node_name}")
                        elif might_contain_target:
                            print(f"   ğŸ” å¯èƒ½åŒ…å«ç›®æ ‡ï¼Œç»§ç»­éå†: {node_name}")
                        else:
                            print(f"   ğŸ” ç»§ç»­éå†: {node_name}")
                    
                    if node.get('type') == 'file':
                        file_name = node.get('name', '')
                        file_ext = get_file_extension(file_name)
                        
                        # æ–‡ä»¶ç±»å‹è¿‡æ»¤
                        if file_types and file_ext not in file_types:
                            return
                        
                        # ä¸´æ—¶ç¦ç”¨æ–‡ä»¶å¤¹è¿‡æ»¤ï¼ŒæŸ¥çœ‹æ‰€æœ‰æ–‡ä»¶
                        if folder_ids:
                            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦åœ¨æŒ‡å®šçš„æ–‡ä»¶å¤¹ä¸­ï¼ˆåŒ…æ‹¬å­æ–‡ä»¶å¤¹ï¼‰
                            file_in_target_folder = False
                            print(f"   ğŸ” æ£€æŸ¥æ–‡ä»¶ '{file_name}' æ˜¯å¦åœ¨ç›®æ ‡æ–‡ä»¶å¤¹ä¸­")
                            print(f"   ğŸ“‚ æ–‡ä»¶è·¯å¾„: '{current_path}', çˆ¶æ–‡ä»¶å¤¹ID: '{current_folder_id}'")
                            print(f"   ğŸ¯ ç›®æ ‡æ–‡ä»¶å¤¹IDs: {folder_ids}")
                            
                            # ä½¿ç”¨æ­£ç¡®çš„è·¯å¾„åŒ¹é…æ£€æŸ¥
                            for target_folder_id in folder_ids:
                                # æ–¹æ³•1: ç›´æ¥æ£€æŸ¥çˆ¶æ–‡ä»¶å¤¹ID
                                if current_folder_id == target_folder_id:
                                    file_in_target_folder = True
                                    print(f"   âœ… æ–‡ä»¶ç›´æ¥åŒ¹é…çˆ¶æ–‡ä»¶å¤¹ID: {file_name} -> {target_folder_id}")
                                    break
                                
                                # æ–¹æ³•2: æ£€æŸ¥æ–‡ä»¶æ˜¯å¦åœ¨ç›®æ ‡æ–‡ä»¶å¤¹çš„å­æ–‡ä»¶å¤¹ä¸­
                                if is_file_in_target_folder_hierarchy(current_path, current_folder_id, target_folder_id, folder_path_mapping):
                                    file_in_target_folder = True
                                    print(f"   âœ… æ–‡ä»¶åœ¨ç›®æ ‡æ–‡ä»¶å¤¹å±‚æ¬¡ç»“æ„ä¸­: {file_name} -> {target_folder_id}")
                                    break
                            
                            if not file_in_target_folder:
                                print(f"   âŒ æ–‡ä»¶ '{file_name}' ä¸åœ¨ä»»ä½•ç›®æ ‡æ–‡ä»¶å¤¹ä¸­ï¼Œè·³è¿‡")
                                return
                        
                        # è·å–æ–‡ä»¶å¤§å°ä¿¡æ¯
                        file_size = 0
                        versions = node.get('versions', [])
                        if versions:
                            # ä½¿ç”¨æœ€æ–°ç‰ˆæœ¬çš„æ–‡ä»¶å¤§å°
                            latest_version = versions[0]  # ç‰ˆæœ¬æŒ‰æ—¶é—´æ’åºï¼Œç¬¬ä¸€ä¸ªæ˜¯æœ€æ–°çš„
                            file_size = latest_version.get('fileSize', 0) or latest_version.get('storageSize', 0)
                        
                        # å¦‚æœç‰ˆæœ¬ä¸­æ²¡æœ‰å¤§å°ä¿¡æ¯ï¼Œå°è¯•ä»attributesè·å–
                        if file_size == 0:
                            file_size = node.get('attributes', {}).get('size', 0) or node.get('attributes', {}).get('storageSize', 0)
                        
                        # æ„å»ºæ˜¾ç¤ºè·¯å¾„ï¼Œä»¥é¡¹ç›®åç§°ä¸ºæ ¹
                        display_path = f"{proj_name}/{current_path}" if current_path else proj_name
                        
                        # è®¡ç®—æ–‡ä»¶å¤¹è·¯å¾„ï¼ˆä¸åŒ…å«æ–‡ä»¶åï¼‰
                        # ä¿®å¤ï¼šcurrent_path å¯¹äºæ–‡ä»¶æ¥è¯´æ˜¯å®Œæ•´è·¯å¾„ï¼ˆçˆ¶æ–‡ä»¶å¤¹è·¯å¾„/æ–‡ä»¶åï¼‰
                        # éœ€è¦æå–æ–‡ä»¶å¤¹éƒ¨åˆ†ï¼ˆå»æ‰æ–‡ä»¶åï¼‰
                        folder_path = ""
                        if current_path:
                            path_parts = current_path.split('/')
                            if len(path_parts) > 1:
                                # æœ‰å¤šä¸ªéƒ¨åˆ†ï¼Œæœ€åä¸€ä¸ªæ˜¯æ–‡ä»¶åï¼Œå‰é¢çš„æ˜¯æ–‡ä»¶å¤¹è·¯å¾„
                                folder_path = '/'.join(path_parts[:-1])
                                print(f"   ğŸ“ è®¡ç®—æ–‡ä»¶å¤¹è·¯å¾„: '{current_path}' -> '{folder_path}'")
                            else:
                                # åªæœ‰ä¸€ä¸ªéƒ¨åˆ†ï¼ˆæ–‡ä»¶åï¼‰ï¼Œè¯´æ˜æ–‡ä»¶åœ¨æ ¹ç›®å½•
                                folder_path = ""
                                print(f"   ğŸ“ æ–‡ä»¶åœ¨æ ¹ç›®å½•: '{current_path}' -> æ— å­è·¯å¾„")
                        else:
                            print(f"   ğŸ“ ç©ºè·¯å¾„ï¼Œæ–‡ä»¶åœ¨æ ¹ç›®å½•")
                        
                        file_info = {
                            'id': node.get('id'),
                            'name': file_name,
                            'path': display_path,  # æ˜¾ç¤ºè·¯å¾„åŒ…å«é¡¹ç›®åç§°
                            'original_path': current_path,  # ä¿å­˜å®Œæ•´ç›¸å¯¹è·¯å¾„ï¼ˆåŒ…å«æ–‡ä»¶åï¼‰
                            'folder_path': folder_path,  # ä¿å­˜æ–‡ä»¶å¤¹è·¯å¾„ï¼ˆä¸åŒ…å«æ–‡ä»¶åï¼‰
                            'extension': file_ext,
                            'type': get_file_type_description(file_ext),
                            'size': file_size,
                            'versions': len(versions),
                            'last_modified': node.get('attributes', {}).get('lastModifiedTime'),
                            'downloadable': is_file_downloadable(file_ext),
                            'original_name': file_name  # ä¿å­˜åŸå§‹æ–‡ä»¶å
                        }
                        files.append(file_info)
                    
                    # å¤„ç†å­èŠ‚ç‚¹ï¼ˆæ–‡ä»¶å¤¹å’Œæ–‡ä»¶ï¼‰- èˆ‡file_sync_apiä¿æŒä¸€è‡´
                    children = node.get('children', [])
                    for child in children:
                        # å¯¹äºå­èŠ‚ç‚¹ï¼Œå½“å‰èŠ‚ç‚¹çš„IDå°±æ˜¯å­èŠ‚ç‚¹çš„çˆ¶æ–‡ä»¶å¤¹ID
                        child_parent_folder_id = node.get('id') if node_type == 'folder' else parent_folder_id
                        # ä½¿ç”¨ç•¶å‰è·¯å¾‘ä½œç‚ºå­ç¯€é»çš„çˆ¶è·¯å¾‘ - èˆ‡file_sync_apiä¸€è‡´
                        next_path = current_path
                        print(f"   ğŸ“‚ é€’å½’å¤„ç†å­èŠ‚ç‚¹: çˆ¶èŠ‚ç‚¹='{node_name}' (ID: {node.get('id')}), å­èŠ‚ç‚¹='{child.get('name')}', ä¼ é€’è·¯å¾„='{next_path}', ä¼ é€’çš„çˆ¶ID='{child_parent_folder_id}'")
                        extract_files(child, next_path, proj_name, False, child_parent_folder_id)
                
                for top_folder in tree_data.get('top_folders', []):
                    extract_files(top_folder, "", project_name, True, None)
                
                # æ·»åŠ è°ƒè¯•ä¿¡æ¯
                if folder_ids:
                    print(f"ğŸ” æ–‡ä»¶å¤¹è¿‡æ»¤ç»“æœ: ç›®æ ‡æ–‡ä»¶å¤¹={folder_ids}, åŒ¹é…æ–‡ä»¶æ•°={len(files)}")
                
                # æŒ‰æ–‡ä»¶ç±»å‹åˆ†ç»„
                files_by_type = {}
                for file_info in files:
                    file_type = file_info['type']
                    if file_type not in files_by_type:
                        files_by_type[file_type] = []
                    files_by_type[file_type].append(file_info)
                
                result = {
                    'files': files,
                    'folders': folders,  # æ·»åŠ æ–‡ä»¶å¤¾ä¿¡æ¯
                    'files_by_type': files_by_type,
                    'total_count': len(files),
                    'folder_count': len(folders),  # æ·»åŠ æ–‡ä»¶å¤¾æ•¸é‡
                    'downloadable_count': len([f for f in files if f['downloadable']]),
                    'total_size': sum(f['size'] for f in files)
                }
                
                # åªæœ‰åœ¨ä¸è·³è¿‡ç¼“å­˜æ—¶æ‰ç¼“å­˜ç»“æœ
                if not bypass_cache:
                    cache_data(cache_key, result)
                    print(f"ğŸ’¾ æ•°æ®å·²ç¼“å­˜ï¼Œé¿å…ä¸‹æ¬¡é‡å¤éå†")
                    print(f"   ç¼“å­˜é”®: {cache_key}")
                    print(f"   ç¼“å­˜æ–‡ä»¶æ•°: {len(result.get('files', []))}")
                    print(f"   ç¼“å­˜æ–‡ä»¶å¤¹æ•°: {len(result.get('folders', []))}")
                else:
                    print(f"âš¡ è·³è¿‡ç¼“å­˜ä¿å­˜ï¼Œä¸ç¼“å­˜æ­¤æ¬¡ç»“æœ")
                
                return jsonify({
                    "status": "success",
                    "data": result,
                    "cached": False
                })
            else:
                return jsonify({
                    "error": data.get('error', 'Unknown error'),
                    "status": "error"
                }), 400
        else:
            return jsonify({
                "error": f"è·å–æ–‡ä»¶åˆ—è¡¨å¤±è´¥: {response.status_code}",
                "status": "error"
            }), 400
            
    except Exception as e:
        return jsonify({
            "error": f"è·å–æ–‡ä»¶åˆ—è¡¨å¤±è´¥: {str(e)}",
            "status": "error"
        }), 500

@download_config_bp.route('/api/download-config/project/<project_id>/debug', methods=['GET'])
def debug_project_files(project_id):
    """è°ƒè¯•é¡¹ç›®æ–‡ä»¶æ•°é‡é—®é¢˜"""
    access_token = utils.get_access_token()
    if not access_token:
        return jsonify({
            "error": "æœªæ‰¾åˆ° Access Tokenï¼Œè¯·å…ˆè¿›è¡Œè®¤è¯",
            "status": "unauthorized"
        }), 401
    
    try:
        # è·å–maxDepthå‚æ•°
        max_depth = request.args.get('maxDepth', 20, type=int)
        
        # è·å–åŸå§‹æ–‡ä»¶æ ‘ï¼ˆéå†æ‰€æœ‰å±‚çº§ä»¥è·å–å®Œæ•´æ•°æ®ï¼‰
        tree_url = f"http://localhost:{config.PORT}/api/file-sync/project/{project_id}/tree"
        params = {'maxDepth': max_depth, 'includeVersions': 'true'}
        
        response = requests.get(tree_url, params=params, timeout=120)
        
        if response.status_code == 200:
            data = response.json()
            if data.get('status') == 'success':
                tree_data = data.get('data', {})
                
                # ç»Ÿè®¡åŸå§‹æ•°æ®
                def count_all_files(node):
                    count = 0
                    if node.get('type') == 'file':
                        count = 1
                    for child in node.get('children', []):
                        count += count_all_files(child)
                    return count
                
                def analyze_tree_structure(node, path="", level=0):
                    """åˆ†ææ ‘ç»“æ„ï¼Œè¿”å›è¯¦ç»†ä¿¡æ¯"""
                    current_path = f"{path}/{node.get('name', '')}" if path else node.get('name', '')
                    node_info = {
                        'name': node.get('name', ''),
                        'type': node.get('type', 'unknown'),
                        'id': node.get('id', ''),
                        'path': current_path,
                        'level': level,
                        'children_count': len(node.get('children', [])),
                        'children': []
                    }
                    
                    for child in node.get('children', []):
                        child_info = analyze_tree_structure(child, current_path, level + 1)
                        node_info['children'].append(child_info)
                    
                    return node_info
                
                total_files_in_tree = 0
                tree_structure = []
                
                for top_folder in tree_data.get('top_folders', []):
                    total_files_in_tree += count_all_files(top_folder)
                    folder_structure = analyze_tree_structure(top_folder)
                    tree_structure.append(folder_structure)
                
                return jsonify({
                    "status": "success",
                    "debug_info": {
                        "project_id": project_id,
                        "tree_statistics": tree_data.get('statistics', {}),
                        "actual_file_count_in_tree": total_files_in_tree,
                        "top_folders_count": len(tree_data.get('top_folders', [])),
                        "tree_structure": tree_structure
                    }
                })
        
        return jsonify({
            "error": "Unable to get project file tree",
            "status": "error"
        }), 400
        
    except Exception as e:
        return jsonify({
            "error": f"è°ƒè¯•å¤±è´¥: {str(e)}",
            "status": "error"
        }), 500

@download_config_bp.route('/api/download-config/download', methods=['POST'])
def start_download():
    """å¼€å§‹å¼‚æ­¥ä¸‹è½½æ–‡ä»¶"""
    access_token = utils.get_access_token()
    if not access_token:
        return jsonify({
            "error": "æœªæ‰¾åˆ° Access Tokenï¼Œè¯·å…ˆè¿›è¡Œè®¤è¯",
            "status": "unauthorized"
        }), 401
    
    try:
        request_data = request.json
        print(f"ğŸ“¥ æ”¶åˆ°ä¸‹è½½è¯·æ±‚: {json.dumps(request_data, indent=2, ensure_ascii=False)}")
        
        project_id = request_data.get('project_id')
        # ç›´æ¥ä»åç«¯è·å–é¡¹ç›®åç§°ï¼Œä¸ä¾èµ–å‰ç«¯ä¼ é€’
        project_name = get_project_name_by_id(project_id)
        file_ids = request_data.get('file_ids', [])
        download_options = request_data.get('options', {})
        
        print(f"ğŸ“‹ è§£æå‚æ•°: project_id={project_id}, project_name='{project_name}' (ä»åç«¯è·å–), file_idsæ•°é‡={len(file_ids)}")
        print(f"ğŸ” å®Œæ•´è¯·æ±‚æ•°æ®: {json.dumps(request_data, indent=2, ensure_ascii=False)}")
        print(f"ğŸ”§ ä¸‹è½½é€‰é¡¹: {json.dumps(download_options, indent=2, ensure_ascii=False)}")
        # æ£€æŸ¥createFoldersé€‰é¡¹ï¼ˆåœ¨optionsæ•°ç»„ä¸­ï¼‰
        create_folders = 'createFolders' in download_options.get('options', [])
        print(f"ğŸ“ createFoldersé€‰é¡¹: {create_folders}")
        print(f"ğŸ“ optionsæ•°ç»„: {download_options.get('options', [])}")
        
        # æ™ºèƒ½è·å–æ–‡ä»¶è·¯å¾„ä¿¡æ¯ï¼Œä¼˜å…ˆä½¿ç”¨ç¼“å­˜é¿å…é‡å¤éå†
        file_path_mapping = {}
        empty_folders = []  # å­˜å‚¨ç©ºæ–‡ä»¶å¤¹ä¿¡æ¯
        if create_folders:
            print("ğŸ” è·å–æ–‡ä»¶è·¯å¾„ä¿¡æ¯å’Œç©ºæ–‡ä»¶å¤¹...")
            try:
                # ä¼˜åŒ–ç­–ç•¥ï¼šå°è¯•ä»æœ€è¿‘çš„APIè°ƒç”¨ç»“æœä¸­è·å–è·¯å¾„ä¿¡æ¯
                # æ£€æŸ¥æ˜¯å¦æœ‰æœ€è¿‘çš„æ–‡ä»¶åˆ—è¡¨ç¼“å­˜å¯ä»¥ä½¿ç”¨
                print(f"ğŸ“ æ™ºèƒ½è·¯å¾„è·å–ï¼šæ£€æŸ¥ {len(file_ids)} ä¸ªæ–‡ä»¶çš„è·¯å¾„ä¿¡æ¯")
                
                # å°è¯•è°ƒç”¨æ–‡ä»¶åˆ—è¡¨APIè·å–è·¯å¾„ä¿¡æ¯ï¼ˆè¿™å¯èƒ½ä¼šä½¿ç”¨ç¼“å­˜ï¼‰
                files_params = {'project_name': project_name}
                files_response = requests.get(f"http://localhost:{config.PORT}/api/download-config/project/{project_id}/files", 
                                            params=files_params, timeout=30)
                if files_response.status_code == 200:
                    files_data = files_response.json()
                    if files_data.get('status') == 'success':
                        all_files = files_data.get('data', {}).get('files', [])
                        all_folders = files_data.get('data', {}).get('folders', [])
                        print(f"ğŸ“‹ ä»APIè·å–åˆ° {len(all_files)} ä¸ªæ–‡ä»¶ä¿¡æ¯å’Œ {len(all_folders)} ä¸ªæ–‡ä»¶å¤¹ä¿¡æ¯")
                        
                        # åªä¸ºæˆ‘ä»¬éœ€è¦ä¸‹è½½çš„æ–‡ä»¶åˆ›å»ºè·¯å¾„æ˜ å°„
                        matched_files = 0
                        for file_info in all_files:
                            file_id = file_info.get('id')
                            if file_id in file_ids:  # åªå¤„ç†æˆ‘ä»¬è¦ä¸‹è½½çš„æ–‡ä»¶
                                folder_path = file_info.get('folder_path', '')
                                original_path = file_info.get('original_path', '')
                                file_name = file_info.get('name', '')
                                
                                print(f"   âœ… æ‰¾åˆ°ä¸‹è½½æ–‡ä»¶: {file_name}")
                                print(f"      ID: {file_id}")
                                print(f"      æ–‡ä»¶å¤¹è·¯å¾„: '{folder_path}'")
                                print(f"      åŸå§‹è·¯å¾„: '{original_path}'")
                                
                                file_path_mapping[file_id] = {
                                    'path': folder_path,
                                    'name': file_name,
                                    'original_path': original_path
                                }
                                matched_files += 1
                        
                        # æ”¶é›†ç©ºæ–‡ä»¶å¤¹ä¿¡æ¯
                        file_folder_paths = set()
                        for file_info in all_files:
                            if file_info.get('id') in file_ids:
                                folder_path = file_info.get('folder_path', '')
                                if folder_path:
                                    file_folder_paths.add(folder_path)
                        
                        # æŸ¥æ‰¾ç©ºæ–‡ä»¶å¤¹ï¼ˆæ²¡æœ‰æ–‡ä»¶çš„æ–‡ä»¶å¤¹ï¼‰
                        for folder_info in all_folders:
                            folder_path = folder_info.get('path', '')
                            folder_name = folder_info.get('name', '')
                            if folder_path and folder_path not in file_folder_paths:
                                empty_folders.append({
                                    'path': folder_path,
                                    'name': folder_name
                                })
                                print(f"   ğŸ“ ç™¼ç¾ç©ºæ–‡ä»¶å¤¾: {folder_name} (è·¯å¾‘: {folder_path})")
                        
                        print(f"âœ… æˆåŠŸåŒ¹é… {matched_files}/{len(file_ids)} ä¸ªæ–‡ä»¶çš„è·¯å¾„ä¿¡æ¯")
                        print(f"ğŸ“ ç™¼ç¾ {len(empty_folders)} å€‹ç©ºæ–‡ä»¶å¤¾")
                        
                        if matched_files < len(file_ids):
                            print(f"âš ï¸ æœ‰ {len(file_ids) - matched_files} ä¸ªæ–‡ä»¶æœªæ‰¾åˆ°è·¯å¾„ä¿¡æ¯ï¼Œä¸‹è½½æ—¶å°†ä½¿ç”¨åŠ¨æ€è·å–")
                    else:
                        print(f"âš ï¸ è·å–æ–‡ä»¶åˆ—è¡¨å¤±è´¥: {files_data.get('error')}")
                        print("ğŸ”„ å°†åœ¨ä¸‹è½½æ—¶åŠ¨æ€è·å–è·¯å¾„ä¿¡æ¯")
                else:
                    print(f"âš ï¸ æ–‡ä»¶åˆ—è¡¨APIè°ƒç”¨å¤±è´¥: {files_response.status_code}")
                    print("ğŸ”„ å°†åœ¨ä¸‹è½½æ—¶åŠ¨æ€è·å–è·¯å¾„ä¿¡æ¯")
            except Exception as e:
                print(f"âš ï¸ è·å–æ–‡ä»¶è·¯å¾„ä¿¡æ¯æ—¶å‡ºé”™: {str(e)}")
                print("ğŸ”„ å°†åœ¨ä¸‹è½½æ—¶åŠ¨æ€è·å–è·¯å¾„ä¿¡æ¯")
        else:
            print("ğŸ“ è·³è¿‡æ–‡ä»¶å¤¹ç»“æ„åˆ›å»º")
        
        if not project_id or not file_ids:
            print(f"âŒ å‚æ•°éªŒè¯å¤±è´¥: project_id={project_id}, file_ids={file_ids}")
            return jsonify({
                "error": "ç¼ºå°‘å¿…è¦å‚æ•°: project_id å’Œ file_ids",
                "status": "error"
            }), 400
        
        # åˆ›å»ºä¸‹è½½ä»»åŠ¡
        task_id = f"download_{int(time.time())}_{len(file_ids)}"
        
        download_task = {
            'task_id': task_id,
            'project_id': project_id,
            'project_name': project_name,  # æ·»åŠ é¡¹ç›®åç§°åˆ°ä»»åŠ¡ä¸­
            'file_ids': file_ids,
            'options': download_options,
            'status': 'pending',
            'progress': 0,
            'total_files': len(file_ids),
            'completed_files': 0,
            'failed_files': 0,
            'start_time': datetime.now().isoformat(),
            'estimated_completion': None,
            'downloaded_files': [],
            'file_progress': {},  # æ¯ä¸ªæ–‡ä»¶çš„ä¸‹è½½è¿›åº¦
            'file_path_mapping': file_path_mapping,  # æ–‡ä»¶è·¯å¾„æ˜ å°„ä¿¡æ¯
            'empty_folders': empty_folders,  # ç©ºæ–‡ä»¶å¤¹ä¿¡æ¯
            'errors': []
        }
        
        download_tasks[task_id] = download_task
        print(f"ğŸ’¾ ä»»åŠ¡å·²å­˜å‚¨: {task_id}, å½“å‰ä»»åŠ¡æ€»æ•°: {len(download_tasks)}")
        
        # æäº¤å¼‚æ­¥ä»»åŠ¡
        future = get_executor().submit(execute_download_task, task_id, access_token)
        download_task['future'] = future
        
        print(f"ğŸš€ å¼‚æ­¥ä»»åŠ¡å·²æäº¤: {task_id}")
        
        return jsonify({
            "status": "success",
            "task_id": task_id,
            "message": f"å¼€å§‹ä¸‹è½½ {len(file_ids)} ä¸ªæ–‡ä»¶",
            "estimated_time": f"{len(file_ids) * 2} ç§’"  # ä¼°ç®—æ¯ä¸ªæ–‡ä»¶2ç§’
        })
        
    except Exception as e:
        return jsonify({
            "error": f"å¯åŠ¨ä¸‹è½½å¤±è´¥: {str(e)}",
            "status": "error"
        }), 500

@download_config_bp.route('/api/download-config/download/<task_id>/status', methods=['GET'])
def get_download_status(task_id):
    """è·å–ä¸‹è½½ä»»åŠ¡çŠ¶æ€"""
    if task_id not in download_tasks:
        return jsonify({
            "error": "Download task does not exist",
            "status": "error"
        }), 404
    
    task = download_tasks[task_id]
    
    # è®¡ç®—è¿›åº¦
    if task['total_files'] > 0:
        task['progress'] = int((task['completed_files'] / task['total_files']) * 100)
    
    # ç§»é™¤ä¸éœ€è¦åºåˆ—åŒ–çš„å­—æ®µ
    response_task = {k: v for k, v in task.items() if k != 'future'}
    
    return jsonify({
        "status": "success",
        "task": response_task
    })

@download_config_bp.route('/api/download-config/download/<task_id>/cancel', methods=['POST'])
def cancel_download(task_id):
    """cancelä¸‹è½½ä»»åŠ¡"""
    if task_id not in download_tasks:
        return jsonify({
            "error": "Download task does not exist",
            "status": "error"
        }), 404
    
    task = download_tasks[task_id]
    
    # å°è¯•cancelä»»åŠ¡
    if 'future' in task and not task['future'].done():
        task['future'].cancel()
    
    task['status'] = 'cancelled'
    
    return jsonify({
        "status": "success",
        "message": "Download task cancelled"
    })

@download_config_bp.route('/api/download-config/downloads', methods=['GET'])
def list_downloads():
    """åˆ—å‡ºæ‰€æœ‰ä¸‹è½½ä»»åŠ¡"""
    print(f"ğŸ“‹ æŸ¥è¯¢ä¸‹è½½ä»»åŠ¡åˆ—è¡¨, å½“å‰ä»»åŠ¡æ•°: {len(download_tasks)}")
    
    tasks = []
    for task_id, task in download_tasks.items():
        print(f"   - ä»»åŠ¡: {task_id}, çŠ¶æ€: {task.get('status')}")
        # ç§»é™¤ä¸éœ€è¦åºåˆ—åŒ–çš„å­—æ®µ
        task_info = {k: v for k, v in task.items() if k != 'future'}
        tasks.append(task_info)
    
    return jsonify({
        "status": "success",
        "tasks": tasks,
        "count": len(tasks)
    })

@download_config_bp.route('/api/download-config/clear-cache', methods=['POST'])
def clear_cache():
    """æ¸…é™¤ç¼“å­˜"""
    try:
        import glob
        cache_files = glob.glob(os.path.join(CACHE_DIR, "*.json"))
        for cache_file in cache_files:
            os.remove(cache_file)
        
        return jsonify({
            "status": "success",
            "message": f"å·²æ¸…é™¤ {len(cache_files)} ä¸ªç¼“å­˜æ–‡ä»¶"
        })
    except Exception as e:
        return jsonify({
            "error": f"æ¸…é™¤ç¼“å­˜å¤±è´¥: {str(e)}",
            "status": "error"
        }), 500

@download_config_bp.route('/api/download-config/file-types', methods=['GET'])
def get_supported_file_types():
    """è·å–æ”¯æŒçš„æ–‡ä»¶ç±»å‹"""
    file_types = {
        'documents': {
            'name': 'Document Files',
            'extensions': ['pdf', 'doc', 'docx', 'txt', 'rtf', 'md'],
            'downloadable': True
        },
        'cad': {
            'name': 'CADæ–‡ä»¶',
            'extensions': ['dwg', 'dxf', 'dwf'],
            'downloadable': True
        },
        'bim': {
            'name': 'BIMæ¨¡å‹',
            'extensions': ['rvt', 'rfa', 'ifc'],
            'downloadable': True
        },
        '3d_models': {
            'name': '3Dæ¨¡å‹',
            'extensions': ['3dm', 'step', 'stp', 'iges', 'igs', 'obj', 'fbx', 'max', 'skp'],
            'downloadable': True
        },
        'images': {
            'name': 'Image Files',
            'extensions': ['jpg', 'jpeg', 'png', 'gif', 'bmp', 'tiff'],
            'downloadable': True
        },
        'spreadsheets': {
            'name': 'Spreadsheet Files',
            'extensions': ['xls', 'xlsx', 'csv'],
            'downloadable': True
        },
        'presentations': {
            'name': 'Presentation Files',
            'extensions': ['ppt', 'pptx'],
            'downloadable': True
        },
        'archives': {
            'name': 'Archive Files',
            'extensions': ['zip', 'rar', '7z', 'tar', 'gz'],
            'downloadable': True
        },
        'videos': {
            'name': 'Video Files',
            'extensions': ['mp4', 'avi', 'mov', 'wmv', 'flv', 'mkv'],
            'downloadable': True
        },
        'audio': {
            'name': 'Audio Files',
            'extensions': ['mp3', 'wav', 'aac', 'flac', 'ogg'],
            'downloadable': True
        }
    }
    
    return jsonify({
        "status": "success",
        "file_types": file_types
    })

@download_config_bp.route('/api/download-config/open-folder', methods=['POST'])
def open_download_folder():
    """æ‰“å¼€ä¸‹è½½æ–‡ä»¶å¤¹"""
    try:
        request_data = request.json
        task_id = request_data.get('task_id')
        project_name = request_data.get('project_name', 'Project Files')
        
        if not task_id:
            return jsonify({
                "error": "ç¼ºå°‘ä»»åŠ¡ID",
                "status": "error"
            }), 400
        
        # æ„å»ºæ–‡ä»¶å¤¹è·¯å¾„
        folder_path = os.path.join(DOWNLOAD_DIR, project_name)
        
        # ç¡®ä¿æ–‡ä»¶å¤¹å­˜åœ¨
        if not os.path.exists(folder_path):
            return jsonify({
                "error": f"æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {folder_path}",
                "status": "error"
            }), 404
        
        # æ ¹æ®æ“ä½œç³»ç»Ÿæ‰“å¼€æ–‡ä»¶å¤¹
        import platform
        import subprocess
        
        system = platform.system()
        
        try:
            if system == "Windows":
                # Windows: ä½¿ç”¨ os.startfile æˆ– subprocess è°ƒç”¨ explorer
                try:
                    # æ–¹æ³•1: ä½¿ç”¨ os.startfile (Windowsä¸“ç”¨)
                    os.startfile(folder_path)
                except (OSError, AttributeError):
                    # æ–¹æ³•2: ä½¿ç”¨ subprocess è°ƒç”¨ explorer
                    normalized_path = os.path.normpath(folder_path)
                    subprocess.run(['cmd', '/c', 'start', '', normalized_path], check=True, shell=True)
            elif system == "Darwin":  # macOS
                # macOS: ä½¿ç”¨ open
                subprocess.run(['open', folder_path], check=True)
            elif system == "Linux":
                # Linux: ä½¿ç”¨ xdg-open
                subprocess.run(['xdg-open', folder_path], check=True)
            else:
                return jsonify({
                    "error": f"ä¸æ”¯æŒçš„æ“ä½œç³»ç»Ÿ: {system}",
                    "status": "error"
                }), 400
            
            return jsonify({
                "status": "success",
                "message": f"å·²æ‰“å¼€æ–‡ä»¶å¤¹: {folder_path}",
                "folder_path": folder_path
            })
            
        except subprocess.CalledProcessError as e:
            return jsonify({
                "error": f"æ‰“å¼€æ–‡ä»¶å¤¹å¤±è´¥: {str(e)}",
                "status": "error"
            }), 500
        except FileNotFoundError:
            return jsonify({
                "error": "System does not support folder opening functionality",
                "status": "error"
            }), 500
            
    except Exception as e:
        return jsonify({
            "error": f"æ‰“å¼€æ–‡ä»¶å¤¹å¤±è´¥: {str(e)}",
            "status": "error"
        }), 500

# è¾…åŠ©å‡½æ•°
def count_files_in_folder(folder_node):
    """ç»Ÿè®¡æ–‡ä»¶å¤¹ä¸­çš„æ–‡ä»¶æ•°é‡"""
    count = 0
    for child in folder_node.get('children', []):
        if child.get('type') == 'file':
            count += 1
        elif child.get('type') == 'folder':
            count += count_files_in_folder(child)
    return count

def count_folders_in_folder(folder_node):
    """ç»Ÿè®¡æ–‡ä»¶å¤¹ä¸­çš„å­æ–‡ä»¶å¤¹æ•°é‡"""
    count = 0
    for child in folder_node.get('children', []):
        if child.get('type') == 'folder':
            count += 1 + count_folders_in_folder(child)
    return count

def get_file_extension(filename):
    """è·å–æ–‡ä»¶æ‰©å±•å"""
    if '.' in filename:
        return filename.split('.')[-1].lower()
    return ''

def get_file_type_description(extension):
    """è·å–æ–‡ä»¶ç±»å‹æè¿°"""
    type_map = {
        'pdf': 'PDF Document',
        'doc': 'Word Document', 'docx': 'Word Document',
        'xls': 'Excel Spreadsheet', 'xlsx': 'Excel Spreadsheet',
        'ppt': 'PowerPoint', 'pptx': 'PowerPoint',
        'dwg': 'AutoCAD Drawing', 'dxf': 'AutoCAD Exchange File',
        'rvt': 'Revit Model', 'rfa': 'Revit Family File',
        'ifc': 'IFC Model',
        'jpg': 'JPEG Image', 'jpeg': 'JPEG Image', 'png': 'PNG Image', 'gif': 'GIF Image',
        'mp4': 'MP4 Video', 'avi': 'AVI Video', 'mov': 'MOV Video', 'wmv': 'WMV Video',
        'mp3': 'MP3 Audio', 'wav': 'WAV Audio',
        'zip': 'ZIP Archive', 'rar': 'RAR Archive', '7z': '7Z Archive',
        'md': 'Markdown Document', 'txt': 'Text Document'
    }
    return type_map.get(extension, f'{extension.upper()} File')

def is_file_downloadable(extension):
    """åˆ¤æ–­æ–‡ä»¶æ˜¯å¦å¯ä¸‹è½½"""
    downloadable_extensions = {
        'pdf', 'doc', 'docx', 'xls', 'xlsx', 'ppt', 'pptx',
        'dwg', 'dxf', 'rvt', 'rfa', 'ifc',
        'jpg', 'jpeg', 'png', 'gif', 'bmp', 'tiff',
        'zip', 'rar', '7z', 'txt', 'csv', 'md',  
        'mp4', 'avi', 'mov', 'wmv', 'flv',  # è§†é¢‘æ–‡ä»¶
        'mp3', 'wav', 'aac', 'flac',  # éŸ³é¢‘æ–‡ä»¶
        '3dm', 'step', 'stp', 'iges', 'igs', 'obj', 'fbx', 'max', 'skp'  # 3Dæ¨¡å‹
    }
    return extension in downloadable_extensions

def is_file_in_target_folder_hierarchy(file_path, current_folder_id, target_folder_id, folder_path_mapping):
    """
    æ£€æŸ¥æ–‡ä»¶æ˜¯å¦åœ¨ç›®æ ‡æ–‡ä»¶å¤¹çš„å±‚æ¬¡ç»“æ„ä¸­ï¼ˆåŒ…æ‹¬å­æ–‡ä»¶å¤¹ï¼‰
    ä½¿ç”¨ä¸¥æ ¼çš„å±‚æ¬¡ç»“æ„æ£€æŸ¥
    """
    if not target_folder_id or not folder_path_mapping:
        return False
    
    print(f"   ğŸ” æ£€æŸ¥æ–‡ä»¶å¤¹å±‚æ¬¡ç»“æ„: æ–‡ä»¶='{file_path}', å½“å‰æ–‡ä»¶å¤¹='{current_folder_id}', ç›®æ ‡='{target_folder_id}'")
    
    # è·å–ç›®æ ‡æ–‡ä»¶å¤¹ä¿¡æ¯
    if target_folder_id not in folder_path_mapping:
        print(f"   âŒ ç›®æ ‡æ–‡ä»¶å¤¹ä¸åœ¨æ˜ å°„ä¸­: {target_folder_id}")
        return False
    
    target_folder_info = folder_path_mapping[target_folder_id]
    target_folder_path = target_folder_info.get('path', '')
    target_folder_name = target_folder_info.get('name', '')
    
    print(f"   ğŸ“ ç›®æ ‡æ–‡ä»¶å¤¹ä¿¡æ¯: åç§°='{target_folder_name}', è·¯å¾„='{target_folder_path}'")
    
    # æ–¹æ³•1: ç›´æ¥æ£€æŸ¥å½“å‰æ–‡ä»¶å¤¹IDæ˜¯å¦å°±æ˜¯ç›®æ ‡æ–‡ä»¶å¤¹
    if current_folder_id == target_folder_id:
        print(f"   âœ… å½“å‰æ–‡ä»¶å¤¹å°±æ˜¯ç›®æ ‡æ–‡ä»¶å¤¹: {current_folder_id}")
        return True
    
    # æ–¹æ³•2: ä¸¥æ ¼æ£€æŸ¥æ–‡ä»¶è·¯å¾„æ˜¯å¦åœ¨ç›®æ ‡æ–‡ä»¶å¤¹ä¸‹
    if target_folder_name and file_path:
        # æ–‡ä»¶è·¯å¾„å¿…é¡»ä»¥"ç›®æ ‡æ–‡ä»¶å¤¹åç§°/"å¼€å¤´
        if file_path.startswith(target_folder_name + '/'):
            print(f"   âœ… æ–‡ä»¶è·¯å¾„åœ¨ç›®æ ‡æ–‡ä»¶å¤¹ä¸‹: {file_path} -> {target_folder_name}")
            return True
        else:
            print(f"   âŒ æ–‡ä»¶è·¯å¾„ä¸åœ¨ç›®æ ‡æ–‡ä»¶å¤¹ä¸‹: {file_path} ä¸ä»¥ '{target_folder_name}/' å¼€å¤´")
    
    # æ–¹æ³•3: æ£€æŸ¥å½“å‰æ–‡ä»¶å¤¹æ˜¯å¦åœ¨ç›®æ ‡æ–‡ä»¶å¤¹çš„å±‚æ¬¡ç»“æ„ä¸­
    if current_folder_id and current_folder_id in folder_path_mapping:
        current_folder_info = folder_path_mapping[current_folder_id]
        current_folder_path = current_folder_info.get('path', '')
        current_folder_name = current_folder_info.get('name', '')
        
        print(f"   ğŸ“‚ å½“å‰æ–‡ä»¶å¤¹ä¿¡æ¯: åç§°='{current_folder_name}', è·¯å¾„='{current_folder_path}'")
        
        # ä¸¥æ ¼æ£€æŸ¥å½“å‰æ–‡ä»¶å¤¹è·¯å¾„æ˜¯å¦åœ¨ç›®æ ‡æ–‡ä»¶å¤¹è·¯å¾„ä¸‹
        if target_folder_path and current_folder_path:
            # è§„èŒƒåŒ–è·¯å¾„ï¼ˆç§»é™¤ 'Project Files/' å‰ç¼€ï¼‰
            normalized_target_path = target_folder_path.replace('Project Files/', '').replace('Project Files', '').strip('/')
            normalized_current_path = current_folder_path.replace('Project Files/', '').replace('Project Files', '').strip('/')
            
            # ä¸¥æ ¼çš„å±‚æ¬¡å…³ç³»æ£€æŸ¥ï¼šå½“å‰æ–‡ä»¶å¤¹å¿…é¡»åœ¨ç›®æ ‡æ–‡ä»¶å¤¹ä¸‹æˆ–å°±æ˜¯ç›®æ ‡æ–‡ä»¶å¤¹
            if normalized_current_path == normalized_target_path:
                print(f"   âœ… å½“å‰æ–‡ä»¶å¤¹å°±æ˜¯ç›®æ ‡æ–‡ä»¶å¤¹: '{normalized_current_path}'")
                return True
            elif normalized_current_path.startswith(normalized_target_path + '/'):
                print(f"   âœ… å½“å‰æ–‡ä»¶å¤¹åœ¨ç›®æ ‡æ–‡ä»¶å¤¹å±‚æ¬¡ç»“æ„ä¸­: '{normalized_current_path}' -> '{normalized_target_path}'")
                return True
            else:
                print(f"   âŒ å½“å‰æ–‡ä»¶å¤¹ä¸åœ¨ç›®æ ‡æ–‡ä»¶å¤¹å±‚æ¬¡ç»“æ„ä¸­: '{normalized_current_path}' ä¸åœ¨ '{normalized_target_path}' ä¸‹")
    
    print(f"   âŒ æ–‡ä»¶ä¸åœ¨ç›®æ ‡æ–‡ä»¶å¤¹å±‚æ¬¡ç»“æ„ä¸­")
    return False

def is_file_in_folder_by_path(file_path, target_folder_id, folder_path_mapping):
    """ä½¿ç”¨è·¯å¾„åŒ¹é…æ£€æŸ¥æ–‡ä»¶æ˜¯å¦åœ¨æŒ‡å®šçš„æ–‡ä»¶å¤¹ä¸­"""
    if not target_folder_id:
        print(f"   âŒ ç›®æ ‡æ–‡ä»¶å¤¹IDä¸ºç©º")
        return False
    
    print(f"   ğŸ” æ£€æŸ¥æ–‡ä»¶æ˜¯å¦åœ¨ç›®æ ‡æ–‡ä»¶å¤¹ä¸­: æ–‡ä»¶='{file_path}', ç›®æ ‡æ–‡ä»¶å¤¹ID='{target_folder_id}'")
    
    # æ–¹æ³•1: ä½¿ç”¨æ–‡ä»¶å¤¹æ˜ å°„è¿›è¡Œç²¾ç¡®åŒ¹é…ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if folder_path_mapping and target_folder_id in folder_path_mapping:
        folder_info = folder_path_mapping[target_folder_id]
        target_folder_path = folder_info.get('path', '')
        target_folder_name = folder_info.get('name', '')
        
        print(f"   ğŸ“ ä½¿ç”¨æ–‡ä»¶å¤¹æ˜ å°„: åç§°='{target_folder_name}', è·¯å¾„='{target_folder_path}'")
        
        # æ£€æŸ¥æ–‡ä»¶è·¯å¾„æ˜¯å¦ä»¥ç›®æ ‡æ–‡ä»¶å¤¹è·¯å¾„å¼€å¤´ï¼ˆç²¾ç¡®åŒ¹é…ï¼‰
        if target_folder_path:
            # è§„èŒƒåŒ–è·¯å¾„æ ¼å¼
            normalized_folder_path = target_folder_path.replace('Project Files/', '')
            normalized_file_path = file_path
            
            # ç¡®ä¿è·¯å¾„åŒ¹é…æ˜¯ç²¾ç¡®çš„ï¼ˆé¿å…éƒ¨åˆ†åŒ¹é…ï¼‰
            # æ–‡ä»¶å¿…é¡»åœ¨ç›®æ ‡æ–‡ä»¶å¤¹å†…æˆ–å…¶å­æ–‡ä»¶å¤¹å†…
            if normalized_file_path.startswith(normalized_folder_path + '/'):
                print(f"   âœ… æ–‡ä»¶è·¯å¾„ç²¾ç¡®åŒ¹é…æ–‡ä»¶å¤¹: {file_path} -> {normalized_folder_path}")
                return True
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ç›´æ¥åœ¨ç›®æ ‡æ–‡ä»¶å¤¹æ ¹ç›®å½•ä¸‹
            # ä¾‹å¦‚: file_path="test/file.txt", target_folder_path="Project Files/test"
            if normalized_file_path.startswith(target_folder_name + '/'):
                print(f"   âœ… æ–‡ä»¶åœ¨ç›®æ ‡æ–‡ä»¶å¤¹æ ¹ç›®å½•: {file_path} -> {target_folder_name}")
                return True
        
        # æ£€æŸ¥æ–‡ä»¶è·¯å¾„æ˜¯å¦åŒ…å«ç›®æ ‡æ–‡ä»¶å¤¹åç§°ï¼ˆä¸¥æ ¼åŒ¹é…ï¼‰
        if target_folder_name:
            path_parts = file_path.split('/')
            if target_folder_name in path_parts:
                # ç¡®ä¿æ–‡ä»¶å¤¹åç§°åŒ¹é…æ˜¯å®Œæ•´çš„ï¼Œä¸”æ–‡ä»¶åœ¨è¯¥æ–‡ä»¶å¤¹å†…
                folder_index = path_parts.index(target_folder_name)
                # æ–‡ä»¶åº”è¯¥åœ¨æ–‡ä»¶å¤¹ä¹‹åçš„è·¯å¾„ä¸­ï¼Œæˆ–è€…æ–‡ä»¶å¤¹æ˜¯è·¯å¾„çš„æœ€åä¸€éƒ¨åˆ†ï¼ˆè¡¨ç¤ºæ–‡ä»¶åœ¨è¯¥æ–‡ä»¶å¤¹æ ¹ç›®å½•ï¼‰
                if folder_index < len(path_parts) - 1:
                    print(f"   âœ… æ–‡ä»¶è·¯å¾„åŒ…å«æ–‡ä»¶å¤¹åç§°: {file_path} -> {target_folder_name}")
                    return True
                elif folder_index == len(path_parts) - 1 and len(path_parts) == 1:
                    # ç‰¹æ®Šæƒ…å†µï¼šæ–‡ä»¶è·¯å¾„åªæ˜¯æ–‡ä»¶å¤¹åç§°ï¼Œå¯èƒ½è¡¨ç¤ºæ–‡ä»¶åœ¨è¯¥æ–‡ä»¶å¤¹æ ¹ç›®å½•
                    # ä½†è¿™ç§æƒ…å†µéœ€è¦é¢å¤–éªŒè¯ï¼Œæš‚æ—¶ä¸åŒ¹é…
                    print(f"   âš ï¸ æ–‡ä»¶è·¯å¾„åªåŒ…å«æ–‡ä»¶å¤¹åç§°ï¼Œéœ€è¦é¢å¤–éªŒè¯: {file_path}")
                    return False
    
    # æ–¹æ³•2: ä¸¥æ ¼åŒ¹é… - å¦‚æœæ— æ³•é€šè¿‡è·¯å¾„æ˜ å°„ç¡®å®šæ–‡ä»¶æ˜¯å¦åœ¨ç›®æ ‡æ–‡ä»¶å¤¹ä¸­ï¼Œåˆ™æ’é™¤è¯¥æ–‡ä»¶
    # è¿™ç¡®ä¿åªæœ‰æ˜ç¡®å±äºç›®æ ‡æ–‡ä»¶å¤¹çš„æ–‡ä»¶æ‰ä¼šè¢«åŒ…å«ï¼Œé¿å…è¯¯åŒ¹é…
    print(f"   âŒ æ— æ³•é€šè¿‡è·¯å¾„æ˜ å°„ç¡®å®šæ–‡ä»¶æ˜¯å¦åœ¨ç›®æ ‡æ–‡ä»¶å¤¹ä¸­ï¼Œæ’é™¤è¯¥æ–‡ä»¶")
    return False

def is_file_in_folder(file_node, target_folder_id, file_path, parent_folder_id=None):
    """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦åœ¨æŒ‡å®šçš„æ–‡ä»¶å¤¹ä¸­ï¼ˆåŒ…æ‹¬å­æ–‡ä»¶å¤¹ï¼‰- ä¿ç•™å‘åå…¼å®¹æ€§"""
    if not target_folder_id:
        return False
    
    target_folder_id_str = str(target_folder_id)
    file_name = file_node.get('name', '')
    
    # æ–¹æ³•1: ç›´æ¥æ£€æŸ¥çˆ¶æ–‡ä»¶å¤¹ID
    if parent_folder_id and str(parent_folder_id) == target_folder_id_str:
        print(f"   âœ… æ–‡ä»¶ '{file_name}' åŒ¹é…çˆ¶æ–‡ä»¶å¤¹ID")
        return True
    
    # æ–¹æ³•2: æ£€æŸ¥æ–‡ä»¶è·¯å¾„ä¸­æ˜¯å¦åŒ…å«ç›®æ ‡æ–‡ä»¶å¤¹ID
    if target_folder_id_str in file_path:
        print(f"   âœ… æ–‡ä»¶ '{file_name}' è·¯å¾„åŒ…å«ç›®æ ‡æ–‡ä»¶å¤¹ID")
        return True
    
    # æ–¹æ³•3: æ£€æŸ¥è·¯å¾„çš„å„ä¸ªéƒ¨åˆ†æ˜¯å¦åŒ…å«ç›®æ ‡æ–‡ä»¶å¤¹ID
    path_parts = file_path.split('/')
    for part in path_parts:
        if target_folder_id_str == part:
            print(f"   âœ… æ–‡ä»¶ '{file_name}' è·¯å¾„éƒ¨åˆ†åŒ¹é…")
            return True
    
    return False

def path_contains_folder(file_path, folder_id):
    """æ£€æŸ¥æ–‡ä»¶è·¯å¾„æ˜¯å¦åŒ…å«æŒ‡å®šæ–‡ä»¶å¤¹ï¼ˆä¿ç•™å‘åå…¼å®¹æ€§ï¼‰"""
    # å¦‚æœæ²¡æœ‰æŒ‡å®šæ–‡ä»¶å¤¹IDï¼Œåˆ™ä¸è¿‡æ»¤ï¼ˆè¿”å›Falseè¡¨ç¤ºä¸åŒ…å«ï¼‰
    if not folder_id:
        return False
    
    # å¦‚æœæ²¡æœ‰æ–‡ä»¶è·¯å¾„ï¼Œåˆ™ä¸åŒ…å«
    if not file_path:
        return False
    
    # å°†æ–‡ä»¶å¤¹IDè½¬æ¢ä¸ºå­—ç¬¦ä¸²è¿›è¡Œæ¯”è¾ƒ
    folder_id_str = str(folder_id)
    
    # æ£€æŸ¥è·¯å¾„ä¸­æ˜¯å¦åŒ…å«æŒ‡å®šçš„æ–‡ä»¶å¤¹ID
    # æ”¯æŒå¤šç§åŒ¹é…æ–¹å¼ï¼šç›´æ¥åŒ…å«ã€è·¯å¾„åˆ†éš”ç¬¦åŒ¹é…ç­‰
    if folder_id_str in file_path:
        return True
    
    # å¦‚æœfolder_idçœ‹èµ·æ¥åƒä¸€ä¸ªæ–‡ä»¶å¤¹åç§°è€Œä¸æ˜¯IDï¼Œä¹Ÿè¿›è¡ŒåŒ¹é…
    path_parts = file_path.split('/')
    return folder_id_str in path_parts

def get_cached_data(cache_key):
    """è·å–ç¼“å­˜æ•°æ®"""
    cache_file = os.path.join(CACHE_DIR, f"{cache_key}.json")
    
    if os.path.exists(cache_file):
        try:
            # æ£€æŸ¥ç¼“å­˜æ˜¯å¦è¿‡æœŸ
            file_time = datetime.fromtimestamp(os.path.getmtime(cache_file))
            if datetime.now() - file_time < timedelta(hours=CACHE_EXPIRY_HOURS):
                with open(cache_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
        except Exception:
            pass
    
    return None

def cache_data(cache_key, data):
    """ç¼“å­˜æ•°æ®"""
    cache_file = os.path.join(CACHE_DIR, f"{cache_key}.json")
    
    try:
        with open(cache_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"ç¼“å­˜æ•°æ®å¤±è´¥: {str(e)}")

def execute_download_task(task_id, access_token):
    """æ‰§è¡Œä¸‹è½½ä»»åŠ¡"""
    task = download_tasks[task_id]
    task['status'] = 'running'
    
    try:
        project_id = task['project_id']
        file_ids = task['file_ids']
        
        # å‰µå»ºç©ºæ–‡ä»¶å¤¾
        empty_folders = task.get('empty_folders', [])
        project_name = task.get('project_name', 'Project Files')
        if empty_folders:
            print(f"ğŸ“ é–‹å§‹å‰µå»º {len(empty_folders)} å€‹ç©ºæ–‡ä»¶å¤¾...")
            for folder_info in empty_folders:
                folder_path = folder_info.get('path', '')
                folder_name = folder_info.get('name', '')
                if folder_path:
                    try:
                        # æ§‹å»ºå®Œæ•´çš„æ–‡ä»¶å¤¾è·¯å¾‘
                        full_folder_path = os.path.join(DOWNLOAD_DIR, project_name, folder_path)
                        os.makedirs(full_folder_path, exist_ok=True)
                        print(f"   âœ… å‰µå»ºç©ºæ–‡ä»¶å¤¾: {folder_name} -> {full_folder_path}")
                    except Exception as e:
                        print(f"   âŒ å‰µå»ºç©ºæ–‡ä»¶å¤¾å¤±æ•—: {folder_name} - {str(e)}")
                        task['errors'].append(f"å‰µå»ºç©ºæ–‡ä»¶å¤¾å¤±æ•—: {folder_name} - {str(e)}")
            print(f"ğŸ“ ç©ºæ–‡ä»¶å¤¾å‰µå»ºå®Œæˆ")
        
        for i, file_id in enumerate(file_ids):
            try:
                # åˆå§‹åŒ–æ–‡ä»¶è¿›åº¦
                task['file_progress'][file_id] = {
                    'status': 'downloading',
                    'progress': 0,
                    'filename': f'æ–‡ä»¶_{i+1}',
                    'start_time': datetime.now().isoformat()
                }
                
                # ä¸‹è½½å•ä¸ªæ–‡ä»¶
                result = download_single_file(project_id, file_id, access_token, task)
                
                if result.get('success'):
                    task['completed_files'] += 1
                    # è®°å½•è¯¦ç»†çš„ä¸‹è½½ä¿¡æ¯
                    download_record = {
                        'file_id': file_id,
                        'filename': result.get('filename'),
                        'original_name': result.get('original_name'),
                        'file_path': result.get('file_path'),
                        'relative_path': result.get('relative_path'),
                        'file_size': result.get('file_size', 0),
                        'original_size': result.get('original_size', 0),
                        'download_time': datetime.now().isoformat()
                    }
                    task['downloaded_files'].append(download_record)
                    
                    # æ›´æ–°æ–‡ä»¶è¿›åº¦
                    task['file_progress'][file_id].update({
                        'status': 'completed',
                        'progress': 100,
                        'filename': result.get('original_name', f'æ–‡ä»¶_{i+1}'),
                        'end_time': datetime.now().isoformat()
                    })
                else:
                    task['failed_files'] += 1
                    error_msg = result.get('error', 'Unknown error')
                    task['errors'].append(f"æ–‡ä»¶ {file_id} ä¸‹è½½å¤±è´¥: {error_msg}")
                    
                    # æ›´æ–°æ–‡ä»¶è¿›åº¦
                    task['file_progress'][file_id].update({
                        'status': 'failed',
                        'progress': 0,
                        'error': error_msg,
                        'end_time': datetime.now().isoformat()
                    })
                
                # æ›´æ–°æ€»è¿›åº¦
                task['progress'] = int(((i + 1) / len(file_ids)) * 100)
                
                # çŸ­æš‚å»¶è¿Ÿé¿å…APIé™æµ
                time.sleep(0.5)
                
            except Exception as e:
                task['failed_files'] += 1
                task['errors'].append(f"æ–‡ä»¶ {file_id} ä¸‹è½½å¼‚å¸¸: {str(e)}")
        
        task['status'] = 'completed' if task['failed_files'] == 0 else 'completed_with_errors'
        task['end_time'] = datetime.now().isoformat()
        
    except Exception as e:
        task['status'] = 'failed'
        task['errors'].append(f"ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {str(e)}")
        task['end_time'] = datetime.now().isoformat()

def download_single_file(project_id, file_id, access_token, task=None):
    """ä¸‹è½½å•ä¸ªæ–‡ä»¶"""
    try:
        # è·å–ä¸‹è½½ä¿¡æ¯
        download_info_url = f"http://localhost:{config.PORT}/api/file-sync/download/{project_id}/{file_id}"
        
        response = requests.get(download_info_url, timeout=60)
        
        if response.status_code == 200:
            data = response.json()
            download_info = data.get('download_info', {})
            version_info = data.get('version_info', {})
            
            # è·å–åŸå§‹æ–‡ä»¶åå’Œè·¯å¾„ä¿¡æ¯
            # å„ªå…ˆä½¿ç”¨æ–‡ä»¶è·¯å¾‘æ˜ å°„ä¸­çš„æ–‡ä»¶åï¼Œç¢ºä¿ä¸€è‡´æ€§
            mapped_filename = None
            if task and task.get('file_path_mapping'):
                file_path_info = task['file_path_mapping'].get(file_id)
                if file_path_info:
                    mapped_filename = file_path_info.get('name')
                    print(f"   ğŸ“„ å¾æ˜ å°„ç²å–æ–‡ä»¶å: '{mapped_filename}'")
            
            # å¦‚æœæ˜ å°„ä¸­æœ‰æ–‡ä»¶åï¼Œä½¿ç”¨æ˜ å°„çš„ï¼›å¦å‰‡ä½¿ç”¨ç‰ˆæœ¬ä¿¡æ¯ä¸­çš„
            original_name = mapped_filename or version_info.get('attributes', {}).get('name', f"file_{file_id.split(':')[-1]}")
            file_size = version_info.get('attributes', {}).get('storageSize', 0)
            
            print(f"   ğŸ“„ Final filename used: '{original_name}' (Source: {'Mapping' if mapped_filename else 'Version info'})")
            
            # è·å–æ–‡ä»¶çš„çœŸå®é¡¹ç›®è·¯å¾„
            relative_path = ""
            task_options = task.get('options', {}) if task else {}
            create_folders = 'createFolders' in task_options.get('options', [])
            if task and create_folders:
                print(f"ğŸ” å¼€å§‹è·å–æ–‡ä»¶è·¯å¾„ä¿¡æ¯ - æ–‡ä»¶ID: {file_id}")
                # å°è¯•ä»ä»»åŠ¡ä¸­è·å–æ–‡ä»¶è·¯å¾„ä¿¡æ¯
                file_path_info = None
                
                # ä»ä»»åŠ¡çš„æ–‡ä»¶IDåˆ—è¡¨ä¸­æŸ¥æ‰¾å½“å‰æ–‡ä»¶çš„è·¯å¾„ä¿¡æ¯
                if task and task.get('file_path_mapping'):
                    file_path_info = task['file_path_mapping'].get(file_id)
                    print(f"   ğŸ“ æ–‡ä»¶è·¯å¾„æ˜ å°„ä¿¡æ¯: {file_path_info}")
                
                if file_path_info and 'path' in file_path_info:
                    # ä½¿ç”¨é¡¹ç›®çš„çœŸå®è·¯å¾„ç»“æ„
                    folder_path = file_path_info['path']
                    print(f"   ğŸ“‚ ä»æ˜ å°„è·å–æ–‡ä»¶å¤¹è·¯å¾„: '{folder_path}'")
                    
                    # folder_path å·²ç»æ˜¯ä¸åŒ…å«æ–‡ä»¶åçš„æ–‡ä»¶å¤¹è·¯å¾„
                    relative_path = folder_path
                    print(f"   âœ… æœ€ç»ˆä½¿ç”¨çš„ç›¸å¯¹è·¯å¾„: '{relative_path}'")
                    
                    # å¦‚æœè·¯å¾„ä¸ºç©ºï¼Œè¯´æ˜æ–‡ä»¶åœ¨æ ¹ç›®å½•
                    if not relative_path:
                        print(f"   ğŸ“ æ–‡ä»¶å°†ä¿å­˜åœ¨é¡¹ç›®æ ¹ç›®å½•")
                    else:
                        print(f"   ğŸ“ æ–‡ä»¶å°†ä¿å­˜åœ¨å­ç›®å½•: {relative_path}")
                else:
                    # å¯¹äºå•æ–‡ä»¶ä¸‹è½½ï¼ŒåŠ¨æ€è·å–æ–‡ä»¶çš„çœŸå®è·¯å¾„
                    print(f"   ğŸ” æ˜ å°„ä¸­æ²¡æœ‰è·¯å¾„ä¿¡æ¯ï¼Œå°è¯•åŠ¨æ€è·å–æ–‡ä»¶è·¯å¾„...")
                    try:
                        # è°ƒç”¨æ–‡ä»¶åˆ—è¡¨APIè·å–å•ä¸ªæ–‡ä»¶çš„è·¯å¾„ä¿¡æ¯
                        files_params = {'project_name': task.get('project_name', '')}
                        files_response = requests.get(f"http://localhost:{config.PORT}/api/download-config/project/{project_id}/files", 
                                                    params=files_params, timeout=30)
                        if files_response.status_code == 200:
                            files_data = files_response.json()
                            if files_data.get('status') == 'success':
                                all_files = files_data.get('data', {}).get('files', [])
                                # æŸ¥æ‰¾å½“å‰æ–‡ä»¶çš„è·¯å¾„ä¿¡æ¯
                                for file_info in all_files:
                                    if file_info.get('id') == file_id:
                                        folder_path = file_info.get('folder_path', '')
                                        dynamic_filename = file_info.get('name', '')
                                        relative_path = folder_path
                                        
                                        # å¦‚æœå‹•æ…‹ç²å–çš„æ–‡ä»¶åèˆ‡ç•¶å‰ä¸åŒï¼Œæ›´æ–°æ–‡ä»¶åä»¥ç¢ºä¿ä¸€è‡´æ€§
                                        if dynamic_filename and dynamic_filename != original_name:
                                            print(f"   ğŸ“„ å‹•æ…‹ç²å–çš„æ–‡ä»¶åèˆ‡åŸå§‹ä¸åŒ: '{original_name}' -> '{dynamic_filename}'")
                                            original_name = dynamic_filename
                                        
                                        print(f"   âœ… åŠ¨æ€è·å–åˆ°æ–‡ä»¶è·¯å¾„: '{relative_path}', æ–‡ä»¶å: '{original_name}'")
                                        break
                                else:
                                    print(f"   âš ï¸ åœ¨æ–‡ä»¶åˆ—è¡¨ä¸­æœªæ‰¾åˆ°æ–‡ä»¶ID: {file_id}")
                                    raise Exception("File not found")
                            else:
                                print(f"   âš ï¸ è·å–æ–‡ä»¶åˆ—è¡¨å¤±è´¥: {files_data.get('error')}")
                                raise Exception("Failed to get file list")
                        else:
                            print(f"   âš ï¸ æ–‡ä»¶åˆ—è¡¨APIè°ƒç”¨å¤±è´¥: {files_response.status_code}")
                            raise Exception("API call failed")
                    except Exception as e:
                        print(f"   âŒ åŠ¨æ€è·å–è·¯å¾„å¤±è´¥: {str(e)}")
                        # æœ€åå›é€€åˆ°ç®€å•çš„æ–‡ä»¶ç±»å‹åˆ†ç±»
                        file_extension = os.path.splitext(original_name)[1].lower()
                        if file_extension in ['.pdf', '.doc', '.docx']:
                            relative_path = "documents"
                        elif file_extension in ['.dwg', '.dxf']:
                            relative_path = "cad"
                        elif file_extension in ['.jpg', '.jpeg', '.png']:
                            relative_path = "images"
                        else:
                            relative_path = "others"
                        print(f"   ğŸ”„ å›é€€åˆ°æ–‡ä»¶ç±»å‹åˆ†ç±»: '{relative_path}'")
            
            download_method = download_info.get('method')
            
            if download_method == 'oss_signed_url':
                # ä½¿ç”¨OSSç­¾åURLä¸‹è½½åŸå§‹æ–‡ä»¶ï¼ˆå®˜æ–¹æ¨èæ–¹å¼ï¼‰
                bucket_key = download_info.get('bucket_key')
                object_key = download_info.get('object_key')
                
                print(f"ğŸš€ ä½¿ç”¨OSSç­¾åURLä¸‹è½½åŸå§‹æ–‡ä»¶: {original_name}")
                print(f"   Bucket: {bucket_key}, Object: {object_key}")
                
                if bucket_key and object_key:
                    # è·å–ç­¾åä¸‹è½½URL
                    signed_url_endpoint = f"{config.AUTODESK_API_BASE}/oss/v2/buckets/{bucket_key}/objects/{object_key}/signeds3download"
                    print(f"   è·å–ç­¾åURL: {signed_url_endpoint}")
                    
                    signed_resp = requests.get(signed_url_endpoint, headers={'Authorization': f'Bearer {access_token}'}, timeout=30)
                    
                    if signed_resp.status_code == 200:
                        signed_data = signed_resp.json()
                        download_url = signed_data.get('url')
                        file_size_from_oss = signed_data.get('size', 0)
                        
                        print(f"   âœ… è·å¾—ç­¾åURLï¼Œæ–‡ä»¶å¤§å°: {file_size_from_oss} bytes")
                        
                        if download_url:
                            # ä½¿ç”¨ç­¾åURLä¸‹è½½æ–‡ä»¶
                            print(f"   ğŸ”— å¼€å§‹ä¸‹è½½: {download_url[:100]}...")
                            
                            # æ³¨æ„ï¼šç­¾åURLä¸éœ€è¦Authorizationå¤´
                            file_response = requests.get(download_url, timeout=300)  # å¢åŠ è¶…æ—¶æ—¶é—´
                            
                            if file_response.status_code == 200:
                                # ä½¿ç”¨åŸå§‹æ–‡ä»¶å
                                filename = original_name
                                
                                # ç¡®ä¿æ–‡ä»¶åå®‰å…¨
                                filename = "".join(c for c in filename if c.isalnum() or c in (' ', '-', '_', '.')).rstrip()
                                
                                # æ ¹æ®ç›¸å¯¹è·¯å¾„åˆ›å»ºå®Œæ•´è·¯å¾„ï¼Œä½¿ç”¨é¡¹ç›®åç§°ä½œä¸ºæ ¹ç›®å½•
                                project_name = task.get('project_name', 'Project Files')
                                print(f"ğŸ’¾ æ–‡ä»¶ä¿å­˜ - é¡¹ç›®åç§°: '{project_name}', ç›¸å¯¹è·¯å¾„: '{relative_path}', æ–‡ä»¶å: '{filename}'")
                                if relative_path:
                                    file_path = os.path.join(DOWNLOAD_DIR, project_name, relative_path, filename)
                                    print(f"   ğŸ“ å®Œæ•´è·¯å¾„(æœ‰å­ç›®å½•): {file_path}")
                                else:
                                    file_path = os.path.join(DOWNLOAD_DIR, project_name, filename)
                                    print(f"   ğŸ“ å®Œæ•´è·¯å¾„(æ ¹ç›®å½•): {file_path}")
                                
                                # ä½¿ç”¨å®‰å…¨å†™å…¥å‡½æ•°
                                write_result = safe_write_file(file_path, file_response.content, filename, create_dirs=True)
                                if not write_result['success']:
                                    return {'success': False, 'error': f'Failed to save file: {write_result["error"]}'}
                                
                                file_path = write_result['file_path']
                                filename = write_result['filename']
                                final_file_size = len(file_response.content)
                                
                                print(f"âœ… OSSåŸå§‹æ–‡ä»¶ä¸‹è½½æˆåŠŸ: {filename} ({final_file_size} bytes)")
                                
                                return {
                                    'success': True,
                                    'filename': filename,
                                    'file_path': file_path,
                                    'relative_path': relative_path,
                                    'original_name': original_name,
                                    'file_size': final_file_size,
                                    'original_size': file_size_from_oss or file_size,
                                    'download_method': 'oss_signed_url'
                                }
                            else:
                                print(f"âŒ ç­¾åURLä¸‹è½½å¤±è´¥: {file_response.status_code}")
                                return {'success': False, 'error': f'Signed URL download failed: {file_response.status_code}'}
                        else:
                            print("âŒ ç­¾åå“åº”ä¸­æ²¡æœ‰URL")
                            return {'success': False, 'error': 'No URL in signed response'}
                    else:
                        print(f"âŒ è·å–ç­¾åURLå¤±è´¥: {signed_resp.status_code} - {signed_resp.text}")
                        return {'success': False, 'error': f'Failed to get signed URL: {signed_resp.status_code}'}
                else:
                    return {'success': False, 'error': 'Missing bucket_key or object_key'}
            
            elif download_method == 'direct_storage_link':
                # ç›´æ¥ä½¿ç”¨å­˜å‚¨é“¾æ¥ä¸‹è½½
                download_url = download_info.get('download_url')
                
                print(f"ğŸš€ ä½¿ç”¨ç›´æ¥å­˜å‚¨é“¾æ¥ä¸‹è½½: {original_name}")
                
                if download_url:
                    direct_response = requests.get(download_url, headers={'Authorization': f'Bearer {access_token}'}, timeout=120)
                    
                    if direct_response.status_code == 200:
                        # ä½¿ç”¨åŸå§‹æ–‡ä»¶å
                        filename = original_name
                        
                        # ç¡®ä¿æ–‡ä»¶åå®‰å…¨
                        filename = "".join(c for c in filename if c.isalnum() or c in (' ', '-', '_', '.')).rstrip()
                        
                        # æ ¹æ®ç›¸å¯¹è·¯å¾„åˆ›å»ºå®Œæ•´è·¯å¾„ï¼Œä½¿ç”¨é¡¹ç›®åç§°ä½œä¸ºæ ¹ç›®å½•
                        project_name = task.get('project_name', 'Project Files')
                        if relative_path:
                            file_path = os.path.join(DOWNLOAD_DIR, project_name, relative_path, filename)
                        else:
                            file_path = os.path.join(DOWNLOAD_DIR, project_name, filename)
                        
                        # å¤„ç†æ–‡ä»¶åå†²çª
                        if os.path.exists(file_path):
                            base_name, ext = os.path.splitext(filename)
                            timestamp = int(time.time())
                            filename = f"{base_name}_{timestamp}{ext}"
                            if relative_path:
                                file_path = os.path.join(DOWNLOAD_DIR, project_name, relative_path, filename)
                            else:
                                file_path = os.path.join(DOWNLOAD_DIR, project_name, filename)
                        
                        try:
                            # ç¡®ä¿ç›®å½•å­˜åœ¨
                            os.makedirs(os.path.dirname(file_path), exist_ok=True)
                            with open(file_path, 'wb') as f:
                                f.write(direct_response.content)
                        except PermissionError as pe:
                            print(f"âŒ æƒé™é”™è¯¯ï¼Œå°è¯•ä½¿ç”¨å¤‡ç”¨æ–‡ä»¶å: {str(pe)}")
                            base_name, ext = os.path.splitext(filename)
                            timestamp = int(time.time())
                            filename = f"{base_name}_backup_{timestamp}{ext}"
                            if relative_path:
                                file_path = os.path.join(DOWNLOAD_DIR, project_name, relative_path, filename)
                            else:
                                file_path = os.path.join(DOWNLOAD_DIR, project_name, filename)
                            # ç¡®ä¿ç›®å½•å­˜åœ¨
                            os.makedirs(os.path.dirname(file_path), exist_ok=True)
                            with open(file_path, 'wb') as f:
                                f.write(direct_response.content)
                        
                        final_file_size = len(direct_response.content)
                        
                        print(f"âœ… Data Management APIç›´æ¥ä¸‹è½½æˆåŠŸ: {filename} ({final_file_size} bytes)")
                        
                        return {
                            'success': True,
                            'filename': filename,
                            'file_path': file_path,
                            'relative_path': relative_path,
                            'original_name': original_name,
                            'file_size': final_file_size,
                            'original_size': file_size,
                            'download_method': 'data_management_direct'
                        }
                    else:
                        print(f"âŒ Data Management APIç›´æ¥ä¸‹è½½å¤±è´¥: {direct_response.status_code}")
                        return {'success': False, 'error': f'Data Management direct download failed: {direct_response.status_code}'}
                else:
                    return {'success': False, 'error': 'No download URL provided'}
            
            elif download_method == 'direct_pdf':
                # ç›´æ¥ä¸‹è½½å®Œæ•´PDF
                pdf_urn = download_info.get('pdf_urn')
                download_url = f"{download_info.get('download_base_url')}/{pdf_urn}"
                
                print(f"ğŸ“„ ç›´æ¥ä¸‹è½½å®Œæ•´PDF: {original_name}")
                
                pdf_response = requests.get(download_url, headers={'Authorization': f'Bearer {access_token}'}, timeout=120)
                
                if pdf_response.status_code == 200:
                    # ä½¿ç”¨åŸå§‹æ–‡ä»¶å
                    base_name = os.path.splitext(original_name)[0]
                    filename = f"{base_name}.pdf"
                    
                    # ç¡®ä¿æ–‡ä»¶åå®‰å…¨
                    filename = "".join(c for c in filename if c.isalnum() or c in (' ', '-', '_', '.')).rstrip()
                    
                    # æ ¹æ®ç›¸å¯¹è·¯å¾„åˆ›å»ºå®Œæ•´è·¯å¾„ï¼Œä½¿ç”¨é¡¹ç›®åç§°ä½œä¸ºæ ¹ç›®å½•
                    project_name = task.get('project_name', 'Project Files')
                    if relative_path:
                        file_path = os.path.join(DOWNLOAD_DIR, project_name, relative_path, filename)
                    else:
                        file_path = os.path.join(DOWNLOAD_DIR, project_name, filename)
                    
                    # å¤„ç†æ–‡ä»¶åå†²çªï¼Œå¦‚æœæ–‡ä»¶å·²å­˜åœ¨åˆ™æ·»åŠ æ—¶é—´æˆ³
                    if os.path.exists(file_path):
                        base_name, ext = os.path.splitext(filename)
                        timestamp = int(time.time())
                        filename = f"{base_name}_{timestamp}{ext}"
                        if relative_path:
                            file_path = os.path.join(DOWNLOAD_DIR, project_name, relative_path, filename)
                        else:
                            file_path = os.path.join(DOWNLOAD_DIR, project_name, filename)
                    
                    # ä½¿ç”¨å®‰å…¨å†™å…¥å‡½æ•°
                    write_result = safe_write_file(file_path, pdf_response.content, filename, create_dirs=True)
                    if not write_result['success']:
                        return {'success': False, 'error': f'Failed to save file: {write_result["error"]}'}
                    
                    file_path = write_result['file_path']
                    filename = write_result['filename']
                    
                    final_file_size = len(pdf_response.content)
                    
                    print(f"âœ… å®Œæ•´PDFä¸‹è½½æˆåŠŸ: {filename} ({final_file_size} bytes)")
                    
                    return {
                        'success': True,
                        'filename': filename,
                        'file_path': file_path,
                        'relative_path': relative_path,
                        'original_name': original_name,
                        'file_size': final_file_size,
                        'original_size': file_size,
                        'download_method': 'direct_pdf'
                    }
                else:
                    print(f"âŒ ç›´æ¥PDFä¸‹è½½å¤±è´¥: {pdf_response.status_code}")
                    return {'success': False, 'error': f'Direct PDF download failed: {pdf_response.status_code}'}
            
            elif download_method == 'original_file':
                # ä¸‹è½½åŸå§‹æ–‡ä»¶
                storage_location = download_info.get('storage_location')
                
                print(f"ğŸ“ ä¸‹è½½åŸå§‹æ–‡ä»¶: {original_name}")
                
                # æ„å»ºOSSä¸‹è½½URL
                # storage_locationæ ¼å¼é€šå¸¸æ˜¯: urn:adsk.objects:os.object:bucket/object_key
                if storage_location and storage_location.startswith('urn:adsk.objects:os.object:'):
                    object_path = storage_location.replace('urn:adsk.objects:os.object:', '')
                    
                    # åˆ†ç¦»bucketå’Œobject_key
                    if '/' in object_path:
                        bucket_key, object_key = object_path.split('/', 1)
                        download_url = f"{config.AUTODESK_API_BASE}/oss/v2/buckets/{bucket_key}/objects/{object_key}"
                    else:
                        # å¦‚æœæ ¼å¼ä¸ç¬¦åˆé¢„æœŸï¼Œå°è¯•ç›´æ¥ä½¿ç”¨
                        download_url = f"{config.AUTODESK_API_BASE}/oss/v2/buckets/{object_path}"
                    
                    print(f"ğŸ”— OSSä¸‹è½½URL: {download_url}")
                    
                    file_response = requests.get(download_url, headers={'Authorization': f'Bearer {access_token}'}, timeout=120)
                    
                    if file_response.status_code == 200:
                        # ä½¿ç”¨åŸå§‹æ–‡ä»¶å
                        filename = original_name
                        
                        # ç¡®ä¿æ–‡ä»¶åå®‰å…¨
                        filename = "".join(c for c in filename if c.isalnum() or c in (' ', '-', '_', '.')).rstrip()
                        
                        # æ ¹æ®ç›¸å¯¹è·¯å¾„åˆ›å»ºå®Œæ•´è·¯å¾„ï¼Œä½¿ç”¨é¡¹ç›®åç§°ä½œä¸ºæ ¹ç›®å½•
                        project_name = task.get('project_name', 'Project Files')
                        if relative_path:
                            file_path = os.path.join(DOWNLOAD_DIR, project_name, relative_path, filename)
                        else:
                            file_path = os.path.join(DOWNLOAD_DIR, project_name, filename)
                        
                        # å¤„ç†æ–‡ä»¶åå†²çªï¼Œå¦‚æœæ–‡ä»¶å·²å­˜åœ¨åˆ™æ·»åŠ æ—¶é—´æˆ³
                        if os.path.exists(file_path):
                            base_name, ext = os.path.splitext(filename)
                            timestamp = int(time.time())
                            filename = f"{base_name}_{timestamp}{ext}"
                            if relative_path:
                                file_path = os.path.join(DOWNLOAD_DIR, project_name, relative_path, filename)
                            else:
                                file_path = os.path.join(DOWNLOAD_DIR, project_name, filename)
                        
                        try:
                            # ç¡®ä¿ç›®å½•å­˜åœ¨
                            os.makedirs(os.path.dirname(file_path), exist_ok=True)
                            with open(file_path, 'wb') as f:
                                f.write(file_response.content)
                        except PermissionError as pe:
                            print(f"âŒ æƒé™é”™è¯¯ï¼Œå°è¯•ä½¿ç”¨å¤‡ç”¨æ–‡ä»¶å: {str(pe)}")
                            # ä½¿ç”¨æ—¶é—´æˆ³åˆ›å»ºå”¯ä¸€æ–‡ä»¶å
                            base_name, ext = os.path.splitext(filename)
                            timestamp = int(time.time())
                            filename = f"{base_name}_backup_{timestamp}{ext}"
                            if relative_path:
                                file_path = os.path.join(DOWNLOAD_DIR, project_name, relative_path, filename)
                            else:
                                file_path = os.path.join(DOWNLOAD_DIR, project_name, filename)
                            # ç¡®ä¿ç›®å½•å­˜åœ¨
                            os.makedirs(os.path.dirname(file_path), exist_ok=True)
                            with open(file_path, 'wb') as f:
                                f.write(file_response.content)
                        
                        final_file_size = len(file_response.content)
                        
                        print(f"âœ… åŸå§‹æ–‡ä»¶ä¸‹è½½æˆåŠŸ: {filename} ({final_file_size} bytes)")
                        
                        return {
                            'success': True,
                            'filename': filename,
                            'file_path': file_path,
                            'original_name': original_name,
                            'file_size': final_file_size,
                            'original_size': file_size,
                            'download_method': 'original_file'
                        }
                    else:
                        print(f"âŒ åŸå§‹æ–‡ä»¶ä¸‹è½½å¤±è´¥: {file_response.status_code}")
                        return {'success': False, 'error': f'Original file download failed: {file_response.status_code}'}
                else:
                    return {'success': False, 'error': 'Invalid storage location format'}
            
            elif download_method == 'model_derivative':
                # ä¸‹è½½æ‰€æœ‰PDFé¡µé¢å¹¶åˆå¹¶
                pdf_pages = download_info.get('pdf_pages', [])
                download_base_url = download_info.get('download_base_url')
                
                if not pdf_pages:
                    print("âŒ æ²¡æœ‰æ‰¾åˆ°PDFé¡µé¢ä¿¡æ¯")
                    return {'success': False, 'error': 'No PDF pages found'}
                
                print(f"ğŸ“„ å¼€å§‹ä¸‹è½½ {len(pdf_pages)} ä¸ªPDFé¡µé¢...")
                
                # ä¸‹è½½æ‰€æœ‰é¡µé¢
                page_contents = []
                total_size = 0
                
                for i, page_urn in enumerate(pdf_pages):
                    try:
                        page_download_url = f"{download_base_url}/{page_urn}"
                        print(f"ğŸ”— ä¸‹è½½é¡µé¢ {i+1}/{len(pdf_pages)}: {page_urn}")
                        
                        page_resp = requests.get(page_download_url, 
                                               headers={'Authorization': f'Bearer {access_token}'}, 
                                               timeout=60)
                        
                        if page_resp.status_code == 200:
                            page_contents.append(page_resp.content)
                            total_size += len(page_resp.content)
                            print(f"âœ… é¡µé¢ {i+1} ä¸‹è½½æˆåŠŸ ({len(page_resp.content)} bytes)")
                        else:
                            print(f"âŒ é¡µé¢ {i+1} ä¸‹è½½å¤±è´¥: {page_resp.status_code}")
                            # ç»§ç»­ä¸‹è½½å…¶ä»–é¡µé¢ï¼Œä¸å› ä¸ºä¸€é¡µå¤±è´¥è€Œç»ˆæ­¢
                            
                    except Exception as e:
                        print(f"âŒ ä¸‹è½½é¡µé¢ {i+1} æ—¶å‡ºé”™: {str(e)}")
                        continue
                
                if not page_contents:
                    return {'success': False, 'error': 'Failed to download any PDF pages'}
                
                # å¦‚æœåªæœ‰ä¸€é¡µï¼Œç›´æ¥ä¿å­˜
                if len(page_contents) == 1:
                    base_name = os.path.splitext(original_name)[0]
                    filename = f"{base_name}.pdf"
                    
                    # ç¡®ä¿æ–‡ä»¶åå®‰å…¨
                    filename = "".join(c for c in filename if c.isalnum() or c in (' ', '-', '_', '.')).rstrip()
                    
                    # æ ¹æ®ç›¸å¯¹è·¯å¾„åˆ›å»ºå®Œæ•´è·¯å¾„ï¼Œä½¿ç”¨é¡¹ç›®åç§°ä½œä¸ºæ ¹ç›®å½•
                    project_name = task.get('project_name', 'Project Files')
                    if relative_path:
                        file_path = os.path.join(DOWNLOAD_DIR, project_name, relative_path, filename)
                    else:
                        file_path = os.path.join(DOWNLOAD_DIR, project_name, filename)
                    
                    # å¤„ç†æ–‡ä»¶åå†²çª
                    if os.path.exists(file_path):
                        base_name, ext = os.path.splitext(filename)
                        timestamp = int(time.time())
                        filename = f"{base_name}_{timestamp}{ext}"
                        if relative_path:
                            file_path = os.path.join(DOWNLOAD_DIR, project_name, relative_path, filename)
                        else:
                            file_path = os.path.join(DOWNLOAD_DIR, project_name, filename)
                    
                    try:
                        # ç¡®ä¿ç›®å½•å­˜åœ¨
                        os.makedirs(os.path.dirname(file_path), exist_ok=True)
                        with open(file_path, 'wb') as f:
                            f.write(page_contents[0])
                        
                        print(f"âœ… å•é¡µPDFä¿å­˜æˆåŠŸ: {filename}")
                        
                        return {
                            'success': True,
                            'filename': filename,
                            'file_path': file_path,
                            'original_name': original_name,
                            'file_size': len(page_contents[0]),
                            'original_size': file_size,
                            'download_method': 'single_pdf_page'
                        }
                    except Exception as e:
                        print(f"âŒ ä¿å­˜PDFæ–‡ä»¶å¤±è´¥: {str(e)}")
                        return {'success': False, 'error': f'Failed to save PDF: {str(e)}'}
                
                # å¤šé¡µPDFéœ€è¦åˆå¹¶ - ä½†è¿™æ˜¯æœ€ä½ä¼˜å…ˆçº§çš„æ–¹æ¡ˆ
                # å…ˆå°è¯•ä¿å­˜æ‰€æœ‰é¡µé¢ä¸ºå•ç‹¬æ–‡ä»¶ï¼Œæç¤ºç”¨æˆ·æ‰‹åŠ¨åˆå¹¶
                base_name = os.path.splitext(original_name)[0]
                saved_pages = []
                project_name = task.get('project_name', 'Project Files')
                
                for i, content in enumerate(page_contents):
                    page_filename = f"{base_name}_page{i+1}.pdf"
                    page_filename = "".join(c for c in page_filename if c.isalnum() or c in (' ', '-', '_', '.')).rstrip()
                    
                    if relative_path:
                        page_path = os.path.join(DOWNLOAD_DIR, project_name, relative_path, page_filename)
                    else:
                        page_path = os.path.join(DOWNLOAD_DIR, project_name, page_filename)
                    
                    try:
                        # ç¡®ä¿ç›®å½•å­˜åœ¨
                        os.makedirs(os.path.dirname(page_path), exist_ok=True)
                        with open(page_path, 'wb') as f:
                            f.write(content)
                        saved_pages.append(page_filename)
                        print(f"âœ… ä¿å­˜é¡µé¢ {i+1}: {page_filename}")
                    except Exception as e:
                        print(f"âŒ ä¿å­˜é¡µé¢ {i+1} å¤±è´¥: {str(e)}")
                
                if saved_pages:
                    print(f"âš ï¸ PDFæ–‡ä»¶æœ‰ {len(page_contents)} é¡µï¼Œå·²ä¿å­˜ä¸ºå•ç‹¬æ–‡ä»¶ã€‚å»ºè®®ä½¿ç”¨PDFå·¥å…·æ‰‹åŠ¨åˆå¹¶ã€‚")
                    
                    return {
                        'success': True,
                        'filename': f"{base_name}_pages.txt",  # åˆ›å»ºä¸€ä¸ªè¯´æ˜æ–‡ä»¶
                        'file_path': DOWNLOAD_DIR,
                        'original_name': original_name,
                        'file_size': total_size,
                        'original_size': file_size,
                        'download_method': 'multiple_pdf_pages',
                        'saved_pages': saved_pages,
                        'note': f'PDFæ–‡ä»¶åŒ…å«{len(page_contents)}é¡µï¼Œå·²ä¿å­˜ä¸ºå•ç‹¬æ–‡ä»¶ï¼Œå»ºè®®æ‰‹åŠ¨åˆå¹¶'
                    }
                
                return {'success': False, 'error': 'Failed to save PDF pages'}
        
        return {'success': False, 'error': 'Download failed'}
        
    except Exception as e:
        print(f"ä¸‹è½½æ–‡ä»¶ {file_id} å¤±è´¥: {str(e)}")
        return {'success': False, 'error': str(e)}

@download_config_bp.route('/api/download-config/download-urn', methods=['GET'])
def download_urn_endpoint():
    """URNä¸‹è½½ç«¯ç‚¹ - ä½¿ç”¨ç°æœ‰çš„urn_download_simpleæ¨¡å—"""
    try:
        urn = request.args.get('urn')
        document_name = request.args.get('document_name')
        
        if not urn:
            return jsonify({
                'success': False,
                'error': 'URNå‚æ•°ç¼ºå¤±'
            }), 400
        
        print(f"[URN Download] å¤„ç†URNä¸‹è½½è¯·æ±‚: {urn}")
        
        # ä½¿ç”¨ç°æœ‰çš„URNä¸‹è½½åŠŸèƒ½
        if 'os.object:' in urn:
            # OSS Objectç±»å‹ï¼ˆåŒ…æ‹¬å¿«ç…§ï¼‰
            result = download_oss_object(urn, document_name=document_name)
        else:
            # é€šç”¨ä¸‹è½½æ–¹æ³•
            result = download_by_urn(urn, document_name=document_name)
        
        print(f"[URN Download] ä¸‹è½½ç»“æœ: {result.get('success', False)}")
        
        if result.get('success'):
            return jsonify(result)
        else:
            return jsonify(result), 400
        
    except Exception as e:
        print(f"[URN Download] ä¸‹è½½å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': f'ä¸‹è½½å¤±è´¥: {str(e)}'
        }), 500
