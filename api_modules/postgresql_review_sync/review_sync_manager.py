"""
å®¡æ‰¹ç³»ç»ŸåŒæ­¥ç®¡ç†å™¨ - ä¼˜åŒ–ç‰ˆ
è´Ÿè´£ä»ACCåŒæ­¥å·¥ä½œæµå’Œè¯„å®¡æ•°æ®åˆ°æœ¬åœ°æ•°æ®åº“
æ”¯æŒå…¨é‡åŒæ­¥å’Œå¢é‡åŒæ­¥

ä¼˜åŒ–ç‰¹æ€§ï¼š
1. å¹¶è¡ŒAPIè°ƒç”¨ - ä½¿ç”¨ThreadPoolExecutorå®ç°å¹¶å‘è¯·æ±‚
2. æ‰¹é‡æ•°æ®åº“æ’å…¥ - å‡å°‘æ•°æ®åº“å¾€è¿”æ¬¡æ•°
3. æ™ºèƒ½åˆ†é¡µå’Œé™æµ - è‡ªåŠ¨å¤„ç†APIåˆ†é¡µå’Œé™æµé‡è¯•
4. æ€§èƒ½ç›‘æ§ - è¯¦ç»†çš„æ€§èƒ½ç»Ÿè®¡å’Œæ—¶é—´è¿½è¸ª
"""

import sys
import os
from typing import Dict, List, Optional, Any, Tuple
from datetime import datetime, timezone
import uuid
import json
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from functools import wraps

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '../..')))

# Try different import paths
try:
    from database_sql.review_data_access import ReviewDataAccess
    from database_sql.neon_config import NeonConfig
except ImportError:
    print("Warning: Could not import from database_sql, trying alternative path")
    try:
        sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '../../database_sql')))
        from review_data_access import ReviewDataAccess
        from neon_config import NeonConfig
    except ImportError:
        print("Warning: Could not import ReviewDataAccess, using placeholder")
        ReviewDataAccess = None
        NeonConfig = None


class ReviewSyncManager:
    """å®¡æ‰¹ç³»ç»ŸåŒæ­¥ç®¡ç†å™¨ - ä¼˜åŒ–ç‰ˆ"""
    
    def __init__(self, data_access: Optional[ReviewDataAccess] = None, max_workers: int = 10):
        """
        åˆå§‹åŒ–åŒæ­¥ç®¡ç†å™¨
        
        Args:
            data_access: æ•°æ®è®¿é—®å±‚å®ä¾‹ï¼Œå¦‚æœä¸ºNoneåˆ™åˆ›å»ºæ–°å®ä¾‹
            max_workers: å¹¶å‘å·¥ä½œçº¿ç¨‹æ•°ï¼ˆå»ºè®®5-10ï¼Œé¿å…APIé™æµï¼‰
        """
        self.da = data_access or ReviewDataAccess()
        self.max_workers = max_workers
        self.sync_stats = {
            'workflows_synced': 0,
            'workflows_updated': 0,
            'workflows_skipped': 0,
            'reviews_synced': 0,
            'reviews_updated': 0,
            'reviews_skipped': 0,
            'errors': [],
            'performance': {
                'api_calls': 0,
                'api_time': 0.0,
                'db_time': 0.0,
                'total_time': 0.0
            }
        }
    
    # ========================================================================
    # APIé™æµå’Œé‡è¯•è£…é¥°å™¨
    # ========================================================================
    
    @staticmethod
    def rate_limit_retry(max_retries: int = 3, backoff_factor: float = 2.0):
        """
        APIé™æµé‡è¯•è£…é¥°å™¨
        
        Args:
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
            backoff_factor: é€€é¿å› å­ï¼ˆæŒ‡æ•°é€€é¿ï¼‰
        """
        def decorator(func):
            @wraps(func)
            def wrapper(*args, **kwargs):
                for attempt in range(max_retries):
                    try:
                        return func(*args, **kwargs)
                    except Exception as e:
                        error_str = str(e).lower()
                        # æ£€æŸ¥æ˜¯å¦æ˜¯é™æµé”™è¯¯
                        if '429' in error_str or 'rate limit' in error_str or 'too many requests' in error_str:
                            if attempt < max_retries - 1:
                                wait_time = backoff_factor ** attempt
                                print(f"âš  APIé™æµï¼Œç­‰å¾… {wait_time:.1f}ç§’åé‡è¯•... (å°è¯• {attempt + 1}/{max_retries})")
                                time.sleep(wait_time)
                            else:
                                raise Exception(f"APIé™æµï¼Œå·²é‡è¯•{max_retries}æ¬¡ä»å¤±è´¥: {str(e)}")
                        else:
                            # éé™æµé”™è¯¯ç›´æ¥æŠ›å‡º
                            raise
                raise Exception(f"APIè°ƒç”¨å¤±è´¥ï¼Œå·²é‡è¯•{max_retries}æ¬¡")
            return wrapper
        return decorator
    
    # ========================================================================
    # å·¥ä½œæµåŒæ­¥
    # ========================================================================
    
    def sync_workflow_from_acc(self, acc_workflow_data: Dict[str, Any]) -> Tuple[int, str]:
        """
        ä»ACCåŒæ­¥å•ä¸ªå·¥ä½œæµ
        
        Args:
            acc_workflow_data: ACCå·¥ä½œæµæ•°æ®
            
        Returns:
            (workflow_id, action) - å·¥ä½œæµIDå’Œæ“ä½œç±»å‹('created', 'updated', 'skipped')
        """
        try:
            acc_workflow_id = acc_workflow_data.get('id')
            if not acc_workflow_id:
                raise ValueError("ACCå·¥ä½œæµæ•°æ®ç¼ºå°‘ID")
            
            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
            existing_workflow = self.da.get_workflow_by_acc_id(acc_workflow_id)
            
            # å‡†å¤‡å·¥ä½œæµæ•°æ®
            workflow_data = self._transform_acc_workflow_data(acc_workflow_data)
            
            if existing_workflow:
                # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°
                if self._should_update_workflow(existing_workflow, workflow_data):
                    # æ›´æ–°ç°æœ‰å·¥ä½œæµ
                    self.da.update_workflow(existing_workflow['id'], workflow_data)
                    self.sync_stats['workflows_updated'] += 1
                    return existing_workflow['id'], 'updated'
                else:
                    self.sync_stats['workflows_skipped'] += 1
                    return existing_workflow['id'], 'skipped'
            else:
                # åˆ›å»ºæ–°å·¥ä½œæµ
                workflow_id = self.da.create_workflow(workflow_data)
                self.sync_stats['workflows_synced'] += 1
                return workflow_id, 'created'
        
        except Exception as e:
            error_msg = f"åŒæ­¥å·¥ä½œæµå¤±è´¥ (ACC ID: {acc_workflow_data.get('id')}): {str(e)}"
            self.sync_stats['errors'].append(error_msg)
            print(f"âœ— {error_msg}")
            raise
    
    def _transform_acc_workflow_data(self, acc_data: Dict[str, Any]) -> Dict[str, Any]:
        """è½¬æ¢ACCå·¥ä½œæµæ•°æ®ä¸ºæœ¬åœ°æ ¼å¼"""
        return {
            'workflow_uuid': acc_data.get('id'),  # ä½¿ç”¨ ACC çš„ workflow ID ä½œä¸º UUID
            'project_id': acc_data.get('projectId'),
            'data_source': 'acc_sync',
            'acc_workflow_id': acc_data.get('id'),
            'name': acc_data.get('name', 'Unnamed Workflow'),
            'description': acc_data.get('description'),
            'notes': acc_data.get('notes'),
            'status': self._map_workflow_status(acc_data.get('status', 'active')),
            'additional_options': acc_data.get('additionalOptions', {}),
            'approval_status_options': acc_data.get('approvalStatusOptions', []),
            'copy_files_options': acc_data.get('copyFilesOptions', {}),
            'attached_attributes': acc_data.get('attachedAttributes', []),
            'update_attributes_options': acc_data.get('updateAttributesOptions', {}),
            'steps': acc_data.get('steps', []),
            'created_by': acc_data.get('createdBy', {}),  # å­˜å‚¨å®Œæ•´çš„ç”¨æˆ·å¯¹è±¡
            'created_at': self._parse_timestamp(acc_data.get('createdAt')),
            'updated_at': self._parse_timestamp(acc_data.get('updatedAt')),
            'last_synced_at': datetime.now(timezone.utc),
            'sync_status': 'synced'
        }
    
    def _map_workflow_status(self, acc_status: str) -> str:
        """æ˜ å°„ACCå·¥ä½œæµçŠ¶æ€åˆ°æœ¬åœ°çŠ¶æ€"""
        status_map = {
            'active': 'ACTIVE',
            'inactive': 'INACTIVE',
            'draft': 'DRAFT',
            'archived': 'ARCHIVED'
        }
        return status_map.get(acc_status.lower(), 'ACTIVE')
    
    def _should_update_workflow(self, existing: Dict, new_data: Dict) -> bool:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦æ›´æ–°å·¥ä½œæµ"""
        # æ¯”è¾ƒå…³é”®å­—æ®µ
        key_fields = ['name', 'description', 'status', 'steps']
        for field in key_fields:
            if existing.get(field) != new_data.get(field):
                return True
        return False
    
    # ========================================================================
    # è¯„å®¡åŒæ­¥
    # ========================================================================
    
    def sync_review_from_acc(self, acc_review_data: Dict[str, Any]) -> Tuple[int, str]:
        """
        ä»ACCåŒæ­¥å•ä¸ªè¯„å®¡
        
        Args:
            acc_review_data: ACCè¯„å®¡æ•°æ®
            
        Returns:
            (review_id, action) - è¯„å®¡IDå’Œæ“ä½œç±»å‹
        """
        try:
            acc_review_id = acc_review_data.get('id')
            if not acc_review_id:
                raise ValueError("ACCè¯„å®¡æ•°æ®ç¼ºå°‘ID")
            
            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
            existing_review = self.da.get_review_by_acc_id(acc_review_id)
            
            # å‡†å¤‡è¯„å®¡æ•°æ®
            review_data = self._transform_acc_review_data(acc_review_data)
            
            if existing_review:
                # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°
                if self._should_update_review(existing_review, review_data):
                    self.da.update_review(existing_review['id'], review_data)
                    review_id = existing_review['id']
                    action = 'updated'
                    self.sync_stats['reviews_updated'] += 1
                else:
                    review_id = existing_review['id']
                    action = 'skipped'
                    self.sync_stats['reviews_skipped'] += 1
            else:
                # åˆ›å»ºæ–°è¯„å®¡
                review_id = self.da.create_review(review_data)
                action = 'created'
                self.sync_stats['reviews_synced'] += 1
            
            # åŒæ­¥è¯„å®¡çš„æ–‡ä»¶ç‰ˆæœ¬
            if 'fileVersions' in acc_review_data:
                self._sync_review_file_versions(review_id, acc_review_data['fileVersions'])
            
            # åŒæ­¥è¯„å®¡è¿›åº¦
            if 'steps' in acc_review_data:
                self._sync_review_progress(review_id, acc_review_data['steps'])
            
            return review_id, action
        
        except Exception as e:
            error_msg = f"åŒæ­¥è¯„å®¡å¤±è´¥ (ACC ID: {acc_review_data.get('id')}): {str(e)}"
            self.sync_stats['errors'].append(error_msg)
            print(f"âœ— {error_msg}")
            raise
    
    def _transform_acc_review_data(self, acc_data: Dict[str, Any]) -> Dict[str, Any]:
        """è½¬æ¢ACCè¯„å®¡æ•°æ®ä¸ºæœ¬åœ°æ ¼å¼"""
        return {
            'review_uuid': acc_data.get('id'),  # ä½¿ç”¨ ACC çš„ review ID ä½œä¸º UUID
            'project_id': acc_data.get('projectId'),
            'data_source': 'acc_sync',
            'acc_review_id': acc_data.get('id'),
            'acc_sequence_id': acc_data.get('sequenceId'),
            'name': acc_data.get('name', 'Unnamed Review'),
            'description': acc_data.get('description'),
            'notes': acc_data.get('notes'),  # APIçš„noteså­—æ®µ
            'status': self._map_review_status(acc_data.get('status', 'open')),
            'current_step_id': acc_data.get('currentStepId'),
            'current_step_due_date': self._parse_timestamp(acc_data.get('currentStepDueDate')),
            'current_step_name': acc_data.get('currentStepName'),
            'workflow_uuid': acc_data.get('workflowId'),
            'created_by': acc_data.get('createdBy', {}),
            'assigned_to': acc_data.get('assignedTo', []),
            'next_action_by': acc_data.get('nextActionBy', {}),
            'archived': acc_data.get('archived', False),
            'archived_by': acc_data.get('archivedBy', {}),
            'archived_at': self._parse_timestamp(acc_data.get('archivedAt')),
            'archived_reason': acc_data.get('archivedReason'),
            'created_at': self._parse_timestamp(acc_data.get('createdAt')),
            'updated_at': self._parse_timestamp(acc_data.get('updatedAt')),
            'started_at': self._parse_timestamp(acc_data.get('startedAt')),
            'finished_at': self._parse_timestamp(acc_data.get('finishedAt')),
            'last_synced_at': datetime.now(timezone.utc),
            'sync_status': 'synced'
        }
    
    def _map_review_status(self, acc_status: str) -> str:
        """æ˜ å°„ACCè¯„å®¡çŠ¶æ€åˆ°æœ¬åœ°çŠ¶æ€"""
        status_map = {
            'open': 'OPEN',
            'closed': 'CLOSED',
            'void': 'VOID',
            'failed': 'FAILED',
            'draft': 'DRAFT',
            'cancelled': 'CANCELLED'
        }
        return status_map.get(acc_status.lower(), 'OPEN')
    
    def _should_update_review(self, existing: Dict, new_data: Dict) -> bool:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦æ›´æ–°è¯„å®¡"""
        key_fields = ['name', 'status', 'current_step_id', 'current_step_name']
        for field in key_fields:
            if existing.get(field) != new_data.get(field):
                return True
        return False
    
    def _sync_review_file_versions(self, review_id: int, file_versions: List[Dict]) -> None:
        """åŒæ­¥è¯„å®¡çš„æ–‡ä»¶ç‰ˆæœ¬ï¼ˆæ‰¹é‡ä¼˜åŒ–ç‰ˆï¼‰"""
        if not file_versions:
            return
        
        db_start = time.time()
        batch_data = []
        
        for fv_data in file_versions:
            try:
                # å¤„ç†å®¡æ‰¹çŠ¶æ€å¯¹è±¡
                approve_status = fv_data.get('approveStatus', {})
                if isinstance(approve_status, dict):
                    approval_status_id = approve_status.get('id')
                    approval_status_value = approve_status.get('value', 'PENDING')
                    approval_label = approve_status.get('label')
                    approval_status = self._map_approval_status(approval_status_value)
                else:
                    # å…¼å®¹æ—§æ ¼å¼
                    approval_status = self._map_approval_status(fv_data.get('approvalStatus', 'pending'))
                    approval_status_id = None
                    approval_status_value = None
                    approval_label = fv_data.get('approvalLabel')
                
                file_data = {
                    'review_id': review_id,
                    'file_urn': fv_data.get('urn') or fv_data.get('fileUrn'),  # APIè¿”å›urnå­—æ®µ
                    'file_name': fv_data.get('name') or fv_data.get('fileName'),
                    'file_size': fv_data.get('fileSize'),
                    'file_extension': fv_data.get('fileExtension'),
                    'file_path': fv_data.get('filePath'),
                    'version_number': fv_data.get('versionNumber'),
                    'version_urn': fv_data.get('versionUrn'),
                    'item_urn': fv_data.get('itemUrn'),
                    'approval_status': approval_status,
                    'approval_status_id': approval_status_id,
                    'approval_status_value': approval_status_value,
                    'approval_label': approval_label,
                    'approval_comments': fv_data.get('approvalComments'),
                    'review_content': fv_data.get('reviewContent', {}),
                    'custom_attributes': fv_data.get('customAttributes', []),
                    'copied_file_version_urn': fv_data.get('copiedFileVersionUrn')
                }
                
                batch_data.append(file_data)
            
            except Exception as e:
                error_msg = f"å‡†å¤‡æ–‡ä»¶ç‰ˆæœ¬æ•°æ®å¤±è´¥: {str(e)}"
                self.sync_stats['errors'].append(error_msg)
                print(f"âœ— {error_msg}")
        
        # æ‰¹é‡æ’å…¥
        if batch_data:
            try:
                inserted_count = self.da.batch_insert_review_files(batch_data)
                db_time = time.time() - db_start
                self.sync_stats['performance']['db_time'] += db_time
                print(f"  âœ“ æ‰¹é‡æ’å…¥ {inserted_count} ä¸ªæ–‡ä»¶ç‰ˆæœ¬ (è€—æ—¶: {db_time:.2f}ç§’)")
            except Exception as e:
                error_msg = f"æ‰¹é‡æ’å…¥æ–‡ä»¶ç‰ˆæœ¬å¤±è´¥: {str(e)}"
                self.sync_stats['errors'].append(error_msg)
                print(f"âœ— {error_msg}")
    
    def _sync_review_progress(self, review_id: int, steps: List[Dict]) -> None:
        """åŒæ­¥è¯„å®¡è¿›åº¦ï¼ˆæ‰¹é‡ä¼˜åŒ–ç‰ˆï¼‰"""
        if not steps:
            return
        
        db_start = time.time()
        batch_data = []
        
        for idx, step_data in enumerate(steps):
            try:
                progress_data = {
                    'review_id': review_id,
                    'step_id': step_data.get('stepId') or step_data.get('id'),  # APIè¿”å›stepId
                    'step_name': step_data.get('stepName') or step_data.get('name'),
                    'step_type': self._map_step_type(step_data.get('type', 'reviewer')),
                    'step_order': idx + 1,
                    'status': self._map_step_status(step_data.get('status', 'pending')),
                    'assigned_to': step_data.get('assignedTo', []),
                    'claimed_by': step_data.get('claimedBy', {}),
                    'completed_by': step_data.get('completedBy', {}),
                    'action_by': step_data.get('actionBy', {}),  # æ–°å¢ï¼šæ‰§è¡Œæ“ä½œçš„ç”¨æˆ·
                    'candidates': step_data.get('candidates', {}),
                    'decision': step_data.get('decision'),
                    'comments': step_data.get('comments'),
                    'notes': step_data.get('notes'),  # æ–°å¢ï¼šæ­¥éª¤å¤‡æ³¨
                    'due_date': self._parse_timestamp(step_data.get('dueDate')),
                    'started_at': self._parse_timestamp(step_data.get('startedAt')),
                    'completed_at': self._parse_timestamp(step_data.get('completedAt')),
                    'end_time': self._parse_timestamp(step_data.get('endTime'))  # æ–°å¢ï¼šç»“æŸæ—¶é—´
                }
                
                batch_data.append(progress_data)
            
            except Exception as e:
                error_msg = f"å‡†å¤‡è¿›åº¦æ­¥éª¤æ•°æ®å¤±è´¥: {str(e)}"
                self.sync_stats['errors'].append(error_msg)
                print(f"âœ— {error_msg}")
        
        # æ‰¹é‡æ’å…¥
        if batch_data:
            try:
                inserted_count = self.da.batch_insert_review_steps(batch_data)
                db_time = time.time() - db_start
                self.sync_stats['performance']['db_time'] += db_time
                print(f"  âœ“ æ‰¹é‡æ’å…¥ {inserted_count} ä¸ªè¿›åº¦æ­¥éª¤ (è€—æ—¶: {db_time:.2f}ç§’)")
            except Exception as e:
                error_msg = f"æ‰¹é‡æ’å…¥è¿›åº¦æ­¥éª¤å¤±è´¥: {str(e)}"
                self.sync_stats['errors'].append(error_msg)
                print(f"âœ— {error_msg}")
    
    def _map_approval_status(self, acc_status: str) -> str:
        """æ˜ å°„å®¡æ‰¹çŠ¶æ€"""
        status_map = {
            'pending': 'PENDING',
            'approved': 'APPROVED',
            'rejected': 'REJECTED',
            'in_review': 'IN_REVIEW'
        }
        return status_map.get(acc_status.lower(), 'PENDING')
    
    def _map_step_type(self, acc_type: str) -> str:
        """æ˜ å°„æ­¥éª¤ç±»å‹"""
        type_map = {
            'reviewer': 'REVIEWER',
            'approver': 'APPROVER',
            'initiator': 'INITIATOR',
            'final': 'FINAL'
        }
        return type_map.get(acc_type.lower(), 'REVIEWER')
    
    def _map_step_status(self, acc_status: str) -> str:
        """æ˜ å°„æ­¥éª¤çŠ¶æ€"""
        status_map = {
            'pending': 'PENDING',
            'claimed': 'CLAIMED',
            'in_progress': 'OPEN',
            'submitted': 'SUBMITTED',
            'approved': 'APPROVED',
            'rejected': 'REJECTED',
            'skipped': 'SKIPPED'
        }
        return status_map.get(acc_status.lower(), 'PENDING')
    
    # ========================================================================
    # æ–‡ä»¶å®¡æ‰¹å†å²åŒæ­¥
    # ========================================================================
    
    def sync_file_approval_history(
        self,
        api_client,
        project_id: str,
        file_version_urn: str,
        review_data: Optional[Dict] = None
    ) -> int:
        """
        åŒæ­¥å•ä¸ªæ–‡ä»¶çš„å®¡æ‰¹å†å²
        
        Args:
            api_client: APIå®¢æˆ·ç«¯
            project_id: é¡¹ç›®ID
            file_version_urn: æ–‡ä»¶ç‰ˆæœ¬URN
            review_data: è¯„å®¡æ•°æ®ï¼ˆå¯é€‰ï¼Œç”¨äºè¡¥å……ä¿¡æ¯ï¼‰
            
        Returns:
            åŒæ­¥çš„è®°å½•æ•°
        """
        try:
            # URLç¼–ç æ–‡ä»¶URN
            import urllib.parse
            encoded_urn = urllib.parse.quote(file_version_urn, safe='')
            
            # è°ƒç”¨APIè·å–å®¡æ‰¹çŠ¶æ€
            url = f'/projects/{project_id}/versions/{encoded_urn}/approval-statuses'
            result = api_client.get(url)
            
            if not result or 'results' not in result:
                return 0
            
            approval_records = []
            for item in result.get('results', []):
                approval_status = item.get('approvalStatus', {})
                review = item.get('review', {})
                
                record = {
                    'file_version_urn': file_version_urn,
                    'file_item_urn': review_data.get('itemUrn') if review_data else None,
                    'file_name': review_data.get('name') if review_data else None,
                    'review_acc_id': review.get('id'),
                    'review_sequence_id': review.get('sequenceId'),
                    'review_status': review.get('status'),
                    'review_name': review_data.get('name') if review_data else None,
                    'approval_status_id': approval_status.get('id'),
                    'approval_status_label': approval_status.get('label'),
                    'approval_status_value': approval_status.get('value'),
                    'approval_status_type': approval_status.get('type'),
                    'is_current': review.get('status') == 'OPEN',
                    'is_latest_in_review': True  # å¯ä»¥åç»­ä¼˜åŒ–
                }
                
                approval_records.append(record)
            
            # æ‰¹é‡æ’å…¥
            if approval_records:
                inserted_count = self.da.batch_insert_file_approval_history(approval_records)
                return inserted_count
            
            return 0
            
        except Exception as e:
            error_msg = f"åŒæ­¥æ–‡ä»¶å®¡æ‰¹å†å²å¤±è´¥ (URN: {file_version_urn}): {str(e)}"
            self.sync_stats['errors'].append(error_msg)
            print(f"âš  {error_msg}")
            return 0
    
    def sync_all_file_approval_histories(
        self,
        api_client,
        project_id: str,
        file_versions: List[Dict],
        show_progress: bool = True
    ) -> int:
        """
        æ‰¹é‡åŒæ­¥æ–‡ä»¶å®¡æ‰¹å†å²
        
        Args:
            api_client: APIå®¢æˆ·ç«¯
            project_id: é¡¹ç›®ID
            file_versions: æ–‡ä»¶ç‰ˆæœ¬åˆ—è¡¨
            show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦
            
        Returns:
            æ€»åŒæ­¥è®°å½•æ•°
        """
        if not file_versions:
            return 0
        
        if show_progress:
            print(f"\nğŸ“‹ åŒæ­¥æ–‡ä»¶å®¡æ‰¹å†å²...")
            print(f"   æ–‡ä»¶æ•°é‡: {len(file_versions)}")
        
        total_synced = 0
        
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            futures = []
            
            for fv in file_versions:
                file_urn = fv.get('urn') or fv.get('fileUrn')
                if file_urn:
                    future = executor.submit(
                        self.sync_file_approval_history,
                        api_client,
                        project_id,
                        file_urn,
                        fv
                    )
                    futures.append(future)
            
            completed = 0
            for future in as_completed(futures):
                try:
                    count = future.result()
                    total_synced += count
                    completed += 1
                    
                    if show_progress and completed % 10 == 0:
                        print(f"   è¿›åº¦: {completed}/{len(futures)} æ–‡ä»¶")
                        
                except Exception as e:
                    error_msg = f"å¤„ç†æ–‡ä»¶å®¡æ‰¹å†å²å¤±è´¥: {str(e)}"
                    self.sync_stats['errors'].append(error_msg)
        
        if show_progress:
            print(f"   âœ“ å®Œæˆ: åŒæ­¥ {total_synced} æ¡å®¡æ‰¹å†å²è®°å½•")
        
        return total_synced
    
    # ========================================================================
    # å¹¶è¡ŒAPIè°ƒç”¨è¾…åŠ©æ–¹æ³•
    # ========================================================================
    
    @rate_limit_retry(max_retries=3, backoff_factor=2.0)
    def _fetch_review_versions(self, api_client, project_id: str, review_id: str) -> List[Dict]:
        """
        è·å–è¯„å®¡çš„æ–‡ä»¶ç‰ˆæœ¬ï¼ˆå¸¦é™æµé‡è¯•ï¼‰
        
        Args:
            api_client: APIå®¢æˆ·ç«¯
            project_id: é¡¹ç›®ID
            review_id: è¯„å®¡ID
            
        Returns:
            æ–‡ä»¶ç‰ˆæœ¬åˆ—è¡¨
        """
        try:
            self.sync_stats['performance']['api_calls'] += 1
            # å‡è®¾APIå®¢æˆ·ç«¯æœ‰get_review_versionsæ–¹æ³•
            result = api_client.get(f'/projects/{project_id}/reviews/{review_id}/versions')
            return result.get('results', []) if result else []
        except Exception as e:
            print(f"âš  è·å–æ–‡ä»¶ç‰ˆæœ¬å¤±è´¥ (review: {review_id}): {e}")
            return []
    
    @rate_limit_retry(max_retries=3, backoff_factor=2.0)
    def _fetch_review_progress(self, api_client, project_id: str, review_id: str) -> List[Dict]:
        """
        è·å–è¯„å®¡è¿›åº¦ï¼ˆå¸¦é™æµé‡è¯•ï¼‰
        
        Args:
            api_client: APIå®¢æˆ·ç«¯
            project_id: é¡¹ç›®ID
            review_id: è¯„å®¡ID
            
        Returns:
            è¿›åº¦æ­¥éª¤åˆ—è¡¨
        """
        try:
            self.sync_stats['performance']['api_calls'] += 1
            result = api_client.get(f'/projects/{project_id}/reviews/{review_id}/progress')
            return result.get('results', []) if result else []
        except Exception as e:
            print(f"âš  è·å–è¿›åº¦å¤±è´¥ (review: {review_id}): {e}")
            return []
    
    @rate_limit_retry(max_retries=3, backoff_factor=2.0)
    def _fetch_review_workflow(self, api_client, project_id: str, review_id: str) -> Dict:
        """
        è·å–è¯„å®¡å·¥ä½œæµï¼ˆå¸¦é™æµé‡è¯•ï¼‰
        
        Args:
            api_client: APIå®¢æˆ·ç«¯
            project_id: é¡¹ç›®ID
            review_id: è¯„å®¡ID
            
        Returns:
            å·¥ä½œæµæ•°æ®
        """
        try:
            self.sync_stats['performance']['api_calls'] += 1
            result = api_client.get(f'/projects/{project_id}/reviews/{review_id}/workflow')
            return result if result else {}
        except Exception as e:
            print(f"âš  è·å–å·¥ä½œæµå¤±è´¥ (review: {review_id}): {e}")
            return {}
    
    # ========================================================================
    # æ‰¹é‡åŒæ­¥
    # ========================================================================
    
    def sync_workflows_batch(
        self,
        acc_workflows: List[Dict[str, Any]],
        show_progress: bool = True
    ) -> Dict[str, Any]:
        """
        æ‰¹é‡åŒæ­¥å·¥ä½œæµ
        
        Args:
            acc_workflows: ACCå·¥ä½œæµæ•°æ®åˆ—è¡¨
            show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦
            
        Returns:
            åŒæ­¥ç»Ÿè®¡ä¿¡æ¯
        """
        total = len(acc_workflows)
        
        if show_progress:
            print(f"\nå¼€å§‹åŒæ­¥ {total} ä¸ªå·¥ä½œæµ...")
            print("=" * 60)
        
        for idx, workflow_data in enumerate(acc_workflows, 1):
            try:
                workflow_id, action = self.sync_workflow_from_acc(workflow_data)
                
                if show_progress:
                    status_icon = {
                        'created': 'âœ“ æ–°å»º',
                        'updated': 'â†» æ›´æ–°',
                        'skipped': 'âŠ˜ è·³è¿‡'
                    }
                    print(f"[{idx}/{total}] {status_icon[action]} å·¥ä½œæµ: {workflow_data.get('name')} (ID: {workflow_id})")
            
            except Exception as e:
                if show_progress:
                    print(f"[{idx}/{total}] âœ— å¤±è´¥: {workflow_data.get('name')}")
        
        if show_progress:
            print("\n" + "=" * 60)
            self._print_sync_summary()
        
        return self.sync_stats
    
    def sync_reviews_batch_parallel(
        self,
        acc_reviews: List[Dict[str, Any]],
        api_client,
        project_id: str,
        show_progress: bool = True
    ) -> Dict[str, Any]:
        """
        å¹¶è¡Œæ‰¹é‡åŒæ­¥è¯„å®¡ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
        
        ç­–ç•¥ï¼š
        1. å…ˆå¹¶è¡Œè·å–æ‰€æœ‰è¯„å®¡çš„è¯¦ç»†æ•°æ®ï¼ˆversions, progressï¼‰
        2. å†æ‰¹é‡æ’å…¥æ•°æ®åº“
        
        Args:
            acc_reviews: ACCè¯„å®¡æ•°æ®åˆ—è¡¨ï¼ˆåŸºç¡€ä¿¡æ¯ï¼‰
            api_client: APIå®¢æˆ·ç«¯å®ä¾‹
            project_id: é¡¹ç›®ID
            show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦
            
        Returns:
            åŒæ­¥ç»Ÿè®¡ä¿¡æ¯
        """
        total = len(acc_reviews)
        
        if show_progress:
            print(f"\nğŸš€ å¼€å§‹å¹¶è¡ŒåŒæ­¥ {total} ä¸ªè¯„å®¡...")
            print(f"   å¹¶å‘çº¿ç¨‹æ•°: {self.max_workers}")
            print("=" * 60)
        
        start_time = time.time()
        
        # ========== é˜¶æ®µ 1: å¹¶è¡Œè·å–è¯¦ç»†æ•°æ® ==========
        if show_progress:
            print(f"\nğŸ“¥ é˜¶æ®µ 1/2: å¹¶è¡Œè·å–APIæ•°æ®...")
        
        api_start = time.time()
        
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # ä¸ºæ¯ä¸ªè¯„å®¡æäº¤3ä¸ªå¹¶è¡Œä»»åŠ¡
            future_to_review = {}
            
            for review_data in acc_reviews:
                review_id = review_data.get('id')
                
                # æäº¤3ä¸ªå¹¶è¡ŒAPIè°ƒç”¨
                future_versions = executor.submit(
                    self._fetch_review_versions, 
                    api_client, 
                    project_id,
                    review_id
                )
                future_progress = executor.submit(
                    self._fetch_review_progress, 
                    api_client, 
                    project_id,
                    review_id
                )
                future_workflow = executor.submit(
                    self._fetch_review_workflow, 
                    api_client, 
                    project_id,
                    review_id
                )
                
                future_to_review[future_versions] = (review_data, 'versions')
                future_to_review[future_progress] = (review_data, 'progress')
                future_to_review[future_workflow] = (review_data, 'workflow')
            
            # æ”¶é›†ç»“æœ
            review_details = {}
            completed = 0
            total_tasks = len(future_to_review)
            
            for future in as_completed(future_to_review):
                review_data, data_type = future_to_review[future]
                review_id = review_data.get('id')
                
                try:
                    result = future.result()
                    
                    if review_id not in review_details:
                        review_details[review_id] = {
                            'review': review_data,
                            'versions': None,
                            'progress': None,
                            'workflow': None
                        }
                    
                    review_details[review_id][data_type] = result
                    completed += 1
                    
                    if show_progress and completed % 10 == 0:
                        progress_pct = (completed / total_tasks) * 100
                        elapsed = time.time() - api_start
                        print(f"   ğŸ“Š è¿›åº¦: {completed}/{total_tasks} ({progress_pct:.1f}%) | è€—æ—¶: {elapsed:.1f}ç§’")
                
                except Exception as e:
                    error_msg = f"è·å–è¯„å®¡è¯¦æƒ…å¤±è´¥ (ID: {review_id}, type: {data_type}): {str(e)}"
                    self.sync_stats['errors'].append(error_msg)
                    if show_progress:
                        print(f"   âœ— {error_msg}")
        
        api_time = time.time() - api_start
        self.sync_stats['performance']['api_time'] += api_time
        
        if show_progress:
            print(f"\nâœ“ APIæ•°æ®è·å–å®Œæˆ")
            print(f"   æ€»APIè°ƒç”¨: {self.sync_stats['performance']['api_calls']} æ¬¡")
            print(f"   è€—æ—¶: {api_time:.2f}ç§’")
            print(f"   å¹³å‡æ¯ä¸ªè¯„å®¡: {api_time/total:.2f}ç§’")
            print(f"   æé€Ÿæ¯”: {(total * 3 * 6) / api_time:.1f}x (ç›¸æ¯”ä¸²è¡Œ6ç§’/è¯·æ±‚)")
        
        # ========== é˜¶æ®µ 2: æ‰¹é‡å†™å…¥æ•°æ®åº“ ==========
        if show_progress:
            print(f"\nğŸ’¾ é˜¶æ®µ 2/2: æ‰¹é‡å†™å…¥æ•°æ®åº“...")
        
        db_start = time.time()
        
        for idx, (review_id, details) in enumerate(review_details.items(), 1):
            try:
                # åˆå¹¶æ•°æ®
                review_data = details['review']
                if details['versions']:
                    review_data['fileVersions'] = details['versions']
                if details['progress']:
                    review_data['steps'] = details['progress']
                
                # åŒæ­¥åˆ°æ•°æ®åº“
                local_review_id, action = self.sync_review_from_acc(review_data)
                
                if show_progress:
                    status_icon = {
                        'created': 'âœ“ æ–°å»º',
                        'updated': 'â†» æ›´æ–°',
                        'skipped': 'âŠ˜ è·³è¿‡'
                    }
                    print(f"[{idx}/{total}] {status_icon[action]} è¯„å®¡: {review_data.get('name')} (ID: {local_review_id})")
            
            except Exception as e:
                error_msg = f"åŒæ­¥è¯„å®¡å¤±è´¥: {review_data.get('name')} - {str(e)}"
                self.sync_stats['errors'].append(error_msg)
                if show_progress:
                    print(f"[{idx}/{total}] âœ— å¤±è´¥: {review_data.get('name')}")
        
        db_time = time.time() - db_start
        total_time = time.time() - start_time
        
        self.sync_stats['performance']['total_time'] = total_time
        
        if show_progress:
            print("\n" + "=" * 60)
            print(f"ğŸ“Š æ€§èƒ½ç»Ÿè®¡:")
            print(f"   APIè°ƒç”¨é˜¶æ®µ: {api_time:.2f}ç§’ ({api_time/total_time*100:.1f}%)")
            print(f"   æ•°æ®åº“å†™å…¥: {db_time:.2f}ç§’ ({db_time/total_time*100:.1f}%)")
            print(f"   æ€»è€—æ—¶: {total_time:.2f}ç§’")
            print(f"   å¹³å‡æ¯ä¸ªè¯„å®¡: {total_time/total:.2f}ç§’")
            print(f"   æ•´ä½“æé€Ÿæ¯”: {(total * 18) / total_time:.1f}x (ç›¸æ¯”ä¸²è¡Œ18ç§’/è¯„å®¡)")
            self._print_sync_summary()
        
        return self.sync_stats
    
    # ========================================================================
    # æ™ºèƒ½åˆ†é¡µè·å–
    # ========================================================================
    
    def fetch_all_reviews_with_pagination(
        self,
        api_client,
        project_id: str,
        limit_per_page: int = 50,
        show_progress: bool = True
    ) -> List[Dict]:
        """
        æ™ºèƒ½åˆ†é¡µè·å–æ‰€æœ‰è¯„å®¡
        
        åˆ©ç”¨APIçš„åˆ†é¡µåŠŸèƒ½å¹¶è¡Œè·å–å¤šé¡µæ•°æ®
        
        Args:
            api_client: APIå®¢æˆ·ç«¯
            project_id: é¡¹ç›®ID
            limit_per_page: æ¯é¡µæ•°é‡ï¼ˆæœ€å¤§50ï¼‰
            show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦
            
        Returns:
            æ‰€æœ‰è¯„å®¡åˆ—è¡¨
        """
        if show_progress:
            print(f"\nğŸ“„ æ™ºèƒ½åˆ†é¡µè·å–è¯„å®¡åˆ—è¡¨...")
        
        # ç¬¬ä¸€æ¬¡è°ƒç”¨è·å–æ€»æ•°
        first_page = api_client.get(
            f'/projects/{project_id}/reviews',
            params={'limit': limit_per_page, 'offset': 0}
        )
        
        total_results = first_page.get('pagination', {}).get('totalResults', 0)
        reviews = first_page.get('results', [])
        
        if show_progress:
            print(f"   æ€»è¯„å®¡æ•°: {total_results}")
            print(f"   ç¬¬ä¸€é¡µ: {len(reviews)} ä¸ª")
        
        # è®¡ç®—éœ€è¦çš„é¡µæ•°
        pages_needed = (total_results - limit_per_page + limit_per_page - 1) // limit_per_page
        
        if pages_needed > 0:
            if show_progress:
                print(f"   éœ€è¦é¢å¤–è·å– {pages_needed} é¡µ...")
            
            # å¹¶è¡Œè·å–å‰©ä½™é¡µé¢
            with ThreadPoolExecutor(max_workers=min(5, pages_needed)) as executor:
                futures = []
                for page in range(1, pages_needed + 1):
                    offset = page * limit_per_page
                    future = executor.submit(
                        self._fetch_reviews_page,
                        api_client,
                        project_id,
                        limit_per_page,
                        offset
                    )
                    futures.append(future)
                
                for idx, future in enumerate(as_completed(futures), 1):
                    try:
                        page_data = future.result()
                        reviews.extend(page_data)
                        if show_progress and idx % 5 == 0:
                            print(f"   å·²è·å– {idx}/{pages_needed} é¡µ")
                    except Exception as e:
                        error_msg = f"è·å–åˆ†é¡µæ•°æ®å¤±è´¥: {e}"
                        self.sync_stats['errors'].append(error_msg)
                        print(f"âš  {error_msg}")
        
        if show_progress:
            print(f"âœ“ å…±è·å– {len(reviews)} ä¸ªè¯„å®¡\n")
        
        return reviews
    
    @rate_limit_retry(max_retries=3, backoff_factor=2.0)
    def _fetch_reviews_page(
        self,
        api_client,
        project_id: str,
        limit: int,
        offset: int
    ) -> List[Dict]:
        """è·å–å•é¡µè¯„å®¡æ•°æ®ï¼ˆå¸¦é™æµé‡è¯•ï¼‰"""
        try:
            self.sync_stats['performance']['api_calls'] += 1
            result = api_client.get(
                f'/projects/{project_id}/reviews',
                params={'limit': limit, 'offset': offset}
            )
            return result.get('results', [])
        except Exception as e:
            print(f"âš  è·å–è¯„å®¡é¡µé¢å¤±è´¥ (offset: {offset}): {e}")
            return []
    
    # ========================================================================
    # è¾…åŠ©æ–¹æ³•
    # ========================================================================
    
    def _parse_timestamp(self, timestamp_str: Optional[str]) -> Optional[datetime]:
        """è§£ææ—¶é—´æˆ³å­—ç¬¦ä¸²"""
        if not timestamp_str:
            return None
        
        try:
            # å°è¯•ISOæ ¼å¼
            return datetime.fromisoformat(timestamp_str.replace('Z', '+00:00'))
        except:
            try:
                # å°è¯•å…¶ä»–æ ¼å¼
                return datetime.strptime(timestamp_str, '%Y-%m-%dT%H:%M:%S.%f')
            except:
                return None
    
    def _print_sync_summary(self) -> None:
        """æ‰“å°åŒæ­¥æ‘˜è¦ï¼ˆå¢å¼ºç‰ˆï¼‰"""
        print("\nğŸ“Š åŒæ­¥æ‘˜è¦:")
        print(f"  å·¥ä½œæµ:")
        print(f"    - æ–°å»º: {self.sync_stats['workflows_synced']}")
        print(f"    - æ›´æ–°: {self.sync_stats['workflows_updated']}")
        print(f"    - è·³è¿‡: {self.sync_stats['workflows_skipped']}")
        print(f"  è¯„å®¡:")
        print(f"    - æ–°å»º: {self.sync_stats['reviews_synced']}")
        print(f"    - æ›´æ–°: {self.sync_stats['reviews_updated']}")
        print(f"    - è·³è¿‡: {self.sync_stats['reviews_skipped']}")
        
        # æ€§èƒ½ç»Ÿè®¡
        perf = self.sync_stats['performance']
        if perf['total_time'] > 0:
            print(f"\nâš¡ æ€§èƒ½æŒ‡æ ‡:")
            print(f"  æ€»è€—æ—¶: {perf['total_time']:.2f}ç§’")
            print(f"  APIè°ƒç”¨: {perf['api_calls']} æ¬¡ ({perf['api_time']:.2f}ç§’)")
            print(f"  æ•°æ®åº“æ“ä½œ: {perf['db_time']:.2f}ç§’")
            
            total_items = (self.sync_stats['workflows_synced'] + 
                          self.sync_stats['workflows_updated'] +
                          self.sync_stats['reviews_synced'] + 
                          self.sync_stats['reviews_updated'])
            
            if total_items > 0:
                print(f"  å¹³å‡å¤„ç†é€Ÿåº¦: {perf['total_time']/total_items:.2f}ç§’/é¡¹")
        
        if self.sync_stats['errors']:
            print(f"\nâš  é”™è¯¯æ•°é‡: {len(self.sync_stats['errors'])}")
            for error in self.sync_stats['errors'][:5]:  # åªæ˜¾ç¤ºå‰5ä¸ªé”™è¯¯
                print(f"  - {error}")
            if len(self.sync_stats['errors']) > 5:
                print(f"  ... è¿˜æœ‰ {len(self.sync_stats['errors']) - 5} ä¸ªé”™è¯¯")
    
    def reset_stats(self) -> None:
        """é‡ç½®ç»Ÿè®¡ä¿¡æ¯"""
        self.sync_stats = {
            'workflows_synced': 0,
            'workflows_updated': 0,
            'workflows_skipped': 0,
            'reviews_synced': 0,
            'reviews_updated': 0,
            'reviews_skipped': 0,
            'errors': [],
            'performance': {
                'api_calls': 0,
                'api_time': 0.0,
                'db_time': 0.0,
                'total_time': 0.0
            }
        }
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return self.sync_stats.copy()


# ============================================================================
# ä¾¿æ·å‡½æ•°
# ============================================================================

def get_review_sync_manager(data_access: Optional[ReviewDataAccess] = None) -> ReviewSyncManager:
    """è·å–ReviewSyncManagerå®ä¾‹"""
    return ReviewSyncManager(data_access)


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    print("å®¡æ‰¹ç³»ç»ŸåŒæ­¥ç®¡ç†å™¨æµ‹è¯•")
    print("=" * 60)
    
    try:
        sync_manager = get_review_sync_manager()
        print("âœ“ åŒæ­¥ç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
        
        # æ˜¾ç¤ºå½“å‰ç»Ÿè®¡
        stats = sync_manager.get_stats()
        print(f"\nå½“å‰ç»Ÿè®¡: {json.dumps(stats, indent=2, ensure_ascii=False)}")
        
    except Exception as e:
        print(f"âœ— é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

