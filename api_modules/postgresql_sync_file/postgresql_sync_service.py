# -*- coding: utf-8 -*-
"""
PostgreSQLåŒæ­¥æœå‹™ - æ¥­å‹™é‚è¼¯å±¤
æä¾›çµ±ä¸€çš„åŒæ­¥æ¥å£ï¼Œæ”¯æŒå…¨é‡å’Œå¢é‡åŒæ­¥
é‡æ§‹å¾Œä½¿ç”¨å…±åŒå·¥å…·æ¨¡çµ„ï¼Œæé«˜å¯ç¶­è­·æ€§
"""

import asyncio
import logging
from datetime import datetime
from typing import Dict, List, Any, Optional

from .postgresql_sync_manager import OptimizedPostgreSQLSyncManager
from database_sql.optimized_data_access import get_optimized_postgresql_dal
from .postgresql_sync_utils import (
    SyncManagerFactory, TaskManager, AuthUtils, 
    RollupCheckUtils, PerformanceUtils, SyncExecutionUtils
)

logger = logging.getLogger(__name__)

class PostgreSQLSyncService:
    """PostgreSQLåŒæ­¥æœå‹™ - é‡æ§‹å¾Œçš„æ¥­å‹™é‚è¼¯å±¤"""
    
    def __init__(self, performance_mode: str = 'standard'):
        self.sync_manager = SyncManagerFactory.create_sync_manager(performance_mode)
        self.current_performance_mode = performance_mode
    
    async def start_full_sync(self, project_id: str, max_depth: int = 10, 
                            include_custom_attributes: bool = True, 
                            performance_mode: str = None) -> Dict[str, Any]:
        """
        å•Ÿå‹•å…¨é‡åŒæ­¥ - é‡æ§‹ç‰ˆæœ¬
        
        Args:
            project_id: é …ç›®ID
            max_depth: æœ€å¤§æ·±åº¦
            include_custom_attributes: æ˜¯å¦åŒ…å«è‡ªå®šç¾©å±¬æ€§
            performance_mode: æ€§èƒ½æ¨¡å¼ï¼Œå¦‚æœç‚ºNoneå‰‡ä½¿ç”¨ç•¶å‰æ¨¡å¼
        
        Returns:
            åŒæ­¥çµæœ
        """
        
        # ä½¿ç”¨æŒ‡å®šçš„æ€§èƒ½æ¨¡å¼æˆ–ç•¶å‰æ¨¡å¼
        if performance_mode is None:
            performance_mode = self.current_performance_mode
        
        logger.info(f"ğŸš€ å•Ÿå‹•å…¨é‡åŒæ­¥: é …ç›® {project_id}, æ€§èƒ½æ¨¡å¼: {performance_mode}")
        
        try:
            # é©—è­‰åƒæ•¸
            validation = AuthUtils.validate_sync_parameters(
                'full_sync', performance_mode, max_depth, include_custom_attributes
            )
            if not validation['valid']:
                return {
                    'status': 'error',
                    'error': f"åƒæ•¸é©—è­‰å¤±æ•—: {', '.join(validation['errors'])}"
                }
            
            # ç”Ÿæˆä»»å‹™UUID
            task_uuid = TaskManager.generate_task_uuid()
            
            # ç²å–èªè­‰é ­
            headers = AuthUtils.get_auth_headers_safe()
            if not headers:
                return {
                    'status': 'error',
                    'error': 'ç„¡æ³•ç²å–èªè­‰ä¿¡æ¯',
                    'task_uuid': task_uuid
                }
            
            # èª¿æ•´åŒæ­¥ç®¡ç†å™¨åƒæ•¸
            if performance_mode != self.current_performance_mode:
                SyncManagerFactory.adjust_sync_manager(self.sync_manager, performance_mode)
                self.current_performance_mode = performance_mode
            
            # å‰µå»ºåŒæ­¥ä»»å‹™è¨˜éŒ„
            parameters = {
                    'max_depth': max_depth,
                    'include_custom_attributes': include_custom_attributes
            }
            
            task_created = await TaskManager.create_sync_task_record(
                project_id, task_uuid, 'full_sync', performance_mode, parameters
            )
            
            if not task_created:
                logger.warning(f"ä»»å‹™è¨˜éŒ„å‰µå»ºå¤±æ•—ï¼Œä½†ç¹¼çºŒåŸ·è¡ŒåŒæ­¥: {task_uuid}")
            
            # åŸ·è¡Œå…¨é‡åŒæ­¥
            result = await SyncExecutionUtils.execute_sync(
                self.sync_manager, 'full_sync', project_id, 
                max_depth, include_custom_attributes, task_uuid
            )
            
            # æ·»åŠ é¡å¤–ä¿¡æ¯
            result['task_uuid'] = task_uuid
            result['performance_mode'] = performance_mode
            result['sync_type'] = 'full_sync'
            
            # å®ŒæˆåŒæ­¥ä»»å‹™è¨˜éŒ„
            if result.get('status') == 'success':
                await TaskManager.complete_sync_task_record(
                    task_uuid, result, self.sync_manager._get_performance_stats()
                )
            elif result.get('status') == 'error':
                await TaskManager.fail_sync_task_record(
                    task_uuid, result.get('error', 'Unknown error'), 
                    {'sync_type': 'full_sync', 'project_id': project_id}
                )
            
            logger.info(f"âœ… å…¨é‡åŒæ­¥å®Œæˆ: {result.get('status', 'unknown')}")
            return result
            
        except Exception as e:
            logger.error(f"âŒ å…¨é‡åŒæ­¥å¤±æ•—: {e}")
            return {
                'status': 'error',
                'error': str(e),
                'task_uuid': task_uuid if 'task_uuid' in locals() else None
            }
    
    async def start_incremental_sync(self, project_id: str, max_depth: int = 10, 
                                   include_custom_attributes: bool = True, 
                                   performance_mode: str = None,
                                   enable_top_level_rollup_check: bool = True) -> Dict[str, Any]:
        """
        å•Ÿå‹•å¢é‡åŒæ­¥ - é‡æ§‹ç‰ˆæœ¬ï¼ŒåŒ…å«é ‚å±¤rollupæª¢æŸ¥å„ªåŒ–
        
        Args:
            project_id: é …ç›®ID
            max_depth: æœ€å¤§æ·±åº¦
            include_custom_attributes: æ˜¯å¦åŒ…å«è‡ªå®šç¾©å±¬æ€§
            performance_mode: æ€§èƒ½æ¨¡å¼ï¼Œå¦‚æœç‚ºNoneå‰‡ä½¿ç”¨ç•¶å‰æ¨¡å¼
            enable_top_level_rollup_check: æ˜¯å¦å•Ÿç”¨é ‚å±¤rollupæª¢æŸ¥
        
        Returns:
            åŒæ­¥çµæœ
        """
        
        # ä½¿ç”¨æŒ‡å®šçš„æ€§èƒ½æ¨¡å¼æˆ–ç•¶å‰æ¨¡å¼
        if performance_mode is None:
            performance_mode = self.current_performance_mode
        
        logger.info(f"ğŸ”„ å•Ÿå‹•å¢é‡åŒæ­¥: é …ç›® {project_id}, æ€§èƒ½æ¨¡å¼: {performance_mode}")
        
        try:
            # é©—è­‰åƒæ•¸
            validation = AuthUtils.validate_sync_parameters(
                'incremental_sync', performance_mode, max_depth, include_custom_attributes
            )
            if not validation['valid']:
                return {
                    'status': 'error',
                    'error': f"åƒæ•¸é©—è­‰å¤±æ•—: {', '.join(validation['errors'])}"
                }
            
            # ç”Ÿæˆä»»å‹™UUID
            task_uuid = TaskManager.generate_task_uuid()
            
            # ğŸ”‘ é—œéµå„ªåŒ–ï¼šé ‚å±¤rollupæ™‚é–“æª¢æŸ¥
            if enable_top_level_rollup_check:
                rollup_check_result = await RollupCheckUtils.check_project_top_level_rollup(
                    project_id, self.sync_manager
                )
                
                if rollup_check_result.get('can_skip_entire_project'):
                    logger.info(f"ğŸš€ é ‚å±¤rollupå„ªåŒ–: æ•´å€‹é …ç›® {project_id} å¯ä»¥è·³é")
                    return {
                        'status': 'no_changes',
                        'message': 'Entire project skipped due to top-level rollup optimization',
                        'task_uuid': task_uuid,
                        'performance_mode': performance_mode,
                        'folders_synced': 0,
                        'files_synced': 0,
                        'custom_attrs_synced': 0,
                        'optimization_efficiency': 100.0,
                        'top_level_rollup_optimization': True,
                        'rollup_check_details': rollup_check_result
                    }
            
            # ç²å–èªè­‰é ­
            headers = AuthUtils.get_auth_headers_safe()
            if not headers:
                return {
                    'status': 'error',
                    'error': 'ç„¡æ³•ç²å–èªè­‰ä¿¡æ¯',
                    'task_uuid': task_uuid
                }
            
            # èª¿æ•´åŒæ­¥ç®¡ç†å™¨åƒæ•¸
            if performance_mode != self.current_performance_mode:
                SyncManagerFactory.adjust_sync_manager(self.sync_manager, performance_mode)
                self.current_performance_mode = performance_mode
            
            # å‰µå»ºåŒæ­¥ä»»å‹™è¨˜éŒ„
            parameters = {
                    'max_depth': max_depth,
                'include_custom_attributes': include_custom_attributes,
                'enable_top_level_rollup_check': enable_top_level_rollup_check
            }
            
            task_created = await TaskManager.create_sync_task_record(
                project_id, task_uuid, 'incremental_sync', performance_mode, parameters
            )
            
            if not task_created:
                logger.warning(f"ä»»å‹™è¨˜éŒ„å‰µå»ºå¤±æ•—ï¼Œä½†ç¹¼çºŒåŸ·è¡ŒåŒæ­¥: {task_uuid}")
            
            # åŸ·è¡Œå¢é‡åŒæ­¥
            result = await SyncExecutionUtils.execute_sync(
                self.sync_manager, 'incremental_sync', project_id, 
                max_depth, include_custom_attributes, task_uuid
            )
            
            # æ·»åŠ é¡å¤–ä¿¡æ¯
            result['task_uuid'] = task_uuid
            result['performance_mode'] = performance_mode
            result['sync_type'] = 'incremental_sync'
            result['top_level_rollup_check'] = enable_top_level_rollup_check
            
            # å®ŒæˆåŒæ­¥ä»»å‹™è¨˜éŒ„
            if result.get('status') == 'success':
                await TaskManager.complete_sync_task_record(
                    task_uuid, result, self.sync_manager._get_performance_stats()
                )
            elif result.get('status') == 'error':
                await TaskManager.fail_sync_task_record(
                    task_uuid, result.get('error', 'Unknown error'), 
                    {'sync_type': 'incremental_sync', 'project_id': project_id}
                )
            
            logger.info(f"âœ… å¢é‡åŒæ­¥å®Œæˆ: {result.get('status', 'unknown')}")
            return result
            
        except Exception as e:
            logger.error(f"âŒ å¢é‡åŒæ­¥å¤±æ•—: {e}")
            return {
                'status': 'error',
                'error': str(e),
                'task_uuid': task_uuid if 'task_uuid' in locals() else None
            }
    
    async def get_sync_status(self, task_uuid: str) -> Dict[str, Any]:
        """
        è·å–åŒæ­¥ä»»åŠ¡çŠ¶æ€
        
        Args:
            task_uuid: ä»»åŠ¡UUID
        
        Returns:
            ä»»åŠ¡çŠ¶æ€ä¿¡æ¯
        """
        
        try:
            dal = await get_optimized_postgresql_dal()
            
            async with dal.get_connection() as conn:
                query = """
                SELECT 
                    task_uuid,
                    project_id,
                    task_type,
                    task_status,
                    performance_mode,
                    parameters,
                    progress,
                    performance_stats,
                    results,
                    start_time,
                    end_time,
                    duration_seconds,
                    created_at,
                    updated_at
                FROM sync_tasks 
                WHERE task_uuid = $1;
                """
                
                row = await conn.fetchrow(query, task_uuid)
                
                if not row:
                    return {
                        'status': 'error',
                        'error': f'ä»»åŠ¡ {task_uuid} ä¸å­˜åœ¨'
                    }
                
                return dal._row_to_dict(row)
                
        except Exception as e:
            logger.error(f"è·å–åŒæ­¥çŠ¶æ€å¤±è´¥: {e}")
            return {
                'status': 'error',
                'error': str(e)
            }
    
    async def get_project_sync_history(self, project_id: str, limit: int = 10) -> List[Dict[str, Any]]:
        """
        è·å–é¡¹ç›®åŒæ­¥å†å²
        
        Args:
            project_id: é¡¹ç›®ID
            limit: è¿”å›è®°å½•æ•°é™åˆ¶
        
        Returns:
            åŒæ­¥å†å²è®°å½•åˆ—è¡¨
        """
        
        try:
            dal = await get_optimized_postgresql_dal()
            
            async with dal.get_connection() as conn:
                query = """
                SELECT 
                    task_uuid,
                    task_type,
                    task_status,
                    performance_mode,
                    start_time,
                    end_time,
                    duration_seconds,
                    results
                FROM sync_tasks 
                WHERE project_id = $1
                ORDER BY start_time DESC
                LIMIT $2;
                """
                
                rows = await conn.fetch(query, project_id, limit)
                return [dal._row_to_dict(row) for row in rows]
                
        except Exception as e:
            logger.error(f"è·å–åŒæ­¥å†å²å¤±è´¥: {e}")
            return []
    
    async def get_sync_performance_stats(self, project_id: str, 
                                       start_date: Optional[datetime] = None,
                                       end_date: Optional[datetime] = None) -> Dict[str, Any]:
        """
        è·å–åŒæ­¥æ€§èƒ½ç»Ÿè®¡
        
        Args:
            project_id: é¡¹ç›®ID
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
        
        Returns:
            æ€§èƒ½ç»Ÿè®¡ä¿¡æ¯
        """
        
        try:
            dal = await get_optimized_postgresql_dal()
            
            async with dal.get_connection() as conn:
                # æ„å»ºæŸ¥è¯¢æ¡ä»¶
                conditions = ["project_id = $1", "task_status = 'completed'"]
                params = [project_id]
                
                if start_date:
                    conditions.append("start_time >= $2")
                    params.append(start_date)
                
                if end_date:
                    conditions.append("start_time <= $3")
                    params.append(end_date)
                
                query = f"""
                SELECT 
                    COUNT(*) as total_syncs,
                    AVG(duration_seconds) as avg_duration,
                    MIN(duration_seconds) as min_duration,
                    MAX(duration_seconds) as max_duration,
                    SUM(CAST(results->>'folders_synced' AS INTEGER)) as total_folders_synced,
                    SUM(CAST(results->>'files_synced' AS INTEGER)) as total_files_synced,
                    SUM(CAST(results->>'custom_attrs_synced' AS INTEGER)) as total_custom_attrs_synced,
                    AVG(CAST(performance_stats->>'optimization_efficiency' AS FLOAT)) as avg_optimization_efficiency
                FROM sync_tasks 
                WHERE {' AND '.join(conditions)};
                """
                
                row = await conn.fetchrow(query, *params)
                
                if row:
                    stats = dal._row_to_dict(row)
                    
                    # è®¡ç®—é¢å¤–ç»Ÿè®¡ä¿¡æ¯
                    stats['performance_grade'] = self._calculate_performance_grade(stats)
                    stats['efficiency_trend'] = await self._get_efficiency_trend(dal, project_id, start_date, end_date)
                    
                    return stats
                else:
                    return {'message': 'æ²¡æœ‰æ‰¾åˆ°åŒæ­¥è®°å½•'}
                
        except Exception as e:
            logger.error(f"è·å–æ€§èƒ½ç»Ÿè®¡å¤±è´¥: {e}")
            return {'error': str(e)}
    
    def _adjust_sync_manager_for_performance_mode(self, performance_mode: str):
        """æ ¹æ®æ€§èƒ½æ¨¡å¼è°ƒæ•´åŒæ­¥ç®¡ç†å™¨å‚æ•°"""
        
        if performance_mode == 'high_performance':
            # é«˜æ€§èƒ½æ¨¡å¼ï¼šæ›´å¤§çš„æ‰¹é‡å¤§å°ï¼Œæ›´å¤šçš„å¹¶å‘
            self.sync_manager.batch_size = 200
            self.sync_manager.max_workers = 16
            self.sync_manager.api_delay = 0.01
            self.sync_manager.memory_threshold_mb = 2048
            
        elif performance_mode == 'memory_optimized':
            # å†…å­˜ä¼˜åŒ–æ¨¡å¼ï¼šè¾ƒå°çš„æ‰¹é‡å¤§å°ï¼Œè¾ƒå°‘çš„å¹¶å‘
            self.sync_manager.batch_size = 50
            self.sync_manager.max_workers = 4
            self.sync_manager.api_delay = 0.05
            self.sync_manager.memory_threshold_mb = 512
            
        else:  # standard
            # æ ‡å‡†æ¨¡å¼ï¼šå¹³è¡¡çš„å‚æ•°
            self.sync_manager.batch_size = 100
            self.sync_manager.max_workers = 8
            self.sync_manager.api_delay = 0.02
            self.sync_manager.memory_threshold_mb = 1024
        
        logger.info(f"åŒæ­¥ç®¡ç†å™¨å·²è°ƒæ•´ä¸º {performance_mode} æ¨¡å¼")
    
    def _calculate_performance_grade(self, stats: Dict[str, Any]) -> str:
        """è®¡ç®—æ€§èƒ½ç­‰çº§"""
        
        avg_duration = stats.get('avg_duration', 0)
        avg_efficiency = stats.get('avg_optimization_efficiency', 0)
        
        if avg_duration < 30 and avg_efficiency > 80:
            return 'A+'
        elif avg_duration < 60 and avg_efficiency > 70:
            return 'A'
        elif avg_duration < 120 and avg_efficiency > 60:
            return 'B'
        elif avg_duration < 300 and avg_efficiency > 50:
            return 'C'
        else:
            return 'D'
    
    async def _get_efficiency_trend(self, dal, project_id: str, 
                                  start_date: Optional[datetime], 
                                  end_date: Optional[datetime]) -> str:
        """è·å–æ•ˆç‡è¶‹åŠ¿"""
        
        try:
            async with dal.get_connection() as conn:
                # è·å–æœ€è¿‘çš„åŒæ­¥è®°å½•ï¼ŒæŒ‰æ—¶é—´æ’åº
                conditions = ["project_id = $1", "task_status = 'completed'"]
                params = [project_id]
                
                if start_date:
                    conditions.append("start_time >= $2")
                    params.append(start_date)
                
                if end_date:
                    conditions.append("start_time <= $3")
                    params.append(end_date)
                
                query = f"""
                SELECT 
                    CAST(performance_stats->>'optimization_efficiency' AS FLOAT) as efficiency
                FROM sync_tasks 
                WHERE {' AND '.join(conditions)}
                ORDER BY start_time DESC
                LIMIT 10;
                """
                
                rows = await conn.fetch(query, *params)
                
                if len(rows) < 2:
                    return 'insufficient_data'
                
                efficiencies = [row['efficiency'] for row in rows if row['efficiency'] is not None]
                
                if len(efficiencies) < 2:
                    return 'insufficient_data'
                
                # è®¡ç®—è¶‹åŠ¿
                recent_avg = sum(efficiencies[:3]) / min(3, len(efficiencies))
                older_avg = sum(efficiencies[-3:]) / min(3, len(efficiencies[-3:]))
                
                if recent_avg > older_avg + 5:
                    return 'improving'
                elif recent_avg < older_avg - 5:
                    return 'declining'
                else:
                    return 'stable'
                    
        except Exception as e:
            logger.warning(f"è·å–æ•ˆç‡è¶‹åŠ¿å¤±è´¥: {e}")
            return 'unknown'

# ============================================================================
# ğŸš€ å…¨å±€æœå‹™å¯¦ä¾‹å’Œä¾¿æ·å‡½æ•¸
# ============================================================================

# å…¨å±€PostgreSQLåŒæ­¥æœå‹™å¯¦ä¾‹
postgresql_sync_service = PostgreSQLSyncService()

# ä¾¿æ·å‡½æ•¸ - é‡æ§‹ç‰ˆæœ¬
async def start_full_sync(project_id: str, **kwargs) -> Dict[str, Any]:
    """å•Ÿå‹•å…¨é‡åŒæ­¥çš„ä¾¿æ·å‡½æ•¸"""
    return await postgresql_sync_service.start_full_sync(project_id, **kwargs)

async def start_incremental_sync(project_id: str, **kwargs) -> Dict[str, Any]:
    """å•Ÿå‹•å¢é‡åŒæ­¥çš„ä¾¿æ·å‡½æ•¸"""
    return await postgresql_sync_service.start_incremental_sync(project_id, **kwargs)

async def get_sync_status(task_uuid: str) -> Dict[str, Any]:
    """ç²å–åŒæ­¥ç‹€æ…‹çš„ä¾¿æ·å‡½æ•¸"""
    return await postgresql_sync_service.get_sync_status(task_uuid)

async def get_project_sync_history(project_id: str, limit: int = 10) -> List[Dict[str, Any]]:
    """ç²å–é …ç›®åŒæ­¥æ­·å²çš„ä¾¿æ·å‡½æ•¸"""
    return await postgresql_sync_service.get_project_sync_history(project_id, limit)

async def get_sync_performance_stats(project_id: str, **kwargs) -> Dict[str, Any]:
    """ç²å–åŒæ­¥æ€§èƒ½çµ±è¨ˆçš„ä¾¿æ·å‡½æ•¸"""
    return await postgresql_sync_service.get_sync_performance_stats(project_id, **kwargs)

# å·¥å» å‡½æ•¸
def create_sync_service(performance_mode: str = 'standard') -> PostgreSQLSyncService:
    """å‰µå»ºæ–°çš„åŒæ­¥æœå‹™å¯¦ä¾‹"""
    return PostgreSQLSyncService(performance_mode)

def get_available_performance_modes() -> List[str]:
    """ç²å–å¯ç”¨çš„æ€§èƒ½æ¨¡å¼"""
    return SyncManagerFactory.get_available_modes()