# -*- coding: utf-8 -*-
"""
æ•°æ®åº“åˆå§‹åŒ–å’Œç´¢å¼•ç®¡ç†æ¨¡å—
ç”¨äºåˆ›å»ºä¼˜åŒ–çš„MongoDBé›†åˆå’Œç´¢å¼•
"""

import logging
from pymongo import MongoClient, ASCENDING, DESCENDING, TEXT
from pymongo.errors import CollectionInvalid, OperationFailure
from datetime import datetime
from .mongodb_config import MongoDBConfig
from .optimized_schema_design import OPTIMIZED_INDEXES, VALIDATION_RULES

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class DatabaseInitializer:
    """æ•°æ®åº“åˆå§‹åŒ–å™¨"""
    
    def __init__(self, db_config: MongoDBConfig = None):
        self.db_config = db_config or MongoDBConfig()
        self.database = None
        
    def connect(self):
        """è¿æ¥æ•°æ®åº“"""
        if not self.db_config.connect():
            raise Exception("æ— æ³•è¿æ¥åˆ°MongoDBæ•°æ®åº“")
        self.database = self.db_config.get_database()
        return True
    
    def initialize_database(self, drop_existing=False):
        """
        åˆå§‹åŒ–æ•°æ®åº“
        
        Args:
            drop_existing: æ˜¯å¦åˆ é™¤ç°æœ‰é›†åˆé‡æ–°åˆ›å»º
        """
        try:
            if not self.database:
                self.connect()
            
            logger.info("å¼€å§‹åˆå§‹åŒ–æ•°æ®åº“...")
            
            # åˆ›å»ºé›†åˆ
            self._create_collections(drop_existing)
            
            # åˆ›å»ºç´¢å¼•
            self._create_indexes()
            
            # è®¾ç½®éªŒè¯è§„åˆ™
            self._setup_validation_rules()
            
            # åˆ›å»ºåˆå§‹æ•°æ®
            self._create_initial_data()
            
            logger.info("æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ!")
            return True
            
        except Exception as e:
            logger.error(f"æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            return False
    
    def _create_collections(self, drop_existing=False):
        """åˆ›å»ºé›†åˆ"""
        collections = [
            "projects",
            "folders", 
            "files",
            "file_versions",
            "sync_tasks"
        ]
        
        for collection_name in collections:
            try:
                if drop_existing and collection_name in self.database.list_collection_names():
                    logger.info(f"åˆ é™¤ç°æœ‰é›†åˆ: {collection_name}")
                    self.database.drop_collection(collection_name)
                
                if collection_name not in self.database.list_collection_names():
                    logger.info(f"åˆ›å»ºé›†åˆ: {collection_name}")
                    self.database.create_collection(collection_name)
                else:
                    logger.info(f"é›†åˆå·²å­˜åœ¨: {collection_name}")
                    
            except CollectionInvalid as e:
                logger.warning(f"é›†åˆ {collection_name} åˆ›å»ºè­¦å‘Š: {str(e)}")
            except Exception as e:
                logger.error(f"åˆ›å»ºé›†åˆ {collection_name} å¤±è´¥: {str(e)}")
                raise
    
    def _create_indexes(self):
        """åˆ›å»ºç´¢å¼•"""
        logger.info("å¼€å§‹åˆ›å»ºç´¢å¼•...")
        
        for collection_name, indexes in OPTIMIZED_INDEXES.items():
            if collection_name not in self.database.list_collection_names():
                logger.warning(f"é›†åˆ {collection_name} ä¸å­˜åœ¨ï¼Œè·³è¿‡ç´¢å¼•åˆ›å»º")
                continue
                
            collection = self.database[collection_name]
            
            # è·å–ç°æœ‰ç´¢å¼•
            existing_indexes = list(collection.list_indexes())
            existing_index_names = {idx['name'] for idx in existing_indexes}
            
            logger.info(f"ä¸ºé›†åˆ {collection_name} åˆ›å»ºç´¢å¼•...")
            
            for index_spec in indexes:
                try:
                    # å¤„ç†ä¸åŒç±»å‹çš„ç´¢å¼•
                    if isinstance(index_spec, dict):
                        # æ£€æŸ¥æ˜¯å¦æ˜¯æ–‡æœ¬ç´¢å¼•
                        if any(v == "text" for v in index_spec.values()):
                            index_name = f"{collection_name}_text_index"
                            if index_name not in existing_index_names:
                                result = collection.create_index(
                                    [(k, TEXT) for k, v in index_spec.items() if v == "text"],
                                    name=index_name
                                )
                                logger.info(f"  åˆ›å»ºæ–‡æœ¬ç´¢å¼•: {index_name} -> {result}")
                        else:
                            # æ™®é€šç´¢å¼•
                            index_fields = []
                            for field, direction in index_spec.items():
                                if direction == 1:
                                    index_fields.append((field, ASCENDING))
                                elif direction == -1:
                                    index_fields.append((field, DESCENDING))
                            
                            if index_fields:
                                index_name = f"{collection_name}_{'_'.join([f[0].replace('.', '_') for f in index_fields])}"
                                if index_name not in existing_index_names:
                                    result = collection.create_index(
                                        index_fields,
                                        name=index_name
                                    )
                                    logger.info(f"  åˆ›å»ºç´¢å¼•: {index_name} -> {result}")
                                else:
                                    logger.info(f"  ç´¢å¼•å·²å­˜åœ¨: {index_name}")
                    
                except OperationFailure as e:
                    logger.warning(f"  åˆ›å»ºç´¢å¼•å¤±è´¥: {str(e)}")
                except Exception as e:
                    logger.error(f"  åˆ›å»ºç´¢å¼•æ—¶å‡ºé”™: {str(e)}")
        
        logger.info("ç´¢å¼•åˆ›å»ºå®Œæˆ")
    
    def _setup_validation_rules(self):
        """è®¾ç½®éªŒè¯è§„åˆ™"""
        logger.info("è®¾ç½®é›†åˆéªŒè¯è§„åˆ™...")
        
        for collection_name, rules in VALIDATION_RULES.items():
            if collection_name not in self.database.list_collection_names():
                continue
                
            try:
                # MongoDBçš„éªŒè¯è§„åˆ™è®¾ç½®
                validator = {
                    "$jsonSchema": {
                        "bsonType": "object",
                        "required": rules.get("required_fields", []),
                        "properties": {}
                    }
                }
                
                # æ·»åŠ å­—æ®µç±»å‹éªŒè¯
                field_types = rules.get("field_types", {})
                for field_path, field_type in field_types.items():
                    # ç®€åŒ–çš„ç±»å‹æ˜ å°„
                    bson_type = "string"
                    if field_type == int:
                        bson_type = "int"
                    elif field_type == float:
                        bson_type = "double"
                    elif field_type == bool:
                        bson_type = "bool"
                    
                    # å¤„ç†åµŒå¥—å­—æ®µè·¯å¾„
                    if "." in field_path:
                        # æš‚æ—¶è·³è¿‡åµŒå¥—å­—æ®µéªŒè¯ï¼ŒMongoDBçš„jsonSchemaæ¯”è¾ƒå¤æ‚
                        continue
                    else:
                        validator["$jsonSchema"]["properties"][field_path] = {
                            "bsonType": bson_type
                        }
                
                # åº”ç”¨éªŒè¯è§„åˆ™
                self.database.command({
                    "collMod": collection_name,
                    "validator": validator,
                    "validationLevel": "moderate",  # åªå¯¹æ–°æ–‡æ¡£å’Œæ›´æ–°éªŒè¯
                    "validationAction": "warn"      # éªŒè¯å¤±è´¥æ—¶è­¦å‘Šè€Œä¸æ˜¯é”™è¯¯
                })
                
                logger.info(f"  ä¸ºé›†åˆ {collection_name} è®¾ç½®éªŒè¯è§„åˆ™")
                
            except Exception as e:
                logger.warning(f"  è®¾ç½®é›†åˆ {collection_name} éªŒè¯è§„åˆ™å¤±è´¥: {str(e)}")
    
    def _create_initial_data(self):
        """åˆ›å»ºåˆå§‹æ•°æ®"""
        logger.info("åˆ›å»ºåˆå§‹æ•°æ®...")
        
        # åˆ›å»ºç³»ç»Ÿé…ç½®æ–‡æ¡£
        try:
            system_config = {
                "_id": "system_config",
                "version": "1.0.0",
                "schema_version": "1.0.0",
                "initialized_at": datetime.now(),
                "features": {
                    "file_sync": True,
                    "folder_sync": True,
                    "version_tracking": True,
                    "custom_attributes": True,
                    "review_states": True
                },
                "limits": {
                    "max_file_size_mb": 1000,
                    "max_versions_per_file": 100,
                    "max_depth": 20
                }
            }
            
            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
            if not self.database.system_config.find_one({"_id": "system_config"}):
                self.database.system_config.insert_one(system_config)
                logger.info("  åˆ›å»ºç³»ç»Ÿé…ç½®æ–‡æ¡£")
            else:
                logger.info("  ç³»ç»Ÿé…ç½®æ–‡æ¡£å·²å­˜åœ¨")
                
        except Exception as e:
            logger.warning(f"åˆ›å»ºåˆå§‹æ•°æ®å¤±è´¥: {str(e)}")
    
    def get_database_info(self):
        """è·å–æ•°æ®åº“ä¿¡æ¯"""
        try:
            if not self.database:
                self.connect()
            
            info = {
                "database_name": self.database.name,
                "collections": [],
                "total_size_mb": 0,
                "total_documents": 0
            }
            
            # è·å–é›†åˆä¿¡æ¯
            for collection_name in self.database.list_collection_names():
                collection = self.database[collection_name]
                stats = self.database.command("collStats", collection_name)
                
                collection_info = {
                    "name": collection_name,
                    "document_count": collection.count_documents({}),
                    "size_mb": round(stats.get("size", 0) / (1024 * 1024), 2),
                    "indexes": len(list(collection.list_indexes())),
                    "avg_document_size": stats.get("avgObjSize", 0)
                }
                
                info["collections"].append(collection_info)
                info["total_documents"] += collection_info["document_count"]
                info["total_size_mb"] += collection_info["size_mb"]
            
            info["total_size_mb"] = round(info["total_size_mb"], 2)
            return info
            
        except Exception as e:
            logger.error(f"è·å–æ•°æ®åº“ä¿¡æ¯å¤±è´¥: {str(e)}")
            return None
    
    def optimize_database(self):
        """ä¼˜åŒ–æ•°æ®åº“æ€§èƒ½"""
        logger.info("å¼€å§‹æ•°æ®åº“ä¼˜åŒ–...")
        
        try:
            if not self.database:
                self.connect()
            
            # é‡å»ºç´¢å¼•
            for collection_name in ["folders", "files", "file_versions"]:
                if collection_name in self.database.list_collection_names():
                    logger.info(f"é‡å»ºé›†åˆ {collection_name} çš„ç´¢å¼•...")
                    self.database[collection_name].reindex()
            
            # å‹ç¼©é›†åˆï¼ˆå¦‚æœæ”¯æŒï¼‰
            try:
                for collection_name in ["folders", "files", "file_versions"]:
                    if collection_name in self.database.list_collection_names():
                        logger.info(f"å‹ç¼©é›†åˆ {collection_name}...")
                        self.database.command("compact", collection_name)
            except Exception as e:
                logger.warning(f"é›†åˆå‹ç¼©å¤±è´¥ï¼ˆå¯èƒ½ä¸æ”¯æŒï¼‰: {str(e)}")
            
            logger.info("æ•°æ®åº“ä¼˜åŒ–å®Œæˆ")
            return True
            
        except Exception as e:
            logger.error(f"æ•°æ®åº“ä¼˜åŒ–å¤±è´¥: {str(e)}")
            return False
    
    def cleanup_old_data(self, days_to_keep=30):
        """æ¸…ç†æ—§æ•°æ®"""
        logger.info(f"æ¸…ç† {days_to_keep} å¤©å‰çš„æ—§æ•°æ®...")
        
        try:
            if not self.database:
                self.connect()
            
            from datetime import timedelta
            cutoff_date = datetime.now() - timedelta(days=days_to_keep)
            
            # æ¸…ç†æ—§çš„åŒæ­¥ä»»åŠ¡è®°å½•
            result = self.database.sync_tasks.delete_many({
                "start_time": {"$lt": cutoff_date},
                "task_status": {"$in": ["completed", "failed"]}
            })
            logger.info(f"  åˆ é™¤äº† {result.deleted_count} ä¸ªæ—§åŒæ­¥ä»»åŠ¡è®°å½•")
            
            # æ¸…ç†æ—§çš„ç³»ç»Ÿæ—¥å¿—ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
            if "system_logs" in self.database.list_collection_names():
                result = self.database.system_logs.delete_many({
                    "created_at": {"$lt": cutoff_date}
                })
                logger.info(f"  åˆ é™¤äº† {result.deleted_count} ä¸ªæ—§æ—¥å¿—è®°å½•")
            
            logger.info("æ—§æ•°æ®æ¸…ç†å®Œæˆ")
            return True
            
        except Exception as e:
            logger.error(f"æ¸…ç†æ—§æ•°æ®å¤±è´¥: {str(e)}")
            return False

# ä¾¿åˆ©å‡½æ•°
def initialize_database(drop_existing=False):
    """åˆå§‹åŒ–æ•°æ®åº“çš„ä¾¿åˆ©å‡½æ•°"""
    initializer = DatabaseInitializer()
    return initializer.initialize_database(drop_existing)

def get_database_info():
    """è·å–æ•°æ®åº“ä¿¡æ¯çš„ä¾¿åˆ©å‡½æ•°"""
    initializer = DatabaseInitializer()
    return initializer.get_database_info()

def optimize_database():
    """ä¼˜åŒ–æ•°æ®åº“çš„ä¾¿åˆ©å‡½æ•°"""
    initializer = DatabaseInitializer()
    return initializer.optimize_database()

if __name__ == "__main__":
    # æµ‹è¯•æ•°æ®åº“åˆå§‹åŒ–
    print("å¼€å§‹æ•°æ®åº“åˆå§‹åŒ–æµ‹è¯•...")
    
    initializer = DatabaseInitializer()
    
    # åˆå§‹åŒ–æ•°æ®åº“
    if initializer.initialize_database():
        print("âœ… æ•°æ®åº“åˆå§‹åŒ–æˆåŠŸ")
        
        # è·å–æ•°æ®åº“ä¿¡æ¯
        info = initializer.get_database_info()
        if info:
            print(f"ğŸ“Š æ•°æ®åº“ä¿¡æ¯:")
            print(f"  æ•°æ®åº“å: {info['database_name']}")
            print(f"  é›†åˆæ•°é‡: {len(info['collections'])}")
            print(f"  æ€»æ–‡æ¡£æ•°: {info['total_documents']}")
            print(f"  æ€»å¤§å°: {info['total_size_mb']} MB")
            
            for collection in info['collections']:
                print(f"  - {collection['name']}: {collection['document_count']} æ–‡æ¡£, {collection['size_mb']} MB, {collection['indexes']} ä¸ªç´¢å¼•")
    else:
        print("âŒ æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥")
