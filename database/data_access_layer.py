# -*- coding: utf-8 -*-
"""
æ•°æ®è®¿é—®å±‚ (Data Access Layer)
æä¾›å¯¹ä¼˜åŒ–æ•°æ®åº“ç»“æ„çš„é«˜çº§æ“ä½œæ¥å£
"""

import logging
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Union
from pymongo import MongoClient, ASCENDING, DESCENDING
from pymongo.errors import DuplicateKeyError, BulkWriteError
from .mongodb_config import MongoDBConfig, get_collection

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class DataAccessLayer:
    """æ•°æ®è®¿é—®å±‚ä¸»ç±»"""
    
    def __init__(self, db_config: MongoDBConfig = None):
        self.db_config = db_config or MongoDBConfig()
        self.database = None
        
    def connect(self):
        """è¿æ¥æ•°æ®åº“"""
        if not self.database:
            self.database = self.db_config.get_database()
        return self.database
    
    # ============================================================================
    # é¡¹ç›®ç›¸å…³æ“ä½œ
    # ============================================================================
    
    def create_or_update_project(self, project_data: Dict[str, Any]) -> bool:
        """åˆ›å»ºæˆ–æ›´æ–°é¡¹ç›®"""
        try:
            db = self.connect()
            project_id = project_data["_id"]
            
            # æ·»åŠ æ—¶é—´æˆ³
            now = datetime.now()
            if "_id" not in project_data or not db.projects.find_one({"_id": project_id}):
                project_data["created_at"] = now
            project_data["updated_at"] = now
            
            # ä½¿ç”¨upsertæ“ä½œ
            result = db.projects.replace_one(
                {"_id": project_id},
                project_data,
                upsert=True
            )
            
            logger.info(f"é¡¹ç›® {project_id} {'æ›´æ–°' if result.matched_count > 0 else 'åˆ›å»º'}æˆåŠŸ")
            return True
            
        except Exception as e:
            logger.error(f"åˆ›å»º/æ›´æ–°é¡¹ç›®å¤±è´¥: {str(e)}")
            return False
    
    def get_project(self, project_id: str) -> Optional[Dict[str, Any]]:
        """è·å–é¡¹ç›®ä¿¡æ¯"""
        try:
            db = self.connect()
            return db.projects.find_one({"_id": project_id})
        except Exception as e:
            logger.error(f"è·å–é¡¹ç›®ä¿¡æ¯å¤±è´¥: {str(e)}")
            return None
    
    def list_projects(self, limit: int = 100) -> List[Dict[str, Any]]:
        """åˆ—å‡ºæ‰€æœ‰é¡¹ç›®"""
        try:
            db = self.connect()
            return list(db.projects.find().limit(limit).sort("updated_at", -1))
        except Exception as e:
            logger.error(f"åˆ—å‡ºé¡¹ç›®å¤±è´¥: {str(e)}")
            return []
    
    def update_project_sync_status(self, project_id: str, status: str, 
                                 duration: float = None, error: str = None) -> bool:
        """æ›´æ–°é¡¹ç›®åŒæ­¥çŠ¶æ€"""
        try:
            import pytz
            # çµ±ä¸€ä½¿ç”¨ä¸­åœ‹æ™‚å€
            china_tz = pytz.timezone('Asia/Shanghai')
            china_time = datetime.now(china_tz)
            
            db = self.connect()
            update_data = {
                "sync_info.sync_status": status,
                "sync_info.last_sync_time": china_time,
                "updated_at": china_time
            }
            
            if duration is not None:
                update_data["sync_info.sync_duration_seconds"] = duration
            if error:
                update_data["sync_info.sync_error"] = error
            
            result = db.projects.update_one(
                {"_id": project_id},
                {"$set": update_data}
            )
            
            return result.modified_count > 0
            
        except Exception as e:
            logger.error(f"æ›´æ–°é¡¹ç›®åŒæ­¥çŠ¶æ€å¤±è´¥: {str(e)}")
            return False
    
    def clear_project_data(self, project_id: str) -> Dict[str, int]:
        """
        æ¸…é™¤é …ç›®çš„æ‰€æœ‰ç›¸é—œæ•¸æ“šï¼ˆç”¨æ–¼å…¨é‡åŒæ­¥å‰çš„æ•¸æ“šæ¸…ç†ï¼‰
        
        Args:
            project_id: é …ç›®ID
            
        Returns:
            æ¸…ç†çµæœçµ±è¨ˆå­—å…¸
        """
        try:
            db = self.connect()
            logger.info(f"ğŸ§¹ é–‹å§‹æ¸…é™¤é …ç›® {project_id} çš„æ‰€æœ‰æ•¸æ“š...")
            
            # æ¸…é™¤æ–‡ä»¶å¤¾æ•¸æ“š
            folders_result = db.folders.delete_many({"project_id": project_id})
            logger.info(f"  æ¸…é™¤æ–‡ä»¶å¤¾: {folders_result.deleted_count} å€‹")
            
            # æ¸…é™¤æ–‡ä»¶æ•¸æ“š  
            files_result = db.files.delete_many({"project_id": project_id})
            logger.info(f"  æ¸…é™¤æ–‡ä»¶: {files_result.deleted_count} å€‹")
            
            # æ¸…é™¤æ–‡ä»¶ç‰ˆæœ¬æ•¸æ“š
            versions_result = db.file_versions.delete_many({"project_id": project_id})
            logger.info(f"  æ¸…é™¤æ–‡ä»¶ç‰ˆæœ¬: {versions_result.deleted_count} å€‹")
            
            # æ¸…é™¤è‡ªå®šç¾©å±¬æ€§æ•¸æ“šï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            attributes_deleted = 0
            if "custom_attributes" in db.list_collection_names():
                attributes_result = db.custom_attributes.delete_many({"project_id": project_id})
                attributes_deleted = attributes_result.deleted_count
                logger.info(f"  æ¸…é™¤è‡ªå®šç¾©å±¬æ€§: {attributes_deleted} å€‹")
            
            # é‡ç½®é …ç›®çµ±è¨ˆæ•¸æ“šï¼Œä½†ä¿ç•™é …ç›®åŸºæœ¬ä¿¡æ¯
            project_reset_result = db.projects.update_one(
                {"_id": project_id},
                {
                    "$unset": {
                        "statistics": "",
                        "sync_info.last_full_sync": ""
                    },
                    "$set": {
                        "sync_info.sync_status": "clearing_data",
                        "updated_at": datetime.now()
                    }
                }
            )
            
            clear_stats = {
                "folders_deleted": folders_result.deleted_count,
                "files_deleted": files_result.deleted_count, 
                "versions_deleted": versions_result.deleted_count,
                "attributes_deleted": attributes_deleted,
                "project_reset": 1 if project_reset_result.modified_count > 0 else 0
            }
            
            total_deleted = sum(clear_stats.values())
            logger.info(f"âœ… é …ç›®æ•¸æ“šæ¸…ç†å®Œæˆï¼Œå…±æ¸…é™¤ {total_deleted} æ¢è¨˜éŒ„")
            
            return clear_stats
            
        except Exception as e:
            logger.error(f"âŒ æ¸…é™¤é …ç›®æ•¸æ“šå¤±æ•—: {str(e)}")
            raise Exception(f"æ¸…é™¤é …ç›®æ•¸æ“šå¤±æ•—: {str(e)}")
    
    # ============================================================================
    # æ–‡ä»¶å¤¹ç›¸å…³æ“ä½œ
    # ============================================================================
    
    def create_or_update_folder(self, folder_data: Dict[str, Any]) -> bool:
        """åˆ›å»ºæˆ–æ›´æ–°å•ä¸ªæ–‡ä»¶å¤¹"""
        try:
            db = self.connect()
            folder_id = folder_data["_id"]
            
            # æ·»åŠ æ—¶é—´æˆ³
            now = datetime.now()
            if "_id" not in folder_data or not db.folders.find_one({"_id": folder_id}):
                folder_data["created_at"] = now
            folder_data["updated_at"] = now
            
            # æ·»åŠ ç»„åˆç´¢å¼•å­—æ®µ
            if "project_id" in folder_data and "path" in folder_data:
                folder_data["project_path"] = f"{folder_data['project_id']}#{folder_data['path']}"
            
            # ä½¿ç”¨upsertæ“ä½œ
            result = db.folders.replace_one(
                {"_id": folder_id},
                folder_data,
                upsert=True
            )
            
            logger.info(f"æ–‡ä»¶å¤¹ {folder_id} {'æ›´æ–°' if result.matched_count > 0 else 'åˆ›å»º'}æˆåŠŸ")
            return True
            
        except Exception as e:
            logger.error(f"åˆ›å»º/æ›´æ–°æ–‡ä»¶å¤¹å¤±è´¥: {str(e)}")
            return False

    def batch_upsert_folders(self, folders_data: List[Dict[str, Any]]) -> Dict[str, int]:
        """æ‰¹é‡æ’å…¥æˆ–æ›´æ–°æ–‡ä»¶å¤¹"""
        try:
            db = self.connect()
            
            if not folders_data:
                return {"inserted": 0, "updated": 0, "errors": 0}
            
            # å‡†å¤‡æ‰¹é‡æ“ä½œ
            operations = []
            now = datetime.now()
            
            for folder_data in folders_data:
                folder_id = folder_data["_id"]
                
                # æ·»åŠ æ—¶é—´æˆ³å’Œç´¢å¼•ä¼˜åŒ–å­—æ®µ
                folder_data["updated_at"] = now
                if "created_at" not in folder_data:
                    folder_data["created_at"] = now
                
                # æ·»åŠ ç»„åˆç´¢å¼•å­—æ®µ
                folder_data["project_path"] = f"{folder_data['project_id']}#{folder_data['path']}"
                if folder_data.get("parent_id"):
                    parent_path = folder_data["path"].rsplit("/", 1)[0] if "/" in folder_data["path"] else ""
                    folder_data["parent_path"] = parent_path
                
                from pymongo import ReplaceOne
                operations.append(
                    ReplaceOne(
                        filter={"_id": folder_id},
                        replacement=folder_data,
                        upsert=True
                    )
                )
            
            # æ‰§è¡Œæ‰¹é‡æ“ä½œ
            result = db.folders.bulk_write(operations, ordered=False)
            
            stats = {
                "inserted": result.upserted_count,
                "updated": result.modified_count,
                "errors": 0
            }
            
            logger.info(f"æ‰¹é‡æ–‡ä»¶å¤¹æ“ä½œå®Œæˆ: æ’å…¥ {stats['inserted']}, æ›´æ–° {stats['updated']}")
            return stats
            
        except BulkWriteError as e:
            logger.error(f"æ‰¹é‡æ–‡ä»¶å¤¹æ“ä½œéƒ¨åˆ†å¤±è´¥: {len(e.details['writeErrors'])} ä¸ªé”™è¯¯")
            return {"inserted": 0, "updated": 0, "errors": len(e.details['writeErrors'])}
        except Exception as e:
            logger.error(f"æ‰¹é‡æ–‡ä»¶å¤¹æ“ä½œå¤±è´¥: {str(e)}")
            return {"inserted": 0, "updated": 0, "errors": len(folders_data)}
    
    def get_folders_by_project(self, project_id: str, parent_id: str = None, 
                              max_depth: int = None) -> List[Dict[str, Any]]:
        """è·å–é¡¹ç›®çš„æ–‡ä»¶å¤¹åˆ—è¡¨"""
        try:
            db = self.connect()
            
            # æ„å»ºæŸ¥è¯¢æ¡ä»¶
            query = {"project_id": project_id}
            if parent_id:
                query["parent_id"] = parent_id
            if max_depth is not None:
                query["depth"] = {"$lte": max_depth}
            
            return list(db.folders.find(query).sort("path", 1))
            
        except Exception as e:
            logger.error(f"è·å–é¡¹ç›®æ–‡ä»¶å¤¹å¤±è´¥: {str(e)}")
            return []
    
    def get_folder_tree(self, project_id: str, root_folder_id: str = None) -> List[Dict[str, Any]]:
        """è·å–æ–‡ä»¶å¤¹æ ‘ç»“æ„"""
        try:
            db = self.connect()
            
            # æ„å»ºèšåˆç®¡é“
            pipeline = [
                {"$match": {"project_id": project_id}},
                {"$sort": {"depth": 1, "path": 1}}
            ]
            
            if root_folder_id:
                pipeline[0]["$match"]["$or"] = [
                    {"_id": root_folder_id},
                    {"path": {"$regex": f"^{root_folder_id}/"}}
                ]
            
            folders = list(db.folders.aggregate(pipeline))
            
            # æ„å»ºæ ‘ç»“æ„
            folder_map = {f["_id"]: f for f in folders}
            tree = []
            
            for folder in folders:
                folder["children"] = []
                parent_id = folder.get("parent_id")
                
                if parent_id and parent_id in folder_map:
                    folder_map[parent_id]["children"].append(folder)
                else:
                    tree.append(folder)
            
            return tree
            
        except Exception as e:
            logger.error(f"è·å–æ–‡ä»¶å¤¹æ ‘å¤±è´¥: {str(e)}")
            return []
    
    def search_folders(self, project_id: str, search_text: str, limit: int = 50) -> List[Dict[str, Any]]:
        """æœç´¢æ–‡ä»¶å¤¹"""
        try:
            db = self.connect()
            
            # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æœç´¢
            query = {
                "project_id": project_id,
                "$or": [
                    {"name": {"$regex": search_text, "$options": "i"}},
                    {"display_name": {"$regex": search_text, "$options": "i"}},
                    {"path": {"$regex": search_text, "$options": "i"}}
                ]
            }
            
            return list(db.folders.find(query).limit(limit).sort("path", 1))
            
        except Exception as e:
            logger.error(f"æœç´¢æ–‡ä»¶å¤¹å¤±è´¥: {str(e)}")
            return []
    
    # ============================================================================
    # æ–‡ä»¶ç›¸å…³æ“ä½œ
    # ============================================================================
    
    def create_or_update_file(self, file_data: Dict[str, Any]) -> bool:
        """åˆ›å»ºæˆ–æ›´æ–°å•ä¸ªæ–‡ä»¶"""
        try:
            db = self.connect()
            file_id = file_data["_id"]
            
            # æ·»åŠ æ—¶é—´æˆ³
            now = datetime.now()
            if "_id" not in file_data or not db.files.find_one({"_id": file_id}):
                file_data["created_at"] = now
            file_data["updated_at"] = now
            
            # æ·»åŠ ç»„åˆç´¢å¼•å­—æ®µ
            if "project_id" in file_data and "folder_path" in file_data:
                file_data["project_folder"] = f"{file_data['project_id']}#{file_data['folder_path']}"
            
            # æ·»åŠ å°å†™æ–‡ä»¶åç”¨äºæœç´¢
            if "name" in file_data:
                file_data["name_lower"] = file_data["name"].lower()
            
            # ä½¿ç”¨upsertæ“ä½œ
            result = db.files.replace_one(
                {"_id": file_id},
                file_data,
                upsert=True
            )
            
            logger.info(f"æ–‡ä»¶ {file_id} {'æ›´æ–°' if result.matched_count > 0 else 'åˆ›å»º'}æˆåŠŸ")
            return True
            
        except Exception as e:
            logger.error(f"åˆ›å»º/æ›´æ–°æ–‡ä»¶å¤±è´¥: {str(e)}")
            return False

    def batch_upsert_files(self, files_data: List[Dict[str, Any]]) -> Dict[str, int]:
        """æ‰¹é‡æ’å…¥æˆ–æ›´æ–°æ–‡ä»¶"""
        try:
            db = self.connect()
            
            if not files_data:
                return {"inserted": 0, "updated": 0, "errors": 0}
            
            # å‡†å¤‡æ‰¹é‡æ“ä½œ
            operations = []
            now = datetime.now()
            
            for file_data in files_data:
                file_id = file_data["_id"]
                
                # æ·»åŠ æ—¶é—´æˆ³å’Œç´¢å¼•ä¼˜åŒ–å­—æ®µ
                file_data["updated_at"] = now
                if "created_at" not in file_data:
                    file_data["created_at"] = now
                
                # æ·»åŠ ç»„åˆç´¢å¼•å­—æ®µ
                file_data["project_folder"] = f"{file_data['project_id']}#{file_data['folder_path']}"
                if file_data.get("file_info", {}).get("file_type"):
                    file_data["project_type"] = f"{file_data['project_id']}#{file_data['file_info']['file_type']}"
                
                # æ·»åŠ å°å†™æ–‡ä»¶åç”¨äºæœç´¢
                file_data["name_lower"] = file_data["name"].lower()
                
                from pymongo import ReplaceOne
                operations.append(
                    ReplaceOne(
                        filter={"_id": file_id},
                        replacement=file_data,
                        upsert=True
                    )
                )
            
            # æ‰§è¡Œæ‰¹é‡æ“ä½œ
            result = db.files.bulk_write(operations, ordered=False)
            
            stats = {
                "inserted": result.upserted_count,
                "updated": result.modified_count,
                "errors": 0
            }
            
            logger.info(f"æ‰¹é‡æ–‡ä»¶æ“ä½œå®Œæˆ: æ’å…¥ {stats['inserted']}, æ›´æ–° {stats['updated']}")
            return stats
            
        except BulkWriteError as e:
            logger.error(f"æ‰¹é‡æ–‡ä»¶æ“ä½œéƒ¨åˆ†å¤±è´¥: {len(e.details['writeErrors'])} ä¸ªé”™è¯¯")
            return {"inserted": 0, "updated": 0, "errors": len(e.details['writeErrors'])}
        except Exception as e:
            logger.error(f"æ‰¹é‡æ–‡ä»¶æ“ä½œå¤±è´¥: {str(e)}")
            return {"inserted": 0, "updated": 0, "errors": len(files_data)}
    
    def get_files_by_folder(self, project_id: str, folder_path: str = None, 
                           file_types: List[str] = None, limit: int = 1000) -> List[Dict[str, Any]]:
        """è·å–æ–‡ä»¶å¤¹ä¸­çš„æ–‡ä»¶"""
        try:
            db = self.connect()
            
            # æ„å»ºæŸ¥è¯¢æ¡ä»¶
            query = {"project_id": project_id}
            if folder_path:
                query["folder_path"] = folder_path
            if file_types:
                query["file_info.file_type"] = {"$in": file_types}
            
            return list(db.files.find(query).limit(limit).sort("name", 1))
            
        except Exception as e:
            logger.error(f"è·å–æ–‡ä»¶å¤¹æ–‡ä»¶å¤±è´¥: {str(e)}")
            return []
    
    def search_files(self, project_id: str, search_text: str = None, 
                    file_types: List[str] = None, review_states: List[str] = None,
                    limit: int = 100) -> List[Dict[str, Any]]:
        """æœç´¢æ–‡ä»¶"""
        try:
            db = self.connect()
            
            # æ„å»ºæŸ¥è¯¢æ¡ä»¶
            query = {"project_id": project_id}
            
            if search_text:
                # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æœç´¢ï¼Œé¿å…æ–‡æœ¬ç´¢å¼•é—®é¢˜
                query["$or"] = [
                    {"name_lower": {"$regex": search_text.lower()}},
                    {"display_name": {"$regex": search_text, "$options": "i"}},
                    {"full_path": {"$regex": search_text, "$options": "i"}}
                ]
            
            if file_types:
                query["file_info.file_type"] = {"$in": file_types}
            
            if review_states:
                query["current_version.review_state"] = {"$in": review_states}
            
            return list(db.files.find(query).limit(limit).sort("metadata.last_modified_time", -1))
            
        except Exception as e:
            logger.error(f"æœç´¢æ–‡ä»¶å¤±è´¥: {str(e)}")
            return []
    
    def get_files_by_review_state(self, project_id: str, review_state: str, 
                                 limit: int = 100) -> List[Dict[str, Any]]:
        """æ ¹æ®reviewçŠ¶æ€è·å–æ–‡ä»¶"""
        try:
            db = self.connect()
            
            query = {
                "project_id": project_id,
                "current_version.review_state": review_state
            }
            
            return list(db.files.find(query).limit(limit).sort("metadata.last_modified_time", -1))
            
        except Exception as e:
            logger.error(f"æ ¹æ®reviewçŠ¶æ€è·å–æ–‡ä»¶å¤±è´¥: {str(e)}")
            return []
    
    # ============================================================================
    # æ–‡ä»¶ç‰ˆæœ¬ç›¸å…³æ“ä½œ
    # ============================================================================
    
    def create_or_update_file_version(self, version_data: Dict[str, Any]) -> bool:
        """åˆ›å»ºæˆ–æ›´æ–°å•ä¸ªæ–‡ä»¶ç‰ˆæœ¬"""
        try:
            db = self.connect()
            version_id = version_data["_id"]
            
            # æ·»åŠ æ—¶é—´æˆ³
            now = datetime.now()
            if "_id" not in version_data or not db.file_versions.find_one({"_id": version_id}):
                version_data["created_at"] = now
            version_data["updated_at"] = now
            
            # ä½¿ç”¨upsertæ“ä½œ
            result = db.file_versions.replace_one(
                {"_id": version_id},
                version_data,
                upsert=True
            )
            
            logger.debug(f"æ–‡ä»¶ç‰ˆæœ¬ {version_id} {'æ›´æ–°' if result.matched_count > 0 else 'åˆ›å»º'}æˆåŠŸ")
            return True
            
        except Exception as e:
            logger.error(f"åˆ›å»º/æ›´æ–°æ–‡ä»¶ç‰ˆæœ¬å¤±è´¥: {str(e)}")
            return False

    def batch_upsert_file_versions(self, versions_data: List[Dict[str, Any]]) -> Dict[str, int]:
        """æ‰¹é‡æ’å…¥æˆ–æ›´æ–°æ–‡ä»¶ç‰ˆæœ¬"""
        try:
            db = self.connect()
            
            if not versions_data:
                return {"inserted": 0, "updated": 0, "errors": 0}
            
            # å‡†å¤‡æ‰¹é‡æ“ä½œ
            operations = []
            now = datetime.now()
            
            for version_data in versions_data:
                version_id = version_data["_id"]
                
                # æ·»åŠ æ—¶é—´æˆ³
                version_data["updated_at"] = now
                if "created_at" not in version_data:
                    version_data["created_at"] = now
                
                from pymongo import ReplaceOne
                operations.append(
                    ReplaceOne(
                        filter={"_id": version_id},
                        replacement=version_data,
                        upsert=True
                    )
                )
            
            # æ‰§è¡Œæ‰¹é‡æ“ä½œ
            result = db.file_versions.bulk_write(operations, ordered=False)
            
            stats = {
                "inserted": result.upserted_count,
                "updated": result.modified_count,
                "errors": 0
            }
            
            logger.info(f"æ‰¹é‡ç‰ˆæœ¬æ“ä½œå®Œæˆ: æ’å…¥ {stats['inserted']}, æ›´æ–° {stats['updated']}")
            return stats
            
        except BulkWriteError as e:
            logger.error(f"æ‰¹é‡ç‰ˆæœ¬æ“ä½œéƒ¨åˆ†å¤±è´¥: {len(e.details['writeErrors'])} ä¸ªé”™è¯¯")
            return {"inserted": 0, "updated": 0, "errors": len(e.details['writeErrors'])}
        except Exception as e:
            logger.error(f"æ‰¹é‡ç‰ˆæœ¬æ“ä½œå¤±è´¥: {str(e)}")
            return {"inserted": 0, "updated": 0, "errors": len(versions_data)}
    
    def get_file_versions(self, file_id: str, limit: int = 50) -> List[Dict[str, Any]]:
        """è·å–æ–‡ä»¶çš„æ‰€æœ‰ç‰ˆæœ¬"""
        try:
            db = self.connect()
            
            return list(db.file_versions.find(
                {"file_id": file_id}
            ).limit(limit).sort("version_number", -1))
            
        except Exception as e:
            logger.error(f"è·å–æ–‡ä»¶ç‰ˆæœ¬å¤±è´¥: {str(e)}")
            return []
    
    def get_version_by_urn(self, urn: str) -> Optional[Dict[str, Any]]:
        """æ ¹æ®URNè·å–ç‰ˆæœ¬ä¿¡æ¯"""
        try:
            db = self.connect()
            
            # å°è¯•ä¸åŒçš„URNå­—æ®µ
            query = {"$or": [
                {"urn": urn},
                {"item_urn": urn},
                {"storage_urn": urn},
                {"lineage_urn": urn}
            ]}
            
            return db.file_versions.find_one(query)
            
        except Exception as e:
            logger.error(f"æ ¹æ®URNè·å–ç‰ˆæœ¬å¤±è´¥: {str(e)}")
            return None
    
    # ============================================================================
    # ç®€åŒ–çš„åŒæ­¥å†å²è®°å½•æ“ä½œ
    # ============================================================================
    
    def create_sync_history_record(self, project_id: str, sync_type: str, results: dict) -> bool:
        """åˆ›å»ºç®€åŒ–çš„åŒæ­¥å†å²è®°å½• - åªè®°å½•æˆåŠŸçš„åŒæ­¥"""
        try:
            from .simplified_sync_schema import create_sync_record
            
            db = self.connect()
            record = create_sync_record(project_id, sync_type, results)
            
            result = db.sync_history.insert_one(record)
            logger.info(f"åˆ›å»ºåŒæ­¥å†å²è®°å½•æˆåŠŸ: {result.inserted_id}")
            return True
            
        except Exception as e:
            logger.error(f"åˆ›å»ºåŒæ­¥å†å²è®°å½•å¤±è´¥: {str(e)}")
            return False
    
    def get_sync_history(self, project_id: str, limit: int = 20, offset: int = 0, 
                        sync_type: str = None) -> List[Dict[str, Any]]:
        """è·å–é¡¹ç›®åŒæ­¥å†å²è®°å½•"""
        try:
            from .simplified_sync_schema import format_china_time
            
            db = self.connect()
            
            # æ„å»ºæŸ¥è¯¢æ¡ä»¶
            query = {"project_id": project_id}
            if sync_type:
                query["sync_type"] = sync_type
            
            # æŸ¥è¯¢è®°å½•
            records = list(db.sync_history.find(query)
                          .sort("sync_time", -1)
                          .skip(offset)
                          .limit(limit))
            
            # æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤º
            for record in records:
                if "_id" in record:
                    record["_id"] = str(record["_id"])
                
                # æ ¼å¼åŒ–æ—¶é—´ä¸ºä¸­å›½æ—¶é—´å­—ç¬¦ä¸²
                if "sync_time" in record and record["sync_time"]:
                    record["sync_time_formatted"] = format_china_time(record["sync_time"])
                if "created_at" in record and record["created_at"]:
                    record["created_at_formatted"] = format_china_time(record["created_at"])
            
            return records
            
        except Exception as e:
            logger.error(f"è·å–åŒæ­¥å†å²è®°å½•å¤±è´¥: {str(e)}")
            return []
    
    def get_sync_history_count(self, project_id: str, sync_type: str = None) -> int:
        """è·å–åŒæ­¥å†å²è®°å½•æ€»æ•°"""
        try:
            db = self.connect()
            
            query = {"project_id": project_id}
            if sync_type:
                query["sync_type"] = sync_type
            
            return db.sync_history.count_documents(query)
            
        except Exception as e:
            logger.error(f"è·å–åŒæ­¥å†å²è®°å½•æ€»æ•°å¤±è´¥: {str(e)}")
            return 0

    # ============================================================================
    # åŒæ­¥ä»»åŠ¡ç›¸å…³æ“ä½œï¼ˆä¿ç•™ç”¨äºå‘åå…¼å®¹ï¼‰
    # ============================================================================
    
    def create_sync_task(self, task_data: Dict[str, Any]) -> Optional[str]:
        """åˆ›å»ºåŒæ­¥ä»»åŠ¡"""
        try:
            db = self.connect()
            
            task_data["created_at"] = datetime.now()
            task_data["updated_at"] = datetime.now()
            
            result = db.sync_tasks.insert_one(task_data)
            logger.info(f"åˆ›å»ºåŒæ­¥ä»»åŠ¡æˆåŠŸ: {result.inserted_id}")
            return str(result.inserted_id)
            
        except Exception as e:
            logger.error(f"åˆ›å»ºåŒæ­¥ä»»åŠ¡å¤±è´¥: {str(e)}")
            return None
    
    def update_sync_task(self, task_id: str, update_data: Dict[str, Any]) -> bool:
        """æ›´æ–°åŒæ­¥ä»»åŠ¡"""
        try:
            db = self.connect()
            
            update_data["updated_at"] = datetime.now()
            
            result = db.sync_tasks.update_one(
                {"_id": task_id},
                {"$set": update_data}
            )
            
            return result.modified_count > 0
            
        except Exception as e:
            logger.error(f"æ›´æ–°åŒæ­¥ä»»åŠ¡å¤±è´¥: {str(e)}")
            return False
    
    def update_sync_task_status(self, task_id: str, status: str, results: Dict[str, Any] = None, duration: float = None) -> bool:
        """æ›´æ–°åŒæ­¥ä»»åŠ¡çŠ¶æ€"""
        try:
            db = self.connect()
            
            update_data = {
                "task_status": status,
                "updated_at": datetime.now()
            }
            
            if results:
                update_data["results"] = results
            
            if duration is not None:
                update_data["duration_seconds"] = duration
                update_data["end_time"] = datetime.now()
            
            result = db.sync_tasks.update_one(
                {"_id": task_id},
                {"$set": update_data}
            )
            
            return result.modified_count > 0
            
        except Exception as e:
            logger.error(f"æ›´æ–°åŒæ­¥ä»»åŠ¡çŠ¶æ€å¤±è´¥: {str(e)}")
            return False
    
    def get_sync_tasks(self, project_id: str = None, status: str = None, 
                      limit: int = 50) -> List[Dict[str, Any]]:
        """è·å–åŒæ­¥ä»»åŠ¡åˆ—è¡¨"""
        try:
            db = self.connect()
            
            query = {}
            if project_id:
                query["project_id"] = project_id
            if status:
                query["task_status"] = status
            
            return list(db.sync_tasks.find(query).limit(limit).sort("start_time", -1))
            
        except Exception as e:
            logger.error(f"è·å–åŒæ­¥ä»»åŠ¡å¤±è´¥: {str(e)}")
            return []
    
    # ============================================================================
    # ç»Ÿè®¡å’Œåˆ†æ
    # ============================================================================
    
    def update_project_statistics(self, project_id: str, stats: Dict[str, Any]) -> bool:
        """æ›´æ–°é¡¹ç›®ç»Ÿè®¡ä¿¡æ¯"""
        try:
            db = self.connect()
            
            result = db.projects.update_one(
                {"_id": project_id},
                {"$set": {
                    "statistics": stats,
                    "updated_at": datetime.now()
                }}
            )
            
            return result.modified_count > 0
            
        except Exception as e:
            logger.error(f"æ›´æ–°é¡¹ç›®ç»Ÿè®¡å¤±è´¥: {str(e)}")
            return False

    def get_project_statistics(self, project_id: str) -> Dict[str, Any]:
        """è·å–é¡¹ç›®ç»Ÿè®¡ä¿¡æ¯"""
        try:
            db = self.connect()
            
            # æ–‡ä»¶å¤¹ç»Ÿè®¡
            folder_stats = db.folders.aggregate([
                {"$match": {"project_id": project_id}},
                {"$group": {
                    "_id": None,
                    "total_folders": {"$sum": 1},
                    "max_depth": {"$max": "$depth"},
                    "avg_children": {"$avg": "$children_stats.direct_folders"}
                }}
            ])
            folder_stats = list(folder_stats)
            folder_stats = folder_stats[0] if folder_stats else {}
            
            # æ–‡ä»¶ç»Ÿè®¡
            file_stats = db.files.aggregate([
                {"$match": {"project_id": project_id}},
                {"$group": {
                    "_id": None,
                    "total_files": {"$sum": 1},
                    "total_size": {"$sum": "$current_version.file_size"},
                    "avg_file_size": {"$avg": "$current_version.file_size"}
                }}
            ])
            file_stats = list(file_stats)
            file_stats = file_stats[0] if file_stats else {}
            
            # æ–‡ä»¶ç±»å‹ç»Ÿè®¡
            file_type_stats = db.files.aggregate([
                {"$match": {"project_id": project_id}},
                {"$group": {
                    "_id": "$file_info.file_type",
                    "count": {"$sum": 1},
                    "total_size": {"$sum": "$current_version.file_size"}
                }},
                {"$sort": {"count": -1}}
            ])
            file_type_stats = list(file_type_stats)
            
            # ReviewçŠ¶æ€ç»Ÿè®¡
            review_stats = db.files.aggregate([
                {"$match": {"project_id": project_id}},
                {"$group": {
                    "_id": "$current_version.review_state",
                    "count": {"$sum": 1}
                }},
                {"$sort": {"count": -1}}
            ])
            review_stats = list(review_stats)
            
            return {
                "project_id": project_id,
                "folders": {
                    "total_count": folder_stats.get("total_folders", 0),
                    "max_depth": folder_stats.get("max_depth", 0),
                    "avg_children": folder_stats.get("avg_children", 0)
                },
                "files": {
                    "total_count": file_stats.get("total_files", 0),
                    "total_size_bytes": file_stats.get("total_size", 0),
                    "avg_file_size_bytes": file_stats.get("avg_file_size", 0)
                },
                "file_types": {item["_id"]: item["count"] for item in file_type_stats if item["_id"]},
                "review_states": {item["_id"]: item["count"] for item in review_stats if item["_id"]},
                "generated_at": datetime.now()
            }
            
        except Exception as e:
            logger.error(f"è·å–é¡¹ç›®ç»Ÿè®¡å¤±è´¥: {str(e)}")
            return {}
    
    def get_recent_sync_tasks(self, project_id: str, limit: int = 5) -> List[Dict[str, Any]]:
        """è·å–é¡¹ç›®æœ€è¿‘çš„åŒæ­¥ä»»åŠ¡"""
        try:
            db = self.connect()
            query = {"project_id": project_id}
            tasks = list(db.sync_tasks.find(query).limit(limit).sort("start_time", -1))
            
            # è½¬æ¢ObjectIdå’Œæ—¥æœŸæ—¶é—´ä¸ºå­—ç¬¦ä¸²
            for task in tasks:
                if "_id" in task:
                    task["_id"] = str(task["_id"])
                for field in ["start_time", "end_time", "created_at", "updated_at"]:
                    if field in task and task[field]:
                        task[field] = task[field].isoformat() if hasattr(task[field], 'isoformat') else task[field]
            
            return tasks
            
        except Exception as e:
            logger.error(f"è·å–æœ€è¿‘åŒæ­¥ä»»åŠ¡å¤±è´¥: {str(e)}")
            return []
    
    def update_sync_task_progress(self, task_id: str, progress_data: dict) -> bool:
        """æ›´æ–°åŒæ­¥ä»»åŠ¡è¿›åº¦"""
        try:
            from bson import ObjectId
            db = self.connect()
            
            update_data = {
                "progress": progress_data,
                "updated_at": datetime.now()
            }
            
            # å°†å­—ç¬¦ä¸²IDè½¬æ¢ä¸ºObjectId
            object_id = ObjectId(task_id) if isinstance(task_id, str) else task_id
            
            result = db.sync_tasks.update_one(
                {"_id": object_id},
                {"$set": update_data}
            )
            
            return result.modified_count > 0
            
        except Exception as e:
            logger.error(f"æ›´æ–°åŒæ­¥ä»»åŠ¡è¿›åº¦å¤±è´¥: {str(e)}")
            return False

    def get_sync_task_progress(self, task_id: str) -> Optional[Dict[str, Any]]:
        """è·å–åŒæ­¥ä»»åŠ¡è¿›åº¦"""
        try:
            from bson import ObjectId
            db = self.connect()
            
            # å°†å­—ç¬¦ä¸²IDè½¬æ¢ä¸ºObjectId
            object_id = ObjectId(task_id) if isinstance(task_id, str) else task_id
            task = db.sync_tasks.find_one({"_id": object_id})
            
            if task:
                # è½¬æ¢ObjectIdä¸ºå­—ç¬¦ä¸²
                if "_id" in task:
                    task["_id"] = str(task["_id"])
                
                # è½¬æ¢æ—¥æœŸæ—¶é—´
                for field in ["start_time", "end_time", "created_at", "updated_at"]:
                    if field in task and task[field]:
                        task[field] = task[field].isoformat() if hasattr(task[field], 'isoformat') else task[field]
                
                return task
            
            return None
            
        except Exception as e:
            logger.error(f"è·å–åŒæ­¥ä»»åŠ¡è¿›åº¦å¤±è´¥: {str(e)}")
            return None

# å…¨å±€æ•°æ®è®¿é—®å±‚å®ä¾‹
dal = DataAccessLayer()

# ä¾¿åˆ©å‡½æ•°
def get_dal() -> DataAccessLayer:
    """è·å–æ•°æ®è®¿é—®å±‚å®ä¾‹"""
    return dal
