"""
Account data synchronization script
Specialized for syncing ACC accounts, users, companies, and role information
Based on AccountRolesList.vue pattern design
"""

import sys
import os

# Set UTF-8 encoding for Windows console
if sys.platform == "win32":
    import codecs
    sys.stdout = codecs.getwriter('utf-8')(sys.stdout.buffer, 'strict')
    sys.stderr = codecs.getwriter('utf-8')(sys.stderr.buffer, 'strict')
import json
import time
import asyncio
import aiohttp
from datetime import datetime, timezone
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

try:
    from database_sql.neon_config import NeonConfig
    import psycopg2
    import psycopg2.extras
    # Import utils for 2-legged token support
    from utils import get_two_legged_token
except ImportError:
    print("Warning: Could not import database dependencies")
    NeonConfig = None
    psycopg2 = None
    get_two_legged_token = None

@dataclass
class AccountSyncStats:
    """è´¦æˆ·åŒæ­¥ç»Ÿè®¡"""
    accounts_synced: int = 0
    users_synced: int = 0
    users_updated: int = 0
    companies_synced: int = 0
    companies_updated: int = 0
    project_users_synced: int = 0
    project_users_updated: int = 0
    roles_synced: int = 0
    errors: List[str] = None
    
    def __post_init__(self):
        if self.errors is None:
            self.errors = []

class AccountDataSyncManager:
    """è´¦æˆ·æ•°æ®åŒæ­¥ç®¡ç†å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–åŒæ­¥ç®¡ç†å™¨"""
        self.neon_config = NeonConfig() if NeonConfig else None
        self.db_params = self.neon_config.get_db_params() if self.neon_config else {}
        self.stats = AccountSyncStats()
    
    def get_connection(self):
        """è·å–æ•°æ®åº“è¿æ¥"""
        if not psycopg2:
            raise Exception("psycopg2 not available")
        return psycopg2.connect(**self.db_params)
    
    def drop_account_tables(self, show_progress: bool = True) -> bool:
        """
        Drop all account-related tables to prevent data corruption
        
        Args:
            show_progress: Whether to show progress messages
            
        Returns:
            True if successful, False otherwise
        """
        if show_progress:
            print("\n[DROP]  Dropping account tables to prevent data corruption...")
        
        conn = None
        try:
            conn = self.get_connection()
            cursor = conn.cursor()
            
            # Drop tables in reverse dependency order
            tables_to_drop = [
                'project_users',  # References users and projects
                'users',          # References accounts and companies
                'projects',       # References accounts
                'companies',      # References accounts
                'roles',          # References accounts
                'accounts'        # Base table
            ]
            
            for table in tables_to_drop:
                try:
                    cursor.execute(f"DROP TABLE IF EXISTS {table} CASCADE")
                    if show_progress:
                        print(f"   [OK] Dropped table: {table}")
                except Exception as e:
                    if show_progress:
                        print(f"   [WARN] Warning dropping {table}: {e}")
            
            # Drop enum types if they exist
            enum_types = [
                'user_status_type',
                'trade_type'
            ]
            
            for enum_type in enum_types:
                try:
                    cursor.execute(f"DROP TYPE IF EXISTS {enum_type} CASCADE")
                    if show_progress:
                        print(f"   [OK] Dropped enum type: {enum_type}")
                except Exception as e:
                    if show_progress:
                        print(f"   [WARN] Warning dropping {enum_type}: {e}")
            
            conn.commit()
            
            if show_progress:
                print("   [SUCCESS] All account tables dropped successfully")
            
            return True
            
        except Exception as e:
            if conn:
                conn.rollback()
            error_msg = f"Failed to drop account tables: {str(e)}"
            self.stats.errors.append(error_msg)
            if show_progress:
                print(f"   [FAILED] {error_msg}")
            return False
            
        finally:
            if conn:
                conn.close()
    
    def create_account_schema(self, show_progress: bool = True) -> bool:
        """
        Create account schema from optimized SQL file
        
        Args:
            show_progress: Whether to show progress messages
            
        Returns:
            True if successful, False otherwise
        """
        if show_progress:
            print("\n[CREATE]  Creating account schema...")
        
        conn = None
        try:
            import os
            import re
            
            # Find the schema file
            schema_file = os.path.join(os.path.dirname(__file__), 'account_schema_optimized.sql')
            
            if not os.path.exists(schema_file):
                error_msg = f"Schema file not found: {schema_file}"
                self.stats.errors.append(error_msg)
                if show_progress:
                    print(f"   [FAILED] {error_msg}")
                return False
            
            conn = self.get_connection()
            cursor = conn.cursor()
            
            # Read schema file
            with open(schema_file, 'r', encoding='utf-8') as f:
                schema_sql = f.read()
            
            # Execute the entire schema as one transaction
            # This handles multi-line functions and DO blocks correctly
            try:
                cursor.execute(schema_sql)
                conn.commit()
                
                if show_progress:
                    print("   [SUCCESS] Account schema created successfully")
                
                return True
                
            except Exception as e:
                # If full execution fails, try to execute in chunks
                if show_progress:
                    print(f"   [WARN] Full execution failed, trying chunk execution: {e}")
                
                conn.rollback()
                
                # Split by major sections, preserving DO blocks and functions
                sections = self._split_sql_into_sections(schema_sql)
                
                for i, section in enumerate(sections):
                    if section.strip() and not section.strip().startswith('--'):
                        try:
                            cursor.execute(section)
                            conn.commit()
                        except Exception as section_error:
                            # Some statements might fail if objects already exist, that's OK
                            if ('already exists' not in str(section_error).lower() and 
                                'does not exist' not in str(section_error).lower()):
                                if show_progress:
                                    print(f"   [WARN] Warning executing section {i+1}: {section_error}")
                            conn.rollback()  # Reset transaction state
                
                if show_progress:
                    print("   [SUCCESS] Account schema created successfully (with warnings)")
                
                return True
            
        except Exception as e:
            if conn:
                conn.rollback()
            error_msg = f"Failed to create account schema: {str(e)}"
            self.stats.errors.append(error_msg)
            if show_progress:
                print(f"   [FAILED] {error_msg}")
            return False
            
        finally:
            if conn:
                conn.close()
    
    def _split_sql_into_sections(self, sql_content: str) -> List[str]:
        """
        Split SQL content into logical sections, preserving multi-line constructs
        """
        import re
        
        # Remove comments but preserve structure
        lines = sql_content.split('\n')
        cleaned_lines = []
        
        for line in lines:
            # Keep non-comment lines and section headers
            if not line.strip().startswith('--') or line.strip().startswith('-- ====='):
                cleaned_lines.append(line)
        
        content = '\n'.join(cleaned_lines)
        
        # Split by major sections (marked by comment blocks)
        sections = re.split(r'\n-- =+[^=]*=+\n', content)
        
        # Also split by major SQL constructs
        all_sections = []
        for section in sections:
            if section.strip():
                # Further split by DO blocks, functions, and major statements
                subsections = re.split(r'(?<=\$\$;)\s*\n|(?<=;)\s*\n(?=CREATE|DROP|DO)', section)
                all_sections.extend([s.strip() for s in subsections if s.strip()])
        
        return all_sections
    
    # ========================================================================
    # è´¦æˆ·åŒæ­¥
    # ========================================================================
    
    def sync_project_info(self, project_id: str, account_id: str, project_name: str = None) -> bool:
        """
        åŒæ­¥é¡¹ç›®åŸºæœ¬ä¿¡æ¯
        
        Args:
            project_id: é¡¹ç›®ID
            account_id: è´¦æˆ·ID
            project_name: é¡¹ç›®åç§°ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            conn = self.get_connection()
            cursor = conn.cursor()
            
            # é¦–å…ˆç¡®ä¿è´¦æˆ·è®°å½•å­˜åœ¨
            cursor.execute("""
                SELECT EXISTS (
                    SELECT 1 FROM accounts 
                    WHERE account_id = %s
                );
            """, [account_id])
            
            account_exists = cursor.fetchone()[0]
            
            if not account_exists:
                print(f"[INFO] Creating account record for project sync: {account_id}")
                cursor.execute("""
                    INSERT INTO accounts (account_id, name, created_at, updated_at)
                    VALUES (%s, %s, %s, %s)
                    ON CONFLICT (account_id) DO NOTHING
                """, [
                    account_id,
                    f"Account {account_id}",
                    datetime.now(timezone.utc),
                    datetime.now(timezone.utc)
                ])
                print(f"[OK] Account record created: {account_id}")
            
            # UPSERTé¡¹ç›®ä¿¡æ¯
            cursor.execute("""
                INSERT INTO projects (project_id, account_id, name, created_at, updated_at)
                VALUES (%s, %s, %s, %s, %s)
                ON CONFLICT (project_id)
                DO UPDATE SET
                    name = COALESCE(EXCLUDED.name, projects.name),
                    updated_at = EXCLUDED.updated_at
            """, [
                project_id,
                account_id,
                project_name or f"Project {project_id}",
                datetime.now(timezone.utc),
                datetime.now(timezone.utc)
            ])
            
            conn.commit()
            print(f"[OK] Project sync successful: {project_id}")
            return True
            
        except Exception as e:
            if conn:
                conn.rollback()
            error_msg = f"Project sync failed: {str(e)}"
            self.stats.errors.append(error_msg)
            print(f"[ERROR] {error_msg}")
            return False
            
        finally:
            if conn:
                conn.close()
    
    def sync_account_info(self, account_id: str, account_name: str = None) -> bool:
        """
        åŒæ­¥è´¦æˆ·åŸºæœ¬ä¿¡æ¯
        
        Args:
            account_id: ACCè´¦æˆ·ID
            account_name: è´¦æˆ·åç§°ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            conn = self.get_connection()
            cursor = conn.cursor()
            
            # UPSERTè´¦æˆ·ä¿¡æ¯
            cursor.execute("""
                INSERT INTO accounts (account_id, name, last_synced_at, sync_status, updated_at)
                VALUES (%s, %s, %s, %s, %s)
                ON CONFLICT (account_id)
                DO UPDATE SET
                    name = COALESCE(EXCLUDED.name, accounts.name),
                    last_synced_at = EXCLUDED.last_synced_at,
                    sync_status = EXCLUDED.sync_status,
                    updated_at = EXCLUDED.updated_at
            """, [
                account_id,
                account_name or f"Account {account_id}",
                datetime.now(timezone.utc),
                'synced',
                datetime.now(timezone.utc)
            ])
            
            conn.commit()
            self.stats.accounts_synced += 1
            print(f"[OK] Account sync successful: {account_id}")
            return True
            
        except Exception as e:
            if conn:
                conn.rollback()
            error_msg = f"Account sync failed: {str(e)}"
            self.stats.errors.append(error_msg)
            print(f"[ERROR] {error_msg}")
            return False
            
        finally:
            if conn:
                conn.close()
    
    # ========================================================================
    # ç”¨æˆ·åŒæ­¥ (åŸºäº ACC Account Users API)
    # ========================================================================
    
    async def sync_account_users(
        self, 
        session: aiohttp.ClientSession,
        account_id: str,
        headers: Dict[str, str],
        show_progress: bool = True
    ) -> Dict[str, Any]:
        """
        åŒæ­¥è´¦æˆ·ç”¨æˆ· (GET /hq/v1/accounts/:account_id/users)
        ä½¿ç”¨2-legged tokenè¿›è¡Œè®¤è¯
        
        Args:
            session: aiohttpä¼šè¯
            account_id: è´¦æˆ·ID
            headers: è¯·æ±‚å¤´ï¼ˆå°†è¢«2-legged tokenè¦†ç›–ï¼‰
            show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦
            
        Returns:
            åŒæ­¥ç»“æœ
        """
        if show_progress:
            print(f"\n[USERS] Starting account users sync: {account_id}")
        
        try:
            # è·å–2-legged tokenç”¨äºè´¦æˆ·çº§API
            if get_two_legged_token is None:
                raise Exception("2-legged token function not available")
            
            two_legged_token = get_two_legged_token()
            if not two_legged_token:
                raise Exception("Failed to obtain 2-legged token")
            
            # ä½¿ç”¨2-legged tokençš„headers
            account_headers = {
                "Authorization": f"Bearer {two_legged_token}",
                "Content-Type": "application/json"
            }
            
            # è·å–æ‰€æœ‰ç”¨æˆ·ï¼ˆåˆ†é¡µï¼‰
            all_users = await self._fetch_all_account_users(session, account_id, account_headers, show_progress)
            
            if not all_users:
                print("   [WARN] æœªè·å–åˆ°ç”¨æˆ·æ•°æ®")
                return {'users_synced': 0, 'users_updated': 0}
            
            # æ‰¹é‡åŒæ­¥åˆ°æ•°æ®åº“
            inserted, updated = self._batch_upsert_users(account_id, all_users)
            
            self.stats.users_synced += inserted
            self.stats.users_updated += updated
            
            if show_progress:
                print(f"   [OK] ç”¨æˆ·åŒæ­¥å®Œæˆ: {inserted}ä¸ªæ–°å¢, {updated}ä¸ªæ›´æ–°")
            
            return {
                'users_synced': inserted,
                'users_updated': updated,
                'total_users': len(all_users)
            }
            
        except Exception as e:
            error_msg = f"åŒæ­¥è´¦æˆ·ç”¨æˆ·å¤±è´¥: {str(e)}"
            self.stats.errors.append(error_msg)
            print(f"   [ERROR] {error_msg}")
            return {'users_synced': 0, 'users_updated': 0}
    
    async def _fetch_all_account_users(
        self,
        session: aiohttp.ClientSession,
        account_id: str,
        headers: Dict[str, str],
        show_progress: bool = True
    ) -> List[Dict]:
        """è·å–æ‰€æœ‰è´¦æˆ·ç”¨æˆ·ï¼ˆåˆ†é¡µï¼‰"""
        all_users = []
        offset = 0
        limit = 100  # APIæœ€å¤§é™åˆ¶
        
        while True:
            url = f"https://developer.api.autodesk.com/hq/v1/accounts/{account_id}/users"
            params = {
                'limit': limit,
                'offset': offset,
                'sort': 'name'
            }
            
            if show_progress:
                print(f"   ğŸ“¡ è·å–ç”¨æˆ·æ•°æ®: offset={offset}, limit={limit}")
            
            async with session.get(url, headers=headers, params=params) as response:
                if response.status != 200:
                    error_text = await response.text()
                    raise Exception(f"APIè°ƒç”¨å¤±è´¥: {response.status} - {error_text}")
                
                users = await response.json()
                
                if not users:
                    break
                
                all_users.extend(users)
                
                if show_progress:
                    print(f"      è·å–åˆ° {len(users)} ä¸ªç”¨æˆ·ï¼Œæ€»è®¡ {len(all_users)}")
                
                # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æ›´å¤šæ•°æ®
                if len(users) < limit:
                    break
                
                offset += limit
        
        return all_users
    
    def _batch_upsert_users(self, account_id: str, users: List[Dict]) -> Tuple[int, int]:
        """æ‰¹é‡UPSERTç”¨æˆ·"""
        if not users:
            return 0, 0
        
        conn = None
        try:
            conn = self.get_connection()
            cursor = conn.cursor()
            
            # å‡†å¤‡æ‰¹é‡UPSERT SQLï¼ˆç®€åŒ–ç‰ˆï¼‰
            upsert_sql = """
                INSERT INTO users (
                    user_id, account_id, email, name, status, company_id,
                    default_role_id, account_roles, created_at, updated_at
                ) VALUES (
                    %(user_id)s, %(account_id)s, %(email)s, %(name)s, %(status)s, %(company_id)s,
                    %(default_role_id)s, %(account_roles)s, %(created_at)s, %(updated_at)s
                )
                ON CONFLICT (user_id)
                DO UPDATE SET
                    email = EXCLUDED.email,
                    name = EXCLUDED.name,
                    status = EXCLUDED.status,
                    company_id = EXCLUDED.company_id,
                    default_role_id = EXCLUDED.default_role_id,
                    account_roles = EXCLUDED.account_roles,
                    updated_at = EXCLUDED.updated_at
                RETURNING (xmax = 0) AS inserted
            """
            
            # å¤„ç†æ¯ä¸ªç”¨æˆ·
            results = []
            for user in users:
                try:
                    user_data = self._transform_user_data(account_id, user)
                    cursor.execute(upsert_sql, user_data)
                    result = cursor.fetchone()
                    if result:
                        results.append(result)
                except Exception as e:
                    error_msg = f"å¤„ç†ç”¨æˆ·å¤±è´¥ {user.get('id', 'unknown')}: {str(e)}"
                    self.stats.errors.append(error_msg)
                    print(f"      [ERROR] {error_msg}")
            
            conn.commit()
            
            # ç»Ÿè®¡ç»“æœ (users return single boolean value)
            inserted = sum(1 for result in results if result[0] == True)
            updated = len(results) - inserted
            
            return inserted, updated
            
        except Exception as e:
            if conn:
                conn.rollback()
            error_msg = f"æ‰¹é‡UPSERTç”¨æˆ·å¤±è´¥: {str(e)}"
            self.stats.errors.append(error_msg)
            print(f"      [ERROR] {error_msg}")
            raise
            
        finally:
            if conn:
                conn.close()
    
    def _transform_user_data(self, account_id: str, user: Dict) -> Dict:
        """è½¬æ¢ç”¨æˆ·æ•°æ®ä¸ºæ•°æ®åº“æ ¼å¼ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        now = datetime.now(timezone.utc)
        
        # è§£ææ—¶é—´æˆ³
        created_at = None
        if user.get('created_at'):
            try:
                created_at = datetime.fromisoformat(user['created_at'].replace('Z', '+00:00'))
            except:
                pass
        
        updated_at = None
        if user.get('updated_at'):
            try:
                updated_at = datetime.fromisoformat(user['updated_at'].replace('Z', '+00:00'))
            except:
                pass
        
        # æ„å»ºè´¦æˆ·çº§è§’è‰²åˆ—è¡¨
        account_roles = []
        if user.get('default_role'):
            account_roles.append({
                'id': user.get('default_role_id'),
                'name': user.get('default_role')
            })
        
        # Handle role association - now that we sync roles, we can use the role ID
        default_role_id = user.get('default_role_id')
        # Keep the role ID if it exists, it should be in roles table now
        
        return {
            'user_id': user.get('id'),
            'account_id': account_id,
            'email': user.get('email'),
            'name': user.get('name'),
            'status': user.get('status', 'active'),
            'company_id': user.get('company_id'),
            'default_role_id': default_role_id,  # Set to NULL to avoid FK constraint
            'account_roles': json.dumps(account_roles),
            'created_at': created_at or now,
            'updated_at': updated_at or now
        }
    
    # ========================================================================
    # å…¬å¸åŒæ­¥ (åŸºäº ACC Companies API)
    # ========================================================================
    
    async def sync_project_companies(
        self,
        session: aiohttp.ClientSession,
        account_id: str,
        project_id: str,
        headers: Dict[str, str],
        show_progress: bool = True
    ) -> Dict[str, Any]:
        """
        åŒæ­¥é¡¹ç›®å…¬å¸ (GET /hq/v1/accounts/:account_id/projects/:project_id/companies)
        ä½¿ç”¨2-legged tokenè¿›è¡Œè®¤è¯
        
        Args:
            session: aiohttpä¼šè¯
            account_id: è´¦æˆ·ID
            project_id: é¡¹ç›®ID
            headers: è¯·æ±‚å¤´ï¼ˆå°†è¢«2-legged tokenè¦†ç›–ï¼‰
            show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦
            
        Returns:
            åŒæ­¥ç»“æœ
        """
        if show_progress:
            print(f"\n[COMPANIES] å¼€å§‹åŒæ­¥é¡¹ç›®å…¬å¸: {project_id}")
        
        try:
            # è·å–2-legged tokenç”¨äºè´¦æˆ·çº§API
            if get_two_legged_token is None:
                raise Exception("2-legged token function not available")
            
            two_legged_token = get_two_legged_token()
            if not two_legged_token:
                raise Exception("Failed to obtain 2-legged token")
            
            # ä½¿ç”¨2-legged tokençš„headers
            account_headers = {
                "Authorization": f"Bearer {two_legged_token}",
                "Content-Type": "application/json"
            }
            
            # è·å–æ‰€æœ‰å…¬å¸ï¼ˆåˆ†é¡µï¼‰
            all_companies = await self._fetch_all_project_companies(
                session, account_id, project_id, account_headers, show_progress
            )
            
            if not all_companies:
                print("   [WARN] æœªè·å–åˆ°å…¬å¸æ•°æ®")
                return {'companies_synced': 0, 'companies_updated': 0}
            
            # æ‰¹é‡åŒæ­¥åˆ°æ•°æ®åº“
            inserted, updated = self._batch_upsert_companies(account_id, project_id, all_companies)
            
            self.stats.companies_synced += inserted
            self.stats.companies_updated += updated
            
            if show_progress:
                print(f"   [OK] å…¬å¸åŒæ­¥å®Œæˆ: {inserted}ä¸ªæ–°å¢, {updated}ä¸ªæ›´æ–°")
            
            return {
                'companies_synced': inserted,
                'companies_updated': updated,
                'total_companies': len(all_companies)
            }
            
        except Exception as e:
            error_msg = f"åŒæ­¥é¡¹ç›®å…¬å¸å¤±è´¥: {str(e)}"
            self.stats.errors.append(error_msg)
            print(f"   [ERROR] {error_msg}")
            return {'companies_synced': 0, 'companies_updated': 0}
    
    async def _fetch_all_project_companies(
        self,
        session: aiohttp.ClientSession,
        account_id: str,
        project_id: str,
        headers: Dict[str, str],
        show_progress: bool = True
    ) -> List[Dict]:
        """è·å–æ‰€æœ‰é¡¹ç›®å…¬å¸ï¼ˆåˆ†é¡µï¼‰"""
        all_companies = []
        offset = 0
        limit = 100  # APIæœ€å¤§é™åˆ¶
        
        while True:
            url = f"https://developer.api.autodesk.com/hq/v1/accounts/{account_id}/projects/{project_id}/companies"
            params = {
                'limit': limit,
                'offset': offset,
                'sort': 'name'
            }
            
            if show_progress:
                print(f"   ğŸ“¡ è·å–å…¬å¸æ•°æ®: offset={offset}, limit={limit}")
            
            async with session.get(url, headers=headers, params=params) as response:
                if response.status != 200:
                    error_text = await response.text()
                    raise Exception(f"APIè°ƒç”¨å¤±è´¥: {response.status} - {error_text}")
                
                companies = await response.json()
                
                if not companies:
                    break
                
                all_companies.extend(companies)
                
                if show_progress:
                    print(f"      è·å–åˆ° {len(companies)} ä¸ªå…¬å¸ï¼Œæ€»è®¡ {len(all_companies)}")
                
                # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æ›´å¤šæ•°æ®
                if len(companies) < limit:
                    break
                
                offset += limit
        
        return all_companies
    
    def _batch_upsert_companies(self, account_id: str, project_id: str, companies: List[Dict]) -> Tuple[int, int]:
        """æ‰¹é‡UPSERTå…¬å¸"""
        if not companies:
            return 0, 0
        
        conn = None
        try:
            conn = self.get_connection()
            cursor = conn.cursor()
            
            # å‡†å¤‡æ‰¹é‡UPSERT SQLï¼ˆç®€åŒ–ç‰ˆï¼‰
            upsert_sql = """
                INSERT INTO companies (
                    company_id, account_id, name, trade, country, created_at, updated_at
                ) VALUES (
                    %(company_id)s, %(account_id)s, %(name)s, %(trade)s, %(country)s, %(created_at)s, %(updated_at)s
                )
                ON CONFLICT (company_id)
                DO UPDATE SET
                    name = EXCLUDED.name,
                    trade = EXCLUDED.trade,
                    country = EXCLUDED.country,
                    updated_at = EXCLUDED.updated_at
                RETURNING (xmax = 0) AS inserted
            """
            
            # å¤„ç†æ¯ä¸ªå…¬å¸
            results = []
            for company in companies:
                try:
                    company_data = self._transform_company_data(account_id, project_id, company)
                    cursor.execute(upsert_sql, company_data)
                    result = cursor.fetchone()
                    if result:
                        results.append(result)
                except Exception as e:
                    error_msg = f"å¤„ç†å…¬å¸å¤±è´¥ {company.get('id', 'unknown')}: {str(e)}"
                    self.stats.errors.append(error_msg)
                    print(f"      [ERROR] {error_msg}")
            
            conn.commit()
            
            # ç»Ÿè®¡ç»“æœ (companies return single boolean value)
            inserted = sum(1 for result in results if result[0] == True)
            updated = len(results) - inserted
            
            return inserted, updated
            
        except Exception as e:
            if conn:
                conn.rollback()
            error_msg = f"æ‰¹é‡UPSERTå…¬å¸å¤±è´¥: {str(e)}"
            self.stats.errors.append(error_msg)
            print(f"      [ERROR] {error_msg}")
            raise
            
        finally:
            if conn:
                conn.close()
    
    def _transform_company_data(self, account_id: str, project_id: str, company: Dict) -> Dict:
        """è½¬æ¢å…¬å¸æ•°æ®ä¸ºæ•°æ®åº“æ ¼å¼ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        now = datetime.now(timezone.utc)
        
        # è§£ææ—¶é—´æˆ³
        created_at = None
        if company.get('created_at'):
            try:
                created_at = datetime.fromisoformat(company['created_at'].replace('Z', '+00:00'))
            except:
                pass
        
        updated_at = None
        if company.get('updated_at'):
            try:
                updated_at = datetime.fromisoformat(company['updated_at'].replace('Z', '+00:00'))
            except:
                pass
        
        # Handle empty trade values
        trade = company.get('trade')
        if trade == '' or trade is None:
            trade = None  # Use NULL instead of empty string for enum
        
        return {
            'company_id': company.get('id'),
            'account_id': account_id,
            'name': company.get('name'),
            'trade': trade,
            'country': company.get('country'),
            'created_at': created_at or now,
            'updated_at': updated_at or now
        }
    
    # ========================================================================
    # è§’è‰²åŒæ­¥ (ä»é¡¹ç›®ç”¨æˆ·æ•°æ®ä¸­æå–)
    # ========================================================================
    
    async def sync_roles_from_project_users(
        self,
        session: aiohttp.ClientSession,
        account_id: str,
        project_ids: List[str],
        headers: Dict[str, str],
        show_progress: bool = True
    ) -> Dict[str, Any]:
        """
        ä»é¡¹ç›®ç”¨æˆ·æ•°æ®ä¸­æå–å¹¶åŒæ­¥è§’è‰²ä¿¡æ¯
        
        Args:
            session: aiohttpä¼šè¯
            project_ids: é¡¹ç›®IDåˆ—è¡¨
            headers: è¯·æ±‚å¤´
            show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦
            
        Returns:
            åŒæ­¥ç»“æœ
        """
        if show_progress:
            print(f"\n[ROLES] Extracting roles from project users...")
        
        try:
            all_roles = set()  # ä½¿ç”¨seté¿å…é‡å¤
            
            # è·å–2-legged tokenç”¨äºè´¦æˆ·çº§API
            if get_two_legged_token is None:
                raise Exception("2-legged token function not available")
            
            two_legged_token = get_two_legged_token()
            if not two_legged_token:
                raise Exception("Failed to obtain 2-legged token")
            
            # ä½¿ç”¨2-legged tokençš„headers
            account_headers = {
                "Authorization": f"Bearer {two_legged_token}",
                "Content-Type": "application/json"
            }
            
            # ä»è´¦æˆ·ç”¨æˆ·æ•°æ®ä¸­æå–è§’è‰²
            account_users = await self._fetch_all_account_users(session, account_id, account_headers, False)
            for user in account_users:
                # æå–é»˜è®¤è§’è‰²
                if user.get('default_role_id') and user.get('default_role'):
                    all_roles.add((user['default_role_id'], user['default_role']))
            
            # ä»æ¯ä¸ªé¡¹ç›®çš„ç”¨æˆ·æ•°æ®ä¸­æå–è§’è‰²
            for project_id in project_ids:
                project_users = await self._fetch_all_project_users(session, project_id, headers, False)
                
                for user in project_users:
                    # æå–è§’è‰²ä¿¡æ¯
                    roles = user.get('roles', [])
                    for role in roles:
                        if role.get('id') and role.get('name'):
                            all_roles.add((role['id'], role['name']))
            
            if not all_roles:
                if show_progress:
                    print("   [WARN] No roles found in project users data")
                return {'roles_synced': 0}
            
            # æ‰¹é‡åŒæ­¥è§’è‰²åˆ°æ•°æ®åº“
            inserted = self._batch_upsert_roles(all_roles, show_progress)
            
            self.stats.roles_synced = inserted
            
            if show_progress:
                print(f"   [OK] Roles sync completed: {inserted} roles synced")
            
            return {
                'roles_synced': inserted,
                'total_roles': len(all_roles)
            }
            
        except Exception as e:
            error_msg = f"Role sync failed: {str(e)}"
            self.stats.errors.append(error_msg)
            if show_progress:
                print(f"   [ERROR] {error_msg}")
            return {'roles_synced': 0}
    
    def _batch_upsert_roles(self, roles_set: set, show_progress: bool = True) -> int:
        """æ‰¹é‡UPSERTè§’è‰²"""
        if not roles_set:
            return 0
        
        conn = None
        try:
            conn = self.get_connection()
            cursor = conn.cursor()
            
            # å‡†å¤‡æ‰¹é‡UPSERT SQL
            upsert_sql = """
                INSERT INTO roles (
                    role_id, name, description, created_at, updated_at
                ) VALUES (
                    %(role_id)s, %(name)s, %(description)s, %(created_at)s, %(updated_at)s
                )
                ON CONFLICT (role_id)
                DO UPDATE SET
                    name = EXCLUDED.name,
                    updated_at = EXCLUDED.updated_at
                RETURNING (xmax = 0) AS inserted
            """
            
            # å¤„ç†æ¯ä¸ªè§’è‰²
            results = []
            now = datetime.now(timezone.utc)
            
            for role_id, role_name in roles_set:
                try:
                    role_data = {
                        'role_id': role_id,
                        'name': role_name,
                        'description': f"Role: {role_name}",  # ç®€å•æè¿°
                        'created_at': now,
                        'updated_at': now
                    }
                    cursor.execute(upsert_sql, role_data)
                    result = cursor.fetchone()
                    if result:
                        results.append(result)
                except Exception as e:
                    error_msg = f"Process role failed {role_id}: {str(e)}"
                    self.stats.errors.append(error_msg)
                    if show_progress:
                        print(f"      [ERROR] {error_msg}")
            
            conn.commit()
            
            # ç»Ÿè®¡ç»“æœ (roles return single boolean value)
            inserted = sum(1 for result in results if result[0] == True)
            
            return inserted
            
        except Exception as e:
            if conn:
                conn.rollback()
            error_msg = f"Batch UPSERT roles failed: {str(e)}"
            self.stats.errors.append(error_msg)
            if show_progress:
                print(f"      [ERROR] {error_msg}")
            raise
            
        finally:
            if conn:
                conn.close()
    
    # ========================================================================
    # é¡¹ç›®ç”¨æˆ·åŒæ­¥ (åŸºäºç°æœ‰çš„ ACC Project Users API)
    # ========================================================================
    
    async def sync_project_users(
        self,
        session: aiohttp.ClientSession,
        project_id: str,
        headers: Dict[str, str],
        show_progress: bool = True
    ) -> Dict[str, Any]:
        """
        åŒæ­¥é¡¹ç›®ç”¨æˆ· (GET /construction/admin/v1/projects/:project_id/users)
        
        Args:
            session: aiohttpä¼šè¯
            project_id: é¡¹ç›®ID
            headers: è¯·æ±‚å¤´
            show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦
            
        Returns:
            åŒæ­¥ç»“æœ
        """
        if show_progress:
            print(f"\n[PROJ_USERS] å¼€å§‹åŒæ­¥é¡¹ç›®ç”¨æˆ·: {project_id}")
        
        try:
            # è·å–æ‰€æœ‰é¡¹ç›®ç”¨æˆ·ï¼ˆåˆ†é¡µï¼‰
            all_users = await self._fetch_all_project_users(session, project_id, headers, show_progress)
            
            if not all_users:
                print("   [WARN] æœªè·å–åˆ°é¡¹ç›®ç”¨æˆ·æ•°æ®")
                return {'project_users_synced': 0, 'project_users_updated': 0}
            
            # æ‰¹é‡åŒæ­¥åˆ°æ•°æ®åº“
            inserted, updated = self._batch_upsert_project_users(project_id, all_users)
            
            self.stats.project_users_synced += inserted
            self.stats.project_users_updated += updated
            
            if show_progress:
                print(f"   [OK] é¡¹ç›®ç”¨æˆ·åŒæ­¥å®Œæˆ: {inserted}ä¸ªæ–°å¢, {updated}ä¸ªæ›´æ–°")
            
            return {
                'project_users_synced': inserted,
                'project_users_updated': updated,
                'total_project_users': len(all_users)
            }
            
        except Exception as e:
            error_msg = f"åŒæ­¥é¡¹ç›®ç”¨æˆ·å¤±è´¥: {str(e)}"
            self.stats.errors.append(error_msg)
            print(f"   [ERROR] {error_msg}")
            return {'project_users_synced': 0, 'project_users_updated': 0}
    
    async def _fetch_all_project_users(
        self,
        session: aiohttp.ClientSession,
        project_id: str,
        headers: Dict[str, str],
        show_progress: bool = True
    ) -> List[Dict]:
        """è·å–æ‰€æœ‰é¡¹ç›®ç”¨æˆ·ï¼ˆåˆ†é¡µï¼‰"""
        all_users = []
        offset = 0
        limit = 200  # APIæœ€å¤§é™åˆ¶
        
        # æ¸…ç†é¡¹ç›®IDå‰ç¼€
        clean_project_id = project_id.replace('b.', '') if project_id.startswith('b.') else project_id
        
        while True:
            url = f"https://developer.api.autodesk.com/construction/admin/v1/projects/{clean_project_id}/users"
            params = {
                'limit': limit,
                'offset': offset,
                'sort': 'name',
                'fields': 'name,email,firstName,lastName,autodeskId,analyticsId,addressLine1,addressLine2,city,stateOrProvince,postalCode,country,imageUrl,phone,jobTitle,industry,aboutMe,accessLevels,companyId,companyName,roleIds,roles,status,addedOn,products'
            }
            
            if show_progress:
                print(f"   ğŸ“¡ è·å–é¡¹ç›®ç”¨æˆ·æ•°æ®: offset={offset}, limit={limit}")
            
            async with session.get(url, headers=headers, params=params) as response:
                if response.status != 200:
                    error_text = await response.text()
                    raise Exception(f"APIè°ƒç”¨å¤±è´¥: {response.status} - {error_text}")
                
                data = await response.json()
                users = data.get('results', [])
                
                if not users:
                    break
                
                all_users.extend(users)
                
                # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æ›´å¤šæ•°æ®
                pagination = data.get('pagination', {})
                total_results = pagination.get('totalResults', len(users))
                
                if show_progress:
                    print(f"      è·å–åˆ° {len(users)} ä¸ªç”¨æˆ·ï¼Œæ€»è®¡ {len(all_users)}/{total_results}")
                
                if offset + len(users) >= total_results:
                    break
                
                offset += limit
        
        return all_users
    
    def _batch_upsert_project_users(self, project_id: str, users: List[Dict]) -> Tuple[int, int]:
        """æ‰¹é‡UPSERTé¡¹ç›®ç”¨æˆ·"""
        if not users:
            return 0, 0
        
        conn = None
        try:
            conn = self.get_connection()
            cursor = conn.cursor()
            
            # å‡†å¤‡æ‰¹é‡UPSERT SQL
            upsert_sql = """
                INSERT INTO project_users (
                    project_id, user_id, project_user_id, autodesk_id, analytics_id,
                    status, access_levels, role_ids, roles, products,
                    project_company_id, project_company_name, added_on,
                    last_synced_at, sync_status, created_at, updated_at
                ) VALUES (
                    %(project_id)s, %(user_id)s, %(project_user_id)s, %(autodesk_id)s, %(analytics_id)s,
                    %(status)s, %(access_levels)s, %(role_ids)s, %(roles)s, %(products)s,
                    %(project_company_id)s, %(project_company_name)s, %(added_on)s,
                    %(last_synced_at)s, %(sync_status)s, %(created_at)s, %(updated_at)s
                )
                ON CONFLICT (project_id, user_id)
                DO UPDATE SET
                    project_user_id = EXCLUDED.project_user_id,
                    autodesk_id = EXCLUDED.autodesk_id,
                    analytics_id = EXCLUDED.analytics_id,
                    status = EXCLUDED.status,
                    access_levels = EXCLUDED.access_levels,
                    role_ids = EXCLUDED.role_ids,
                    roles = EXCLUDED.roles,
                    products = EXCLUDED.products,
                    project_company_id = EXCLUDED.project_company_id,
                    project_company_name = EXCLUDED.project_company_name,
                    added_on = EXCLUDED.added_on,
                    last_synced_at = EXCLUDED.last_synced_at,
                    sync_status = EXCLUDED.sync_status,
                    updated_at = EXCLUDED.updated_at
                RETURNING id, (xmax = 0) AS inserted
            """
            
            # å¤„ç†æ¯ä¸ªç”¨æˆ·
            results = []
            for user in users:
                try:
                    user_data = self._transform_project_user_data(project_id, user)
                    cursor.execute(upsert_sql, user_data)
                    result = cursor.fetchone()
                    if result:
                        results.append(result)
                except Exception as e:
                    error_msg = f"å¤„ç†é¡¹ç›®ç”¨æˆ·å¤±è´¥ {user.get('id', 'unknown')}: {str(e)}"
                    self.stats.errors.append(error_msg)
                    print(f"      [ERROR] {error_msg}")
            
            conn.commit()
            
            # ç»Ÿè®¡ç»“æœ (project_users return id and boolean)
            inserted = sum(1 for _, is_insert in results if is_insert)
            updated = len(results) - inserted
            
            return inserted, updated
            
        except Exception as e:
            if conn:
                conn.rollback()
            error_msg = f"æ‰¹é‡UPSERTé¡¹ç›®ç”¨æˆ·å¤±è´¥: {str(e)}"
            self.stats.errors.append(error_msg)
            print(f"      [ERROR] {error_msg}")
            raise
            
        finally:
            if conn:
                conn.close()
    
    def _transform_project_user_data(self, project_id: str, user: Dict) -> Dict:
        """è½¬æ¢é¡¹ç›®ç”¨æˆ·æ•°æ®ä¸ºæ•°æ®åº“æ ¼å¼"""
        now = datetime.now(timezone.utc)
        
        # è§£ææ—¶é—´æˆ³
        added_on = None
        if user.get('addedOn'):
            try:
                added_on = datetime.fromisoformat(user['addedOn'].replace('Z', '+00:00'))
            except:
                pass
        
        return {
            'project_id': project_id,
            'user_id': user.get('id'),
            'project_user_id': user.get('id'),  # åœ¨é¡¹ç›®ç”¨æˆ·APIä¸­ï¼Œè¿™é€šå¸¸æ˜¯åŒä¸€ä¸ªID
            'autodesk_id': user.get('autodeskId'),
            'analytics_id': user.get('analyticsId'),
            'status': user.get('status', 'active'),
            'access_levels': json.dumps(user.get('accessLevels', {})),
            'role_ids': json.dumps(user.get('roleIds', [])),
            'roles': json.dumps(user.get('roles', [])),
            'products': json.dumps(user.get('products', [])),
            'project_company_id': user.get('companyId'),
            'project_company_name': user.get('companyName'),
            'added_on': added_on,
            'last_synced_at': now,
            'sync_status': 'synced',
            'created_at': now,
            'updated_at': now
        }
    
    # ========================================================================
    # è§’è‰²æ±‡æ€»åˆ†æ (åŸºäº AccountRolesList.vue çš„æ¨¡å¼)
    # ========================================================================
    
    def get_account_roles_summary(self, account_id: str) -> Dict[str, Any]:
        """
        è·å–è´¦æˆ·è§’è‰²æ±‡æ€»ï¼ˆç±»ä¼¼ AccountRolesList.vue çš„åŠŸèƒ½ï¼‰
        
        Args:
            account_id: è´¦æˆ·ID
            
        Returns:
            è§’è‰²æ±‡æ€»æ•°æ®
        """
        conn = None
        try:
            conn = self.get_connection()
            cursor = conn.cursor(cursor_factory=psycopg2.extras.RealDictCursor)
            
            start_time = time.time()
            
            # è·å–è§’è‰²æ±‡æ€»ç»Ÿè®¡
            cursor.execute("""
                WITH role_stats AS (
                    SELECT 
                        jsonb_array_elements(pu.roles)->>'name' as role_name,
                        jsonb_array_elements(pu.roles)->>'id' as role_id,
                        COUNT(DISTINCT pu.user_id) as unique_users,
                        COUNT(DISTINCT pu.project_id) as unique_projects,
                        COUNT(*) as total_assignments,
                        array_agg(DISTINCT pu.project_id) as projects,
                        array_agg(DISTINCT jsonb_build_object(
                            'user_id', u.user_id,
                            'user_name', u.name,
                            'user_email', u.email,
                            'status', pu.status,
                            'project_id', pu.project_id
                        )) as users
                    FROM project_users pu
                    JOIN users u ON pu.user_id = u.user_id
                    WHERE u.account_id = %s
                    AND jsonb_array_length(pu.roles) > 0
                    GROUP BY jsonb_array_elements(pu.roles)->>'name', jsonb_array_elements(pu.roles)->>'id'
                )
                SELECT * FROM role_stats
                ORDER BY unique_users DESC, role_name ASC
            """, [account_id])
            
            role_summary = [dict(row) for row in cursor.fetchall()]
            
            # è·å–æ€»ä½“ç»Ÿè®¡ (fixed to avoid set-returning function in aggregate)
            cursor.execute("""
                WITH role_expanded AS (
                    SELECT 
                        pu.user_id,
                        pu.project_id,
                        jsonb_array_elements(pu.roles)->>'name' as role_name
                    FROM project_users pu
                    JOIN users u ON pu.user_id = u.user_id
                    WHERE u.account_id = %s
                    AND jsonb_array_length(pu.roles) > 0
                )
                SELECT 
                    COUNT(DISTINCT role_name) as unique_roles,
                    COUNT(*) as total_role_assignments,
                    COUNT(DISTINCT user_id) as users_with_roles,
                    COUNT(DISTINCT project_id) as projects_with_roles
                FROM role_expanded
            """, [account_id])
            
            statistics = dict(cursor.fetchone()) if cursor.rowcount > 0 else {}
            
            # è·å–ç”¨æˆ·è§’è‰²æ˜ å°„ (fixed to avoid set-returning function in aggregate)
            cursor.execute("""
                WITH user_roles_expanded AS (
                    SELECT 
                        u.user_id,
                        u.name as user_name,
                        u.email as user_email,
                        jsonb_array_elements(pu.roles)->>'name' as role_name
                    FROM users u
                    JOIN project_users pu ON u.user_id = pu.user_id
                    WHERE u.account_id = %s
                    AND jsonb_array_length(pu.roles) > 0
                )
                SELECT 
                    user_id,
                    user_name,
                    user_email,
                    array_agg(DISTINCT role_name) as roles
                FROM user_roles_expanded
                GROUP BY user_id, user_name, user_email
            """, [account_id])
            
            user_role_mapping = {row['user_id']: dict(row) for row in cursor.fetchall()}
            
            query_duration = time.time() - start_time
            statistics['query_duration_seconds'] = round(query_duration, 3)
            
            # è·å–è§’è‰²è¡¨ä¸­çš„æ‰€æœ‰è§’è‰²åŠå…¶ç”¨æˆ·ç»Ÿè®¡
            cursor.execute("""
                SELECT 
                    r.role_id,
                    r.name as role_name,
                    r.description,
                    r.created_at,
                    -- ç»Ÿè®¡ä½¿ç”¨æ­¤è§’è‰²ä½œä¸ºé»˜è®¤è§’è‰²çš„ç”¨æˆ·æ•°
                    COUNT(DISTINCT u.user_id) as users_with_default_role,
                    -- ç»Ÿè®¡åœ¨é¡¹ç›®ä¸­ä½¿ç”¨æ­¤è§’è‰²çš„ç”¨æˆ·æ•°
                    COUNT(DISTINCT pu_role.user_id) as users_in_projects,
                    -- ç»Ÿè®¡ä½¿ç”¨æ­¤è§’è‰²çš„é¡¹ç›®æ•°
                    COUNT(DISTINCT pu_role.project_id) as projects_using_role
                FROM roles r
                LEFT JOIN users u ON r.role_id = u.default_role_id
                LEFT JOIN (
                    SELECT DISTINCT 
                        pu.user_id, 
                        pu.project_id,
                        jsonb_array_elements(pu.roles)->>'id' as role_id
                    FROM project_users pu
                    WHERE jsonb_array_length(pu.roles) > 0
                ) pu_role ON r.role_id = pu_role.role_id
                GROUP BY r.role_id, r.name, r.description, r.created_at
                ORDER BY users_with_default_role DESC, users_in_projects DESC, r.name ASC
            """)
            
            roles_detail = [dict(row) for row in cursor.fetchall()]
            
            return {
                'role_summary': role_summary,
                'user_role_mapping': user_role_mapping,
                'roles_detail': roles_detail,  # æ–°å¢ï¼šè§’è‰²è¯¦ç»†ä¿¡æ¯
                'statistics': statistics,
                'query_time': datetime.now(timezone.utc).isoformat()
            }
            
        except Exception as e:
            error_msg = f"è·å–è§’è‰²æ±‡æ€»å¤±è´¥: {str(e)}"
            print(f"[ERROR] {error_msg}")
            return {
                'role_summary': [],
                'user_role_mapping': {},
                'statistics': {},
                'error': error_msg
            }
            
        finally:
            if conn:
                conn.close()
    
    def get_users_by_role(self, role_id: str = None, role_name: str = None) -> Dict[str, Any]:
        """
        è·å–æŒ‡å®šè§’è‰²ä¸‹çš„æ‰€æœ‰ç”¨æˆ·
        
        Args:
            role_id: è§’è‰²ID
            role_name: è§’è‰²åç§° (å¦‚æœæ²¡æœ‰role_id)
            
        Returns:
            è§’è‰²åŠå…¶ç”¨æˆ·ä¿¡æ¯
        """
        conn = None
        try:
            conn = self.get_connection()
            cursor = conn.cursor(cursor_factory=psycopg2.extras.RealDictCursor)
            
            # æ„å»ºæŸ¥è¯¢æ¡ä»¶
            if role_id:
                role_condition = "r.role_id = %s"
                role_param = role_id
            elif role_name:
                role_condition = "r.name = %s"
                role_param = role_name
            else:
                raise ValueError("Must provide either role_id or role_name")
            
            # æŸ¥è¯¢è§’è‰²ä¿¡æ¯
            cursor.execute(f"""
                SELECT role_id, name, description, created_at
                FROM roles r
                WHERE {role_condition}
            """, [role_param])
            
            role_info = cursor.fetchone()
            if not role_info:
                return {'error': 'Role not found'}
            
            role_info = dict(role_info)
            
            # æŸ¥è¯¢ä½¿ç”¨æ­¤è§’è‰²ä½œä¸ºé»˜è®¤è§’è‰²çš„ç”¨æˆ·
            cursor.execute(f"""
                SELECT 
                    u.user_id,
                    u.name as user_name,
                    u.email,
                    u.status,
                    c.name as company_name,
                    'default_role' as role_type
                FROM users u
                LEFT JOIN companies c ON u.company_id = c.company_id
                LEFT JOIN roles r ON u.default_role_id = r.role_id
                WHERE {role_condition}
            """, [role_param])
            
            default_role_users = [dict(row) for row in cursor.fetchall()]
            
            # æŸ¥è¯¢åœ¨é¡¹ç›®ä¸­ä½¿ç”¨æ­¤è§’è‰²çš„ç”¨æˆ·
            cursor.execute(f"""
                SELECT DISTINCT
                    u.user_id,
                    u.name as user_name,
                    u.email,
                    u.status,
                    c.name as company_name,
                    pu.project_id,
                    p.name as project_name,
                    'project_role' as role_type
                FROM users u
                LEFT JOIN companies c ON u.company_id = c.company_id
                JOIN project_users pu ON u.user_id = pu.user_id
                LEFT JOIN projects p ON pu.project_id = p.project_id
                JOIN roles r ON r.role_id = %s
                WHERE pu.roles @> jsonb_build_array(jsonb_build_object('id', r.role_id))
                AND jsonb_array_length(pu.roles) > 0
            """, [role_param])
            
            project_role_users = [dict(row) for row in cursor.fetchall()]
            
            # åˆå¹¶ç”¨æˆ·åˆ—è¡¨ï¼ˆå»é‡ï¼‰
            all_users = {}
            
            # æ·»åŠ é»˜è®¤è§’è‰²ç”¨æˆ·
            for user in default_role_users:
                user_id = user['user_id']
                if user_id not in all_users:
                    all_users[user_id] = user
                    all_users[user_id]['role_types'] = []
                all_users[user_id]['role_types'].append('default_role')
            
            # æ·»åŠ é¡¹ç›®è§’è‰²ç”¨æˆ·
            for user in project_role_users:
                user_id = user['user_id']
                if user_id not in all_users:
                    all_users[user_id] = user
                    all_users[user_id]['role_types'] = []
                if 'project_role' not in all_users[user_id]['role_types']:
                    all_users[user_id]['role_types'].append('project_role')
                
                # æ·»åŠ é¡¹ç›®ä¿¡æ¯
                if 'projects' not in all_users[user_id]:
                    all_users[user_id]['projects'] = []
                all_users[user_id]['projects'].append({
                    'project_id': user['project_id'],
                    'project_name': user['project_name']
                })
            
            return {
                'role_info': role_info,
                'users': list(all_users.values()),
                'total_users': len(all_users),
                'default_role_users': len(default_role_users),
                'project_role_users': len(project_role_users)
            }
            
        except Exception as e:
            error_msg = f"Query users by role failed: {str(e)}"
            print(f"[ERROR] {error_msg}")
            return {'error': error_msg}
            
        finally:
            if conn:
                conn.close()
    
    # ========================================================================
    # å®Œæ•´åŒæ­¥æµç¨‹
    # ========================================================================
    
    async def full_account_sync(
        self,
        account_id: str,
        project_ids: List[str],
        access_token: str,
        show_progress: bool = True,
        clean_first: bool = True
    ) -> Dict[str, Any]:
        """
        å®Œæ•´çš„è´¦æˆ·æ•°æ®åŒæ­¥
        
        Args:
            account_id: è´¦æˆ·ID
            project_ids: é¡¹ç›®IDåˆ—è¡¨
            access_token: è®¿é—®ä»¤ç‰Œ
            show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦
            clean_first: æ˜¯å¦å…ˆæ¸…ç†æ•°æ®åº“è¡¨
            
        Returns:
            åŒæ­¥ç»“æœç»Ÿè®¡
        """
        if show_progress:
            print(f"\n[START] Starting full account data synchronization")
            print(f"   Account ID: {account_id}")
            print(f"   Projects: {len(project_ids)}")
            print(f"   Clean first: {clean_first}")
            print("=" * 60)
        
        start_time = time.time()
        
        headers = {
            "Authorization": f"Bearer {access_token}",
            "Content-Type": "application/json"
        }
        
        # é‡ç½®ç»Ÿè®¡
        self.stats = AccountSyncStats()
        
        # Step 0: Clean database if requested
        if clean_first:
            if show_progress:
                print(f"\n[CLEAN] Cleaning database to prevent data corruption...")
            
            # Drop existing tables
            drop_success = self.drop_account_tables(show_progress)
            if not drop_success:
                if show_progress:
                    print("   [WARN] Warning: Failed to drop some tables, continuing anyway...")
            
            # Recreate schema
            schema_success = self.create_account_schema(show_progress)
            if not schema_success:
                error_msg = "Failed to create account schema"
                self.stats.errors.append(error_msg)
                if show_progress:
                    print(f"   [FAILED] {error_msg}")
                return {
                    'account_id': account_id,
                    'projects_processed': 0,
                    'statistics': {
                        'accounts_synced': 0,
                        'users_synced': 0,
                        'users_updated': 0,
                        'companies_synced': 0,
                        'companies_updated': 0,
                        'project_users_synced': 0,
                        'project_users_updated': 0,
                        'total_errors': len(self.stats.errors)
                    },
                    'errors': self.stats.errors,
                    'execution_time': f"{time.time() - start_time:.2f}s",
                    'sync_time': datetime.now(timezone.utc).isoformat()
                }
        
        async with aiohttp.ClientSession() as session:
            # 1. åŒæ­¥è´¦æˆ·ä¿¡æ¯
            if show_progress:
                print(f"\n[SYNC] Syncing account information...")
            self.sync_account_info(account_id)
            
            # 2. åŒæ­¥é¡¹ç›®ä¿¡æ¯å’Œå…¬å¸ (å¿…é¡»åœ¨ç”¨æˆ·ä¹‹å‰)
            for project_id in project_ids:
                if show_progress:
                    print(f"\n[PROJECT] Processing project: {project_id}")
                
                # åŒæ­¥é¡¹ç›®åŸºæœ¬ä¿¡æ¯
                self.sync_project_info(project_id, account_id)
                
                # åŒæ­¥é¡¹ç›®å…¬å¸ (å¿…é¡»åœ¨ç”¨æˆ·ä¹‹å‰ï¼Œå› ä¸ºç”¨æˆ·è¡¨æœ‰å¤–é”®å¼•ç”¨)
                await self.sync_project_companies(session, account_id, project_id, headers, show_progress)
            
            # 3. åŒæ­¥è§’è‰² (åœ¨ç”¨æˆ·ä¹‹å‰ï¼Œå› ä¸ºç”¨æˆ·è¡¨æœ‰å¤–é”®å¼•ç”¨)
            if show_progress:
                print(f"\n[ROLES] Syncing roles...")
            await self.sync_roles_from_project_users(session, account_id, project_ids, headers, show_progress)
            
            # 4. åŒæ­¥ç”¨æˆ· (åœ¨å…¬å¸å’Œè§’è‰²åŒæ­¥å®Œæˆå)
            if show_progress:
                print(f"\n[USERS] Syncing account users...")
            await self.sync_account_users(session, account_id, headers, show_progress)
            
            # 5. åŒæ­¥é¡¹ç›®ç”¨æˆ· (åœ¨ç”¨æˆ·å’Œå…¬å¸éƒ½åŒæ­¥å®Œæˆå)
            for project_id in project_ids:
                if show_progress:
                    print(f"\n[PROJ_USERS] Processing project users: {project_id}")
                
                # åŒæ­¥é¡¹ç›®ç”¨æˆ·
                await self.sync_project_users(session, project_id, headers, show_progress)
        
        total_time = time.time() - start_time
        
        # ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
        result = {
            'account_id': account_id,
            'projects_processed': len(project_ids),
            'statistics': {
                'accounts_synced': self.stats.accounts_synced,
                'users_synced': self.stats.users_synced,
                'users_updated': self.stats.users_updated,
                'companies_synced': self.stats.companies_synced,
                'companies_updated': self.stats.companies_updated,
                'project_users_synced': self.stats.project_users_synced,
                'project_users_updated': self.stats.project_users_updated,
                'total_errors': len(self.stats.errors)
            },
            'errors': self.stats.errors,
            'execution_time': f"{total_time:.2f}ç§’",
            'sync_time': datetime.now(timezone.utc).isoformat()
        }
        
        if show_progress:
            print("\n" + "=" * 60)
            print("[STATS] åŒæ­¥å®Œæˆç»Ÿè®¡:")
            print(f"   è´¦æˆ·: {self.stats.accounts_synced}ä¸ª")
            print(f"   ç”¨æˆ·: {self.stats.users_synced}ä¸ªæ–°å¢, {self.stats.users_updated}ä¸ªæ›´æ–°")
            print(f"   å…¬å¸: {self.stats.companies_synced}ä¸ªæ–°å¢, {self.stats.companies_updated}ä¸ªæ›´æ–°")
            print(f"   é¡¹ç›®ç”¨æˆ·: {self.stats.project_users_synced}ä¸ªæ–°å¢, {self.stats.project_users_updated}ä¸ªæ›´æ–°")
            print(f"   é”™è¯¯: {len(self.stats.errors)}ä¸ª")
            print(f"   æ€»è€—æ—¶: {total_time:.2f}ç§’")
            
            if self.stats.errors:
                print(f"\n[FAILED] é”™è¯¯è¯¦æƒ…:")
                for error in self.stats.errors[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ªé”™è¯¯
                    print(f"   - {error}")
                if len(self.stats.errors) > 5:
                    print(f"   ... è¿˜æœ‰ {len(self.stats.errors) - 5} ä¸ªé”™è¯¯")
        
        return result


# ============================================================================
# ä¾¿æ·å‡½æ•°
# ============================================================================

def get_account_sync_manager() -> AccountDataSyncManager:
    """è·å–è´¦æˆ·åŒæ­¥ç®¡ç†å™¨å®ä¾‹"""
    return AccountDataSyncManager()


async def sync_account_data(
    account_id: str,
    project_ids: List[str],
    access_token: str,
    show_progress: bool = True,
    clean_first: bool = True
) -> Dict[str, Any]:
    """
    ä¾¿æ·çš„è´¦æˆ·æ•°æ®åŒæ­¥å‡½æ•°
    
    Args:
        account_id: è´¦æˆ·ID
        project_ids: é¡¹ç›®IDåˆ—è¡¨
        access_token: è®¿é—®ä»¤ç‰Œ
        show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦
        clean_first: æ˜¯å¦å…ˆæ¸…ç†æ•°æ®åº“è¡¨
        
    Returns:
        åŒæ­¥ç»“æœ
    """
    manager = get_account_sync_manager()
    return await manager.full_account_sync(account_id, project_ids, access_token, show_progress, clean_first)


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    print("è´¦æˆ·æ•°æ®åŒæ­¥è„šæœ¬æµ‹è¯•")
    print("=" * 60)
    
    try:
        manager = get_account_sync_manager()
        print("[OK] è´¦æˆ·åŒæ­¥ç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
        
        # æµ‹è¯•è§’è‰²æ±‡æ€»åŠŸèƒ½
        # account_id = "your-account-id"
        # summary = manager.get_account_roles_summary(account_id)
        # print(f"\nè§’è‰²æ±‡æ€»æµ‹è¯•:")
        # print(json.dumps(summary, indent=2, ensure_ascii=False, default=str))
        
    except Exception as e:
        print(f"[ERROR] é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
